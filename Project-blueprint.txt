Project Cerberus 完整实施蓝图
第一部分：首席架构师 (Chief Architect) 详细实施方案
1.1 系统架构详细设计
python"""
系统架构核心设计文档
Version: 1.0
Last Updated: 2024
"""

class SystemArchitecture:
    """
    Cerberus风险管理系统架构设计
    """
    
    def __init__(self):
        self.layers = {
            "数据接入层": {
                "实时数据源": {
                    "股票行情": ["IB API", "Bloomberg Terminal", "Refinitiv"],
                    "期权链": ["CBOE Direct Feed", "OPRA"],
                    "加密货币": ["Binance WebSocket", "Coinbase Pro", "CME CF"],
                    "波动率指数": ["VIX Feed", "Proprietary Vol Surface"]
                },
                "历史数据源": {
                    "主数据库": "TimescaleDB (时序优化)",
                    "备份存储": "AWS S3 (Parquet格式)",
                    "快速缓存": "Redis Cluster"
                },
                "数据预处理": {
                    "清洗规则": self._define_cleaning_rules(),
                    "标准化流程": self._define_normalization(),
                    "质量检查": self._define_quality_checks()
                }
            },
            
            "计算引擎层": {
                "期权定价引擎": {
                    "基础模型": ["Black-Scholes", "American Option (Binomial/FD)"],
                    "高级模型": ["Heston Stochastic Vol", "Jump Diffusion"],
                    "数值方法": ["Monte Carlo (GPU)", "Finite Difference", "FFT"]
                },
                "风险计算引擎": {
                    "Greeks计算": self._define_greeks_engine(),
                    "VaR/ES计算": self._define_var_engine(),
                    "情景分析": self._define_scenario_engine()
                },
                "性能优化": {
                    "并行计算": "Ray + Dask",
                    "GPU加速": "CUDA via CuPy",
                    "缓存策略": "Multi-level caching"
                }
            },
            
            "业务逻辑层": {
                "风控规则引擎": self._define_risk_rules(),
                "交易前检查": self._define_pretrade_checks(),
                "限额管理": self._define_limit_management(),
                "告警系统": self._define_alert_system()
            },
            
            "API服务层": {
                "内部API": {
                    "框架": "FastAPI",
                    "协议": "REST + WebSocket",
                    "认证": "JWT + API Keys"
                },
                "外部接口": {
                    "FIX Gateway": "QuickFIX",
                    "Market Data": "Binary Protocol"
                }
            },
            
            "展示层": {
                "实时仪表盘": {
                    "框架": "React 18 + TypeScript",
                    "图表": "D3.js + Victory",
                    "实时更新": "WebSocket + Server-Sent Events"
                },
                "报告系统": {
                    "生成器": "Jupyter + Papermill",
                    "调度": "Apache Airflow"
                }
            }
        }
    
    def _define_cleaning_rules(self):
        """数据清洗规则详细定义"""
        return {
            "异常值处理": {
                "价格跳变": "如果价格变化>20%，标记为异常并使用前值",
                "负价格": "期权价格<0时，使用理论下限max(S-K, 0)",
                "时间戳": "统一转换为UTC时间，处理夏令时"
            },
            "缺失值处理": {
                "前向填充": ["bid", "ask", "last"],
                "插值": ["implied_volatility"],
                "删除": ["volume=0的记录"]
            },
            "数据一致性": {
                "买卖价差": "确保bid <= ask",
                "期权平价": "检查put-call parity",
                "无套利条件": "检查butterfly spread条件"
            }
        }
    
    def _define_normalization(self):
        """数据标准化流程"""
        return {
            "价格标准化": {
                "股票": "调整分红和拆股",
                "期权": "标准化到100股单位",
                "指数": "计算总回报指数"
            },
            "时间标准化": {
                "交易时间": "美东时间9:30-16:00",
                "期权到期": "标准化到16:00 ET",
                "节假日": "使用NYSE日历"
            }
        }
    
    def _define_quality_checks(self):
        """数据质量检查标准"""
        return {
            "完整性检查": {
                "覆盖率": "每分钟至少有一个价格更新",
                "期权链": "所有行权价都有报价",
                "时间连续": "无超过1分钟的间隙"
            },
            "准确性检查": {
                "交叉验证": "多数据源对比",
                "理论边界": "期权价格在理论范围内",
                "相关性": "MSTR-BTC相关性在合理范围"
            },
            "及时性检查": {
                "延迟监控": "数据延迟<100ms",
                "更新频率": "高流动性合约每秒更新"
            }
        }
    
    def _define_greeks_engine(self):
        """Greeks计算引擎设计"""
        return {
            "一阶Greeks": {
                "Delta": {
                    "方法": "中心差分法",
                    "精度": "价格变动0.01%",
                    "调整": "考虑离散分红"
                },
                "Vega": {
                    "方法": "隐含波动率扰动1%",
                    "曲面": "考虑smile effect"
                },
                "Theta": {
                    "方法": "时间推进1天",
                    "调整": "考虑周末和假期"
                },
                "Rho": {
                    "方法": "利率扰动1bp",
                    "曲线": "使用完整收益率曲线"
                }
            },
            "二阶Greeks": {
                "Gamma": {
                    "方法": "Delta的数值导数",
                    "用途": "Pin risk管理"
                },
                "Vanna": {
                    "方法": "Delta对vol的导数",
                    "用途": "Vol-spot相关性风险"
                },
                "Volga": {
                    "方法": "Vega对vol的导数",
                    "用途": "Vol凸性风险"
                }
            },
            "聚合方法": {
                "加总": "按标的物、到期日、Greeks类型",
                "加权": "考虑相关性的组合Greeks",
                "情景": "不同市场状态下的Greeks"
            }
        }
    
    def _define_var_engine(self):
        """VaR/ES计算引擎设计"""
        return {
            "历史模拟法": {
                "窗口": "250-500交易日",
                "权重": "指数衰减权重",
                "调整": "波动率标准化"
            },
            "蒙特卡罗法": {
                "路径数": "100,000条路径",
                "时间步": "日度/小时级",
                "随机过程": {
                    "股票": "几何布朗运动 + 跳跃",
                    "波动率": "Heston模型",
                    "相关性": "动态DCC-GARCH"
                }
            },
            "参数法": {
                "分布": "学生t分布",
                "自由度": "基于历史数据估计",
                "调整": "Cornish-Fisher展开"
            },
            "压力测试": {
                "历史场景": ["2008金融危机", "2020年3月", "2022加密寒冬"],
                "假设场景": ["BTC闪崩50%", "MSTR脱钩", "流动性危机"],
                "逆向压力测试": "找到导致特定损失的场景"
            }
        }

# 部署配置
DEPLOYMENT_CONFIG = {
    "生产环境": {
        "服务器配置": {
            "计算节点": "8 cores, 32GB RAM (x4)",
            "GPU节点": "NVIDIA A100 40GB (x2)",
            "数据库服务器": "16 cores, 64GB RAM, NVMe SSD"
        },
        "网络架构": {
            "负载均衡": "HAProxy",
            "内网通信": "10Gbps以太网",
            "外网接入": "专线 + VPN备份"
        },
        "高可用设计": {
            "主从复制": "PostgreSQL streaming replication",
            "故障转移": "Keepalived + Virtual IP",
            "备份策略": "每日全量 + 每小时增量"
        }
    },
    "开发环境": {
        "容器化": "Docker Compose",
        "编排": "Kubernetes (Minikube)",
        "CI/CD": "GitLab CI + ArgoCD"
    }
}
1.2 API接口详细规范
python"""
API接口规范文档
遵循OpenAPI 3.0标准
"""

from typing import Dict, List, Optional, Union
from datetime import datetime
from pydantic import BaseModel, Field
from enum import Enum

# ============ 数据模型定义 ============

class OptionType(str, Enum):
    """期权类型枚举"""
    CALL = "CALL"
    PUT = "PUT"

class OrderType(str, Enum):
    """订单类型枚举"""
    MARKET = "MARKET"
    LIMIT = "LIMIT"
    STOP = "STOP"
    STOP_LIMIT = "STOP_LIMIT"

class RiskMetricType(str, Enum):
    """风险指标类型"""
    VAR_95 = "VAR_95"
    VAR_99 = "VAR_99"
    CVAR_95 = "CVAR_95"
    CVAR_99 = "CVAR_99"
    DELTA = "DELTA"
    GAMMA = "GAMMA"
    VEGA = "VEGA"
    THETA = "THETA"

class Position(BaseModel):
    """持仓数据模型"""
    symbol: str = Field(..., description="标的代码")
    quantity: float = Field(..., description="持仓数量")
    avg_price: float = Field(..., description="平均成本")
    market_value: float = Field(..., description="市值")
    unrealized_pnl: float = Field(..., description="未实现盈亏")
    
    # 期权特有字段
    option_type: Optional[OptionType] = None
    strike: Optional[float] = None
    expiration: Optional[datetime] = None
    underlying: Optional[str] = None

class Greeks(BaseModel):
    """Greeks数据模型"""
    position_id: str
    delta: float = Field(..., description="价格敏感度")
    gamma: float = Field(..., description="Delta变化率")
    vega: float = Field(..., description="波动率敏感度")
    theta: float = Field(..., description="时间衰减")
    rho: float = Field(..., description="利率敏感度")
    
    # 高阶Greeks
    vanna: Optional[float] = Field(None, description="Delta的Vega")
    volga: Optional[float] = Field(None, description="Vega的Vega")
    charm: Optional[float] = Field(None, description="Delta的Theta")

class RiskMetrics(BaseModel):
    """风险指标数据模型"""
    timestamp: datetime
    portfolio_value: float
    
    # VaR指标
    var_95_1d: float = Field(..., description="95%置信度1日VaR")
    var_99_1d: float = Field(..., description="99%置信度1日VaR")
    var_95_10d: float = Field(..., description="95%置信度10日VaR")
    
    # Expected Shortfall
    es_95_1d: float = Field(..., description="95%置信度1日ES")
    es_99_1d: float = Field(..., description="99%置信度1日ES")
    
    # 组合Greeks
    portfolio_delta: float
    portfolio_gamma: float
    portfolio_vega: float
    portfolio_theta: float
    
    # 集中度指标
    concentration_score: float = Field(..., ge=0, le=1)
    largest_position_pct: float
    
    # 压力测试结果
    stress_scenarios: Dict[str, float]

class PreTradeCheck(BaseModel):
    """交易前检查请求"""
    order: Dict = Field(..., description="订单详情")
    checks_requested: List[str] = Field(
        default=["position_limit", "greek_limit", "var_limit"],
        description="需要执行的检查类型"
    )

class PreTradeCheckResponse(BaseModel):
    """交易前检查响应"""
    order_id: str
    passed: bool
    checks_performed: List[Dict[str, Union[bool, str]]]
    warnings: List[str] = []
    blocks: List[str] = []
    
    # 如果通过，提供风险影响预估
    risk_impact: Optional[Dict[str, float]] = None

# ============ API端点定义 ============

class RiskManagementAPI:
    """
    风险管理系统核心API
    """
    
    def __init__(self):
        self.base_url = "/api/v1/risk"
        self.endpoints = self._define_endpoints()
    
    def _define_endpoints(self):
        """定义所有API端点"""
        return {
            # ===== 实时数据端点 =====
            "GET /positions": {
                "description": "获取当前所有持仓",
                "params": {
                    "account_id": "string",
                    "asset_class": "enum[equity, option, crypto]"
                },
                "response": List[Position],
                "cache": "1 second"
            },
            
            "GET /greeks": {
                "description": "获取实时Greeks",
                "params": {
                    "position_id": "string (optional)",
                    "aggregate": "boolean (default: false)"
                },
                "response": Union[Greeks, List[Greeks]],
                "cache": "real-time"
            },
            
            "GET /risk-metrics": {
                "description": "获取当前风险指标",
                "params": {
                    "metrics": "array[RiskMetricType]",
                    "horizon": "enum[1d, 5d, 10d, 21d]"
                },
                "response": RiskMetrics,
                "cache": "5 seconds"
            },
            
            # ===== 计算端点 =====
            "POST /calculate/var": {
                "description": "计算VaR/ES",
                "body": {
                    "positions": List[Position],
                    "confidence_levels": "array[float]",
                    "horizons": "array[int]",
                    "method": "enum[historical, monte_carlo, parametric]",
                    "scenarios": "int (MC paths, default: 100000)"
                },
                "response": {
                    "var": Dict[str, float],
                    "es": Dict[str, float],
                    "distribution": "array[float] (optional)"
                },
                "async": True
            },
            
            "POST /calculate/stress-test": {
                "description": "运行压力测试",
                "body": {
                    "scenarios": {
                        "预定义": ["2008_crisis", "flash_crash", "btc_50_drop"],
                        "自定义": {
                            "spot_change": "float",
                            "vol_change": "float",
                            "correlation_change": "float"
                        }
                    },
                    "positions": List[Position]
                },
                "response": {
                    "scenario_results": Dict[str, float],
                    "worst_case": float,
                    "recommendations": List[str]
                }
            },
            
            # ===== 交易控制端点 =====
            "POST /pre-trade-check": {
                "description": "交易前风控检查",
                "body": PreTradeCheck,
                "response": PreTradeCheckResponse,
                "sla": "< 50ms"
            },
            
            "POST /post-trade-allocation": {
                "description": "交易后风险分配",
                "body": {
                    "trade": Dict,
                    "allocation_method": "enum[pro_rata, risk_weighted]"
                },
                "response": {
                    "allocations": List[Dict],
                    "risk_impact": Dict[str, float]
                }
            },
            
            # ===== 限额管理端点 =====
            "GET /limits": {
                "description": "获取当前风险限额",
                "params": {
                    "limit_type": "enum[position, greek, var, concentration]",
                    "account": "string (optional)"
                },
                "response": {
                    "limits": List[Dict],
                    "utilization": Dict[str, float]
                }
            },
            
            "PUT /limits": {
                "description": "更新风险限额",
                "body": {
                    "limit_type": str,
                    "limit_value": float,
                    "effective_time": datetime,
                    "approval": {
                        "approver": str,
                        "approval_id": str
                    }
                },
                "response": {
                    "success": bool,
                    "new_limit": Dict
                },
                "auth": "ROLE_RISK_MANAGER"
            },
            
            # ===== 报告端点 =====
            "GET /reports/daily": {
                "description": "获取日度风险报告",
                "params": {
                    "date": "date",
                    "format": "enum[json, pdf, excel]"
                },
                "response": Union[Dict, bytes]
            },
            
            "GET /reports/pnl-attribution": {
                "description": "P&L归因分析",
                "params": {
                    "start_date": "date",
                    "end_date": "date",
                    "granularity": "enum[position, factor, greek]"
                },
                "response": {
                    "total_pnl": float,
                    "attribution": Dict[str, float],
                    "unexplained": float,
                    "chart_data": List[Dict]
                }
            },
            
            # ===== WebSocket端点 =====
            "WS /stream/risk-metrics": {
                "description": "实时风险指标流",
                "subscribe": {
                    "metrics": List[str],
                    "throttle": "int (ms, min: 100)"
                },
                "message_format": {
                    "type": "risk_update",
                    "timestamp": "ISO8601",
                    "data": RiskMetrics
                }
            },
            
            "WS /stream/alerts": {
                "description": "风险告警流",
                "subscribe": {
                    "severity": "enum[info, warning, critical]",
                    "categories": List[str]
                },
                "message_format": {
                    "type": "alert",
                    "severity": str,
                    "message": str,
                    "data": Dict,
                    "actions": List[str]
                }
            }
        }

# ============ 性能基准要求 ============

PERFORMANCE_REQUIREMENTS = {
    "API延迟要求": {
        "实时查询": {
            "p50": "< 10ms",
            "p95": "< 50ms",
            "p99": "< 100ms"
        },
        "计算密集型": {
            "VaR计算": "< 5 seconds",
            "压力测试": "< 30 seconds",
            "完整回测": "< 5 minutes"
        },
        "交易前检查": {
            "硬限制": "< 50ms",
            "软限制": "< 20ms"
        }
    },
    
    "吞吐量要求": {
        "实时Greeks更新": "10,000 updates/second",
        "交易前检查": "1,000 checks/second",
        "风险计算": "100 portfolios/minute"
    },
    
    "可用性要求": {
        "核心系统": "99.99% (52分钟/年宕机)",
        "报告系统": "99.9% (8.7小时/年宕机)",
        "RTO": "< 5 minutes",
        "RPO": "< 1 minute"
    }
}
第二部分：量化建模专家 (Quant Modeler) 详细实施方案
2.1 MSTR-BTC基差风险模型
python"""
MSTR-BTC基差风险建模
包含协整分析、动态beta、杠杆效应
"""

import numpy as np
import pandas as pd
from scipy import stats
from statsmodels.tsa.stattools import coint, adfuller
from statsmodels.api import OLS
import warnings
warnings.filterwarnings('ignore')

class MSTRBTCBasisRiskModel:
    """
    MSTR相对于BTC的基差风险模型
    考虑：
    1. 长期协整关系
    2. 短期动态调整
    3. MSTR的BTC持仓杠杆
    4. 市场情绪因素
    """
    
    def __init__(self, lookback_days=252):
        self.lookback_days = lookback_days
        self.model_params = {}
        self.diagnostics = {}
        
    def fit(self, mstr_prices: pd.Series, btc_prices: pd.Series, 
            mstr_btc_holdings: pd.Series, mstr_shares_outstanding: pd.Series):
        """
        训练基差风险模型
        
        Parameters:
        -----------
        mstr_prices: MSTR股价时间序列
        btc_prices: BTC价格时间序列  
        mstr_btc_holdings: MSTR持有的BTC数量
        mstr_shares_outstanding: MSTR流通股数
        """
        
        # 1. 计算对数收益率
        mstr_log_returns = np.log(mstr_prices / mstr_prices.shift(1))
        btc_log_returns = np.log(btc_prices / btc_prices.shift(1))
        
        # 2. 计算MSTR的内在BTC价值
        btc_value_per_share = (mstr_btc_holdings * btc_prices) / mstr_shares_outstanding
        mstr_premium = mstr_prices / btc_value_per_share - 1  # 溢价率
        
        # 3. 协整检验
        self._test_cointegration(mstr_prices, btc_prices)
        
        # 4. 动态Beta模型（DCC-GARCH）
        self._fit_dynamic_beta(mstr_log_returns, btc_log_returns)
        
        # 5. 基差均值回复模型
        self._fit_basis_mean_reversion(mstr_premium)
        
        # 6. 极端事件模型
        self._fit_tail_dependence(mstr_log_returns, btc_log_returns)
        
        # 7. 杠杆效应分析
        self._analyze_leverage_effect(mstr_prices, btc_prices, mstr_btc_holdings, 
                                     mstr_shares_outstanding)
        
        return self
    
    def _test_cointegration(self, mstr_prices, btc_prices):
        """协整关系检验"""
        
        # ADF单位根检验
        mstr_adf = adfuller(mstr_prices, maxlag=12)
        btc_adf = adfuller(btc_prices, maxlag=12)
        
        # Engle-Granger协整检验
        score, pvalue, _ = coint(mstr_prices, btc_prices)
        
        self.diagnostics['cointegration'] = {
            'mstr_stationary': mstr_adf[1] < 0.05,
            'btc_stationary': btc_adf[1] < 0.05,
            'cointegrated': pvalue < 0.05,
            'cointegration_score': score,
            'cointegration_pvalue': pvalue
        }
        
        # 如果存在协整，估计长期均衡关系
        if pvalue < 0.05:
            # Johansen检验获得协整向量
            from statsmodels.tsa.vector_ar.vecm import coint_johansen
            data = pd.DataFrame({'mstr': mstr_prices, 'btc': btc_prices})
            joh_result = coint_johansen(data, det_order=0, k_ar_diff=1)
            
            self.model_params['cointegration_vector'] = joh_result.evec[:, 0]
            self.model_params['adjustment_speed'] = joh_result.alpha[:, 0]
    
    def _fit_dynamic_beta(self, mstr_returns, btc_returns):
        """
        动态Beta估计（使用DCC-GARCH）
        """
        from arch import arch_model
        from arch.univariate import GARCH, Normal
        
        # 1. 单变量GARCH拟合
        mstr_garch = arch_model(mstr_returns.dropna(), vol='GARCH', p=1, q=1)
        mstr_fit = mstr_garch.fit(disp='off')
        
        btc_garch = arch_model(btc_returns.dropna(), vol='GARCH', p=1, q=1)
        btc_fit = btc_garch.fit(disp='off')
        
        # 2. 标准化残差
        mstr_std_resid = mstr_fit.resid / mstr_fit.conditional_volatility
        btc_std_resid = btc_fit.resid / btc_fit.conditional_volatility
        
        # 3. DCC模型估计动态相关性
        # 这里简化使用EWMA估计
        lambda_param = 0.94  # RiskMetrics参数
        
        dynamic_corr = pd.Series(index=mstr_returns.index)
        dynamic_beta = pd.Series(index=mstr_returns.index)
        
        # 初始化
        corr = mstr_std_resid.corr(btc_std_resid)
        
        for i in range(1, len(mstr_returns)):
            if pd.notna(mstr_std_resid.iloc[i]) and pd.notna(btc_std_resid.iloc[i]):
                # 更新相关性
                corr = lambda_param * corr + (1 - lambda_param) * \
                       mstr_std_resid.iloc[i] * btc_std_resid.iloc[i]
                dynamic_corr.iloc[i] = corr
                
                # 计算动态Beta
                mstr_vol = mstr_fit.conditional_volatility.iloc[i]
                btc_vol = btc_fit.conditional_volatility.iloc[i]
                dynamic_beta.iloc[i] = corr * (mstr_vol / btc_vol)
        
        self.model_params['dynamic_beta'] = dynamic_beta
        self.model_params['dynamic_correlation'] = dynamic_corr
        self.model_params['mstr_garch'] = mstr_fit
        self.model_params['btc_garch'] = btc_fit
        
    def _fit_basis_mean_reversion(self, premium_series):
        """
        基差（溢价）均值回复模型
        使用Ornstein-Uhlenbeck过程
        """
        
        # OU过程: dX_t = θ(μ - X_t)dt + σdW_t
        # 离散化: X_{t+1} = X_t + θ(μ - X_t)Δt + σ√Δt * ε_t
        
        premium_clean = premium_series.dropna()
        
        # 使用最小二乘法估计参数
        Y = premium_clean.diff().dropna()
        X = premium_clean.shift(1).dropna()[1:]
        
        # 回归: ΔX = a + b*X_{t-1} + ε
        # 其中 a = θ*μ*Δt, b = -θ*Δt
        
        model = OLS(Y, pd.DataFrame({'const': 1, 'lag': X}))
        result = model.fit()
        
        # 提取OU参数
        dt = 1/252  # 日度数据
        theta = -result.params['lag'] / dt  # 均值回复速度
        mu = result.params['const'] / (theta * dt)  # 长期均值
        sigma = result.resid.std() / np.sqrt(dt)  # 波动率
        
        # 计算半衰期
        half_life = np.log(2) / theta if theta > 0 else np.inf
        
        self.model_params['ou_process'] = {
            'mean_reversion_speed': theta,
            'long_term_mean': mu,
            'volatility': sigma,
            'half_life_days': half_life,
            'current_premium': premium_clean.iloc[-1],
            'z_score': (premium_clean.iloc[-1] - mu) / sigma
        }
        
        # 诊断统计
        self.diagnostics['mean_reversion'] = {
            'r_squared': result.rsquared,
            'durbin_watson': stats.durbin_watson(result.resid),
            'jarque_bera': stats.jarque_bera(result.resid)
        }
    
    def _fit_tail_dependence(self, mstr_returns, btc_returns):
        """
        尾部相依性建模（使用Copula）
        """
        from scipy.stats import kendalltau, spearmanr
        from scipy.stats import t as student_t
        
        # 清理数据
        returns = pd.DataFrame({
            'mstr': mstr_returns,
            'btc': btc_returns
        }).dropna()
        
        # 1. 计算秩相关系数
        kendall_tau, _ = kendalltau(returns['mstr'], returns['btc'])
        spearman_rho, _ = spearmanr(returns['mstr'], returns['btc'])
        
        # 2. 转换为均匀分布（经验CDF）
        u_mstr = returns['mstr'].rank() / (len(returns) + 1)
        u_btc = returns['btc'].rank() / (len(returns) + 1)
        
        # 3. 拟合t-Copula
        # 估计自由度（使用矩匹配）
        sample_corr = returns.corr().iloc[0, 1]
        
        # 通过MLE估计t-Copula参数
        def neg_log_likelihood(params):
            nu = params[0]  # 自由度
            if nu <= 2:
                return 1e10
            
            # 转换到t分布空间
            t_mstr = student_t.ppf(u_mstr, df=nu)
            t_btc = student_t.ppf(u_btc, df=nu)
            
            # 计算对数似然
            try:
                ll = stats.multivariate_normal.logpdf(
                    np.column_stack([t_mstr, t_btc]),
                    mean=[0, 0],
                    cov=[[1, sample_corr], [sample_corr, 1]]
                )
                return -np.sum(ll)
            except:
                return 1e10
        
        from scipy.optimize import minimize
        result = minimize(neg_log_likelihood, x0=[5], bounds=[(2.1, 30)])
        optimal_nu = result.x[0]
        
        # 4. 计算尾部相依系数
        # 对于t-Copula: λ_upper = λ_lower = 2 * t_{ν+1}(-√((ν+1)(1-ρ)/(1+ρ)))
        tail_dependence = 2 * student_t.cdf(
            -np.sqrt((optimal_nu + 1) * (1 - sample_corr) / (1 + sample_corr)),
            df=optimal_nu + 1
        )
        
        self.model_params['tail_dependence'] = {
            'kendall_tau': kendall_tau,
            'spearman_rho': spearman_rho,
            'linear_correlation': sample_corr,
            't_copula_nu': optimal_nu,
            'tail_dependence_coefficient': tail_dependence,
            'extreme_co_movement_prob': tail_dependence
        }
    
    def _analyze_leverage_effect(self, mstr_prices, btc_prices, 
                                btc_holdings, shares_outstanding):
        """
        分析MSTR的杠杆效应
        """
        
        # 1. 计算隐含杠杆
        mstr_market_cap = mstr_prices * shares_outstanding
        btc_value = btc_holdings * btc_prices
        
        # 净资产价值（假设除BTC外的资产价值）
        other_assets = mstr_market_cap.iloc[0] - btc_value.iloc[0]  # 初始值
        nav = btc_value + other_assets
        
        # 隐含杠杆 = 市值变动 / NAV变动
        mstr_returns = mstr_market_cap.pct_change()
        nav_returns = nav.pct_change()
        
        # 滚动窗口计算杠杆
        window = 20
        rolling_leverage = mstr_returns.rolling(window).std() / \
                         nav_returns.rolling(window).std()
        
        # 2. 杠杆的非对称性（上涨vs下跌）
        up_days = btc_prices.pct_change() > 0
        down_days = btc_prices.pct_change() < 0
        
        leverage_up = (mstr_returns[up_days] / nav_returns[up_days]).mean()
        leverage_down = (mstr_returns[down_days] / nav_returns[down_days]).mean()
        
        # 3. 杠杆与波动率的关系
        from scipy.stats import linregress
        btc_volatility = btc_prices.pct_change().rolling(window).std() * np.sqrt(252)
        
        # 只使用有效数据
        valid_idx = ~(rolling_leverage.isna() | btc_volatility.isna())
        if valid_idx.sum() > 10:
            slope, intercept, r_value, p_value, _ = linregress(
                btc_volatility[valid_idx], 
                rolling_leverage[valid_idx]
            )
            vol_leverage_sensitivity = slope
        else:
            vol_leverage_sensitivity = 0
        
        self.model_params['leverage'] = {
            'current_implied_leverage': rolling_leverage.iloc[-1],
            'average_leverage': rolling_leverage.mean(),
            'leverage_up_market': leverage_up,
            'leverage_down_market': leverage_down,
            'leverage_asymmetry': leverage_up - leverage_down,
            'volatility_sensitivity': vol_leverage_sensitivity,
            'btc_value_ratio': (btc_value / mstr_market_cap).iloc[-1]
        }
    
    def calculate_basis_risk_metrics(self, current_data: Dict) -> Dict:
        """
        计算当前的基差风险指标
        """
        
        metrics = {}
        
        # 1. 基差偏离度
        current_premium = current_data['mstr_premium']
        ou_params = self.model_params['ou_process']
        
        metrics['premium_z_score'] = (current_premium - ou_params['long_term_mean']) / \
                                    ou_params['volatility']
        metrics['mean_reversion_signal'] = -np.sign(metrics['premium_z_score']) * \
                                          min(abs(metrics['premium_z_score']), 3) / 3
        
        # 2. 预期回复时间和幅度
        theta = ou_params['mean_reversion_speed']
        metrics['expected_reversion_days'] = ou_params['half_life_days']
        metrics['expected_reversion_pnl'] = -(current_premium - ou_params['long_term_mean']) * \
                                           current_data['position_value']
        
        # 3. 动态对冲比率
        current_beta = self.model_params['dynamic_beta'].iloc[-1]
        leverage = self.model_params['leverage']['current_implied_leverage']
        
        metrics['hedge_ratio'] = current_beta * leverage
        metrics['beta_adjusted_exposure'] = current_data['mstr_position'] * metrics['hedge_ratio']
        
        # 4. 尾部风险
        tail_dep = self.model_params['tail_dependence']['tail_dependence_coefficient']
        metrics['extreme_loss_prob'] = tail_dep
        metrics['tail_risk_capital'] = current_data['position_value'] * tail_dep * 0.2  # 假设极端损失20%
        
        # 5. 风险预警
        warnings = []
        if abs(metrics['premium_z_score']) > 2:
            warnings.append(f"Premium deviation high: {metrics['premium_z_score']:.2f} std")
        if leverage > 2:
            warnings.append(f"High leverage detected: {leverage:.2f}x")
        if tail_dep > 0.3:
            warnings.append(f"High tail dependence: {tail_dep:.2%}")
            
        metrics['risk_warnings'] = warnings
        metrics['overall_risk_score'] = self._calculate_risk_score(metrics)
        
        return metrics
    
    def _calculate_risk_score(self, metrics: Dict) -> float:
        """
        综合风险评分 (0-100)
        """
        score = 0
        
        # 基差偏离风险 (0-30分)
        z_score_risk = min(abs(metrics['premium_z_score']) / 3, 1) * 30
        score += z_score_risk
        
        # 杠杆风险 (0-30分)  
        leverage = self.model_params['leverage']['current_implied_leverage']
        leverage_risk = min(leverage / 3, 1) * 30
        score += leverage_risk
        
        # 尾部风险 (0-20分)
        tail_risk = metrics['extreme_loss_prob'] / 0.5 * 20
        score += tail_risk
        
        # Beta不稳定性 (0-20分)
        beta_std = self.model_params['dynamic_beta'].rolling(20).std().iloc[-1]
        beta_instability = min(beta_std / 0.5, 1) * 20
        score += beta_instability
        
        return min(score, 100)

# 使用示例
if __name__ == "__main__":
    # 模拟数据生成（实际使用时替换为真实数据）
    dates = pd.date_range('2022-01-01', '2024-01-01', freq='D')
    
    # 模拟BTC价格
    btc_returns = np.random.normal(0.002, 0.04, len(dates))
    btc_prices = pd.Series(30000 * np.exp(np.cumsum(btc_returns)), index=dates)
    
    # 模拟MSTR价格（与BTC相关但有噪音）
    mstr_returns = 1.5 * btc_returns + np.random.normal(0, 0.02, len(dates))
    mstr_prices = pd.Series(400 * np.exp(np.cumsum(mstr_returns)), index=dates)
    
    # MSTR的BTC持仓
    btc_holdings = pd.Series(150000, index=dates)  # 假设固定持仓
    shares_outstanding = pd.Series(10000000, index=dates)
    
    # 训练模型
    model = MSTRBTCBasisRiskModel()
    model.fit(mstr_prices, btc_prices, btc_holdings, shares_outstanding)
    
    # 计算当前风险指标
    current_data = {
        'mstr_premium': 0.15,  # 当前溢价15%
        'position_value': 1000000,  # 100万美元MSTR持仓
        'mstr_position': 2500  # 2500股
    }
    
    risk_metrics = model.calculate_basis_risk_metrics(current_data)
    
    print("MSTR-BTC Basis Risk Metrics:")
    print("-" * 40)
    for key, value in risk_metrics.items():
        if key != 'risk_warnings':
            print(f"{key}: {value}")
    
    if risk_metrics['risk_warnings']:
        print("\nRisk Warnings:")
        for warning in risk_metrics['risk_warnings']:
            print(f"⚠️  {warning}")
2.2 波动率曲面建模
python"""
期权波动率曲面建模
使用SABR和SVI模型，特别优化for MSTR期权
"""

import numpy as np
from scipy.optimize import minimize, differential_evolution
from scipy.interpolate import RectBivariateSpline
from scipy.stats import norm
from typing import Tuple, Dict, List, Optional
import pandas as pd

class VolatilitySurfaceModel:
    """
    期权隐含波动率曲面建模
    支持：
    1. SABR模型（随机波动率）
    2. SVI模型（随机波动率启发）
    3. 动态曲面演化
    4. 套利无风险条件检查
    """
    
    def __init__(self, model_type='SVI'):
        """
        Parameters:
        -----------
        model_type: 'SABR' 或 'SVI'
        """
        self.model_type = model_type
        self.surface_params = {}
        self.calibration_errors = {}
        
    def calibrate(self, market_data: pd.DataFrame, spot: float, rate: float):
        """
        校准波动率曲面
        
        Parameters:
        -----------
        market_data: DataFrame with columns [strike, maturity, implied_vol, bid_vol, ask_vol]
        spot: 当前标的价格
        rate: 无风险利率
        """
        
        self.spot = spot
        self.rate = rate
        
        # 按到期日分组
        maturities = market_data['maturity'].unique()
        
        if self.model_type == 'SABR':
            self._calibrate_sabr(market_data, maturities)
        elif self.model_type == 'SVI':
            self._calibrate_svi(market_data, maturities)
        else:
            raise ValueError(f"Unknown model type: {self.model_type}")
        
        # 构建插值曲面
        self._build_interpolation_surface(market_data)
        
        # 检查无套利条件
        self._check_arbitrage_conditions()
        
        return self
    
    def _calibrate_svi(self, market_data: pd.DataFrame, maturities: np.ndarray):
        """
        SVI (Stochastic Volatility Inspired) 模型校准
        
        SVI参数化：
        σ²(k, T) = a + b(ρ(k-m) + sqrt((k-m)² + σ²))
        
        其中k = log(K/F)是对数货币度
        """
        
        svi_params = {}
        
        for T in maturities:
            # 筛选当期数据
            slice_data = market_data[market_data['maturity'] == T].copy()
            
            # 计算forward和log-moneyness
            forward = self.spot * np.exp(self.rate * T)
            slice_data['log_moneyness'] = np.log(slice_data['strike'] / forward)
            
            # 转换为总方差
            slice_data['total_variance'] = slice_data['implied_vol']**2 * T
            
            # SVI参数初始猜测
            atm_vol = slice_data.loc[slice_data['strike'].sub(self.spot).abs().idxmin(), 'implied_vol']
            initial_params = [
                atm_vol**2 * T * 0.9,  # a (总方差水平)
                0.1,                    # b (翼部斜率)  
                -0.1,                   # ρ (偏斜)
                0.3,                    # m (位移)
                0.2                     # σ (ATM曲率)
            ]
            
            # 约束条件（确保无套利）
            def svi_constraints(params):
                a, b, rho, m, sigma = params
                # Gatheral's条件
                constraints = []
                constraints.append(b - 0.0001)  # b >= 0
                constraints.append(1 - abs(rho) - 0.0001)  # |ρ| < 1
                constraints.append(sigma - 0.0001)  # σ > 0
                constraints.append(a + b * sigma * np.sqrt(1 - rho**2) - 0.0001)  # a + bσ√(1-ρ²) >= 0
                return constraints
            
            # 目标函数
            def objective(params):
                a, b, rho, m, sigma = params
                k = slice_data['log_moneyness'].values
                
                # SVI公式
                w = a + b * (rho * (k - m) + np.sqrt((k - m)**2 + sigma**2))
                
                # 确保正值
                w = np.maximum(w, 1e-6)
                
                # 计算隐含波动率
                model_vols = np.sqrt(w / T)
                market_vols = slice_data['implied_vol'].values
                
                # 加权误差（ATM权重更高）
                weights = np.exp(-2 * k**2)
                errors = weights * (model_vols - market_vols)**2
                
                return np.sum(errors)
            
            # 优化
            constraints = {'type': 'ineq', 'fun': svi_constraints}
            
            # 使用差分进化算法进行全局优化
            bounds = [
                (0, atm_vol**2 * T * 2),  # a
                (0, 1),                     # b
                (-0.99, 0.99),             # ρ
                (-0.5, 0.5),               # m
                (0.01, 1)                  # σ
            ]
            
            result = differential_evolution(objective, bounds, seed=42, maxiter=1000)
            
            # 精细化局部优化
            refined = minimize(objective, result.x, method='SLSQP', 
                             constraints=constraints, options={'maxiter': 1000})
            
            optimal_params = refined.x if refined.success else result.x
            
            svi_params[T] = {
                'a': optimal_params[0],
                'b': optimal_params[1],
                'rho': optimal_params[2],
                'm': optimal_params[3],
                'sigma': optimal_params[4],
                'calibration_error': objective(optimal_params),
                'forward': forward
            }
            
        self.surface_params = svi_params
    
    def _calibrate_sabr(self, market_data: pd.DataFrame, maturities: np.ndarray):
        """
        SABR模型校准
        """
        
        sabr_params = {}
        
        for T in maturities:
            slice_data = market_data[market_data['maturity'] == T]
            forward = self.spot * np.exp(self.rate * T)
            
            # SABR参数初始化
            atm_vol = slice_data.loc[slice_data['strike'].sub(forward).abs().idxmin(), 'implied_vol']
            
            initial_params = [
                atm_vol,  # α (初始波动率)
                0.3,      # β (CEV指数，通常固定)
                0.0,      # ρ (相关性)
                0.5       # ν (波动率的波动率)
            ]
            
            def objective(params):
                alpha, beta, rho, nu = params
                
                model_vols = []
                for _, row in slice_data.iterrows():
                    K = row['strike']
                    vol = self._sabr_implied_vol(forward, K, T, alpha, beta, rho, nu)
                    model_vols.append(vol)
                
                market_vols = slice_data['implied_vol'].values
                errors = np.array(model_vols) - market_vols
                
                return np.sum(errors**2)
            
            # 约束
            bounds = [
                (0.001, 1),     # α
                (0, 1),         # β  
                (-0.99, 0.99),  # ρ
                (0.001, 2)      # ν
            ]
            
            result = minimize(objective, initial_params, bounds=bounds, method='L-BFGS-B')
            
            sabr_params[T] = {
                'alpha': result.x[0],
                'beta': result.x[1],
                'rho': result.x[2],
                'nu': result.x[3],
                'calibration_error': result.fun,
                'forward': forward
            }
        
        self.surface_params = sabr_params
    
    def _sabr_implied_vol(self, F: float, K: float, T: float, 
                         alpha: float, beta: float, rho: float, nu: float) -> float:
        """
        SABR模型隐含波动率公式（Hagan近似）
        """
        
        if abs(F - K) < 1e-6:
            # ATM情况
            return alpha * (1 + (((1 - beta)**2 * alpha**2 / (24 * F**(2 - 2*beta)) + 
                                  rho * beta * nu * alpha / (4 * F**(1 - beta)) + 
                                  (2 - 3 * rho**2) * nu**2 / 24)) * T)
        
        # OTM/ITM情况
        FK = F * K
        z = nu / alpha * FK**((1 - beta) / 2) * np.log(F / K)
        x = np.log((np.sqrt(1 - 2 * rho * z + z**2) + z - rho) / (1 - rho))
        
        numerator = alpha
        denominator1 = FK**((1 - beta) / 2) * (1 + (1 - beta)**2 / 24 * np.log(F / K)**2 + 
                                               (1 - beta)**4 / 1920 * np.log(F / K)**4)
        
        term1 = (1 - beta)**2 / 24 * alpha**2 / FK**(1 - beta)
        term2 = rho * beta * nu * alpha / (4 * FK**((1 - beta) / 2))
        term3 = (2 - 3 * rho**2) / 24 * nu**2
        
        vol = numerator / denominator1 * z / x * (1 + (term1 + term2 + term3) * T)
        
        return vol
    
    def _build_interpolation_surface(self, market_data: pd.DataFrame):
        """
        构建2D插值曲面for快速查询
        """
        
        # 创建规则网格
        strikes = np.linspace(
            market_data['strike'].min() * 0.8,
            market_data['strike'].max() * 1.2,
            50
        )
        
        maturities = np.sort(market_data['maturity'].unique())
        
        # 构建曲面
        vol_surface = np.zeros((len(maturities), len(strikes)))
        
        for i, T in enumerate(maturities):
            for j, K in enumerate(strikes):
                vol_surface[i, j] = self.get_implied_vol(K, T)
        
        # 创建双线性插值器
        self.surface_interpolator = RectBivariateSpline(
            maturities, strikes, vol_surface, kx=1, ky=1
        )
        
        self.strike_range = (strikes.min(), strikes.max())
        self.maturity_range = (maturities.min(), maturities.max())
    
    def _check_arbitrage_conditions(self):
        """
        检查无套利条件
        """
        
        arbitrage_violations = []
        
        # 检查日历套利（波动率随时间递增）
        maturities = sorted(self.surface_params.keys())
        for i in range(len(maturities) - 1):
            T1, T2 = maturities[i], maturities[i + 1]
            
            # 检查ATM波动率
            atm_vol_T1 = self.get_implied_vol(self.spot, T1)
            atm_vol_T2 = self.get_implied_vol(self.spot, T2)
            
            total_var_T1 = atm_vol_T1**2 * T1
            total_var_T2 = atm_vol_T2**2 * T2
            
            if total_var_T2 < total_var_T1:
                arbitrage_violations.append({
                    'type': 'calendar',
                    'details': f'Total variance decreases from T={T1} to T={T2}'
                })
        
        # 检查蝶式套利（凸性条件）
        for T in maturities:
            strikes = np.linspace(self.spot * 0.8, self.spot * 1.2, 20)
            
            for i in range(1, len(strikes) - 1):
                K1, K2, K3 = strikes[i-1], strikes[i], strikes[i+1]
                
                if K2 - K1 == K3 - K2:  # 等距行权价
                    vol1 = self.get_implied_vol(K1, T)
                    vol2 = self.get_implied_vol(K2, T)
                    vol3 = self.get_implied_vol(K3, T)
                    
                    # 蝶式套利条件
                    butterfly_value = vol2 - 0.5 * (vol1 + vol3)
                    
                    if butterfly_value > 0.01:  # 允许小误差
                        arbitrage_violations.append({
                            'type': 'butterfly',
                            'details': f'Convexity violation at T={T}, K={K2}'
                        })
        
        self.calibration_errors['arbitrage_violations'] = arbitrage_violations
        
        if arbitrage_violations:
            print(f"⚠️ Found {len(arbitrage_violations)} arbitrage violations")
    
    def get_implied_vol(self, strike: float, maturity: float) -> float:
        """
        获取指定行权价和到期日的隐含波动率
        """
        
        if self.model_type == 'SVI':
            return self._get_svi_vol(strike, maturity)
        elif self.model_type == 'SABR':
            return self._get_sabr_vol(strike, maturity)
        else:
            # 使用插值
            if hasattr(self, 'surface_interpolator'):
                return float(self.surface_interpolator(maturity, strike)[0, 0])
            else:
                raise ValueError("Surface not calibrated")
    
    def _get_svi_vol(self, strike: float, maturity: float) -> float:
        """
        使用SVI模型计算隐含波动率
        """
        
        # 如果精确匹配到期日
        if maturity in self.surface_params:
            params = self.surface_params[maturity]
            forward = params['forward']
            k = np.log(strike / forward)
            
            # SVI公式
            w = params['a'] + params['b'] * (
                params['rho'] * (k - params['m']) + 
                np.sqrt((k - params['m'])**2 + params['sigma']**2)
            )
            
            return np.sqrt(max(w / maturity, 1e-6))
        
        # 插值between maturities
        maturities = sorted(self.surface_params.keys())
        
        if maturity <= maturities[0]:
            return self._get_svi_vol(strike, maturities[0])
        if maturity >= maturities[-1]:
            return self._get_svi_vol(strike, maturities[-1])
        
        # 线性插值
        for i in range(len(maturities) - 1):
            if maturities[i] <= maturity <= maturities[i + 1]:
                w1 = (maturities[i + 1] - maturity) / (maturities[i + 1] - maturities[i])
                w2 = 1 - w1
                
                vol1 = self._get_svi_vol(strike, maturities[i])
                vol2 = self._get_svi_vol(strike, maturities[i + 1])
                
                # 在方差空间插值
                var1 = vol1**2 * maturities[i]
                var2 = vol2**2 * maturities[i + 1]
                
                interpolated_var = w1 * var1 + w2 * var2
                return np.sqrt(interpolated_var / maturity)
        
        raise ValueError(f"Could not interpolate for maturity {maturity}")
    
    def _get_sabr_vol(self, strike: float, maturity: float) -> float:
        """
        使用SABR模型计算隐含波动率
        """
        
        if maturity in self.surface_params:
            params = self.surface_params[maturity]
            return self._sabr_implied_vol(
                params['forward'], strike, maturity,
                params['alpha'], params['beta'], 
                params['rho'], params['nu']
            )
        
        # 时间插值逻辑类似SVI
        # ...（省略重复代码）
        
    def get_local_vol(self, strike: float, maturity: float) -> float:
        """
        Dupire局部波动率
        """
        
        # 数值微分计算局部波动率
        eps_K = strike * 0.001
        eps_T = 0.01 / 365  # 约1小时
        
        # 计算偏导数
        vol = self.get_implied_vol(strike, maturity)
        vol_up = self.get_implied_vol(strike + eps_K, maturity)
        vol_down = self.get_implied_vol(strike - eps_K, maturity)
        vol_T_up = self.get_implied_vol(strike, maturity + eps_T)
        
        # 一阶导数
        dVol_dK = (vol_up - vol_down) / (2 * eps_K)
        dVol_dT = (vol_T_up - vol) / eps_T
        
        # 二阶导数
        vol_up2 = self.get_implied_vol(strike + 2*eps_K, maturity)
        d2Vol_dK2 = (vol_up2 - 2*vol_up + vol) / (eps_K**2)
        
        # Dupire公式
        d1 = (np.log(self.spot / strike) + (self.rate + 0.5 * vol**2) * maturity) / \
             (vol * np.sqrt(maturity))
        
        numerator = vol**2 + 2 * vol * maturity * (dVol_dT + self.rate * strike * dVol_dK)
        denominator = (1 + strike * d1 * dVol_dK * np.sqrt(maturity))**2 + \
                     vol * maturity * strike**2 * d2Vol_dK2
        
        local_vol = np.sqrt(numerator / denominator) if denominator > 0 else vol
        
        return local_vol
    
    def calculate_vol_metrics(self) -> Dict:
        """
        计算波动率指标
        """
        
        metrics = {}
        
        # ATM期限结构
        atm_term_structure = {}
        for T in sorted(self.surface_params.keys()):
            atm_term_structure[T] = self.get_implied_vol(self.spot, T)
        
        metrics['atm_term_structure'] = atm_term_structure
        
        # Skew指标
        T_target = 30/365  # 30天期权
        if T_target in self.surface_params or hasattr(self, 'surface_interpolator'):
            strike_90 = self.spot * 0.9
            strike_110 = self.spot * 1.1
            
            vol_90 = self.get_implied_vol(strike_90, T_target)
            vol_110 = self.get_implied_vol(strike_110, T_target)
            
            metrics['skew_90_110'] = vol_90 - vol_110
            metrics['risk_reversal'] = vol_90 - vol_110  # 25-delta approximation
        
        # 凸性指标（butterfly）
        if T_target in self.surface_params or hasattr(self, 'surface_interpolator'):
            vol_atm = self.get_implied_vol(self.spot, T_target)
            butterfly = 0.5 * (vol_90 + vol_110) - vol_atm
            metrics['butterfly_spread'] = butterfly
        
        # 波动率锥形
        strikes = np.linspace(self.spot * 0.7, self.spot * 1.3, 20)
        vol_smile = [self.get_implied_vol(K, T_target) for K in strikes]
        
        metrics['smile_range'] = max(vol_smile) - min(vol_smile)
        metrics['smile_convexity'] = np.std(vol_smile)
        
        return metrics

# 使用示例
if __name__ == "__main__":
    # 创建模拟市场数据
    np.random.seed(42)
    
    spot = 500  # MSTR当前价格
    rate = 0.05  # 无风险利率
    
    # 生成期权链数据
    strikes = np.array([400, 450, 475, 500, 525, 550, 600])
    maturities = np.array([7/365, 30/365, 60/365, 90/365])  # 天数转年
    
    market_data = []
    for T in maturities:
        for K in strikes:
            # 模拟隐含波动率（带smile）
            moneyness = np.log(K / spot)
            base_vol = 0.8  # MSTR的高波动率
            skew = -0.5 * moneyness
            smile = 0.2 * moneyness**2
            
            impl_vol = base_vol + skew + smile + np.random.normal(0, 0.02)
            impl_vol = max(impl_vol, 0.1)  # 下界
            
            market_data.append({
                'strike': K,
                'maturity': T,
                'implied_vol': impl_vol,
                'bid_vol': impl_vol - 0.01,
                'ask_vol': impl_vol + 0.01
            })
    
    market_df = pd.DataFrame(market_data)
    
    # 校准SVI模型
    svi_model = VolatilitySurfaceModel(model_type='SVI')
    svi_model.calibrate(market_df, spot, rate)
    
    # 计算波动率指标
    vol_metrics = svi_model.calculate_vol_metrics()
    
    print("Volatility Surface Metrics:")
    print("-" * 40)
    for key, value in vol_metrics.items():
        if isinstance(value, dict):
            print(f"{key}:")
            for k, v in value.items():
                print(f"  T={k:.3f}: {v:.3f}")
        else:
            print(f"{key}: {value:.4f}")
    
    # 检查套利违规
    if svi_model.calibration_errors.get('arbitrage_violations'):
        print("\n⚠️ Arbitrage Violations Detected:")
        for violation in svi_model.calibration_errors['arbitrage_violations'][:5]:
            print(f"  - {violation}")
第三部分：Greeks与实时风控专家详细实施方案
3.1 Greeks计算引擎
python"""
高性能Greeks计算引擎
支持实时计算、高阶Greeks、组合分解
"""

import numpy as np
from numba import jit, vectorize, float64
from typing import Dict, List, Tuple, Optional
import pandas as pd
from dataclasses import dataclass
from enum import Enum
from concurrent.futures import ThreadPoolExecutor
import time

class OptionStyle(Enum):
    EUROPEAN = "european"
    AMERICAN = "american"

@dataclass
class OptionContract:
    """期权合约数据结构"""
    symbol: str
    underlying: str
    strike: float
    maturity: float  # 年化
    option_type: str  # 'call' or 'put'
    style: OptionStyle = OptionStyle.AMERICAN
    position: float = 0.0
    
    # 市场数据
    spot: float = 0.0
    implied_vol: float = 0.0
    rate: float = 0.0
    div_yield: float = 0.0
    
    # 计算结果缓存
    price: Optional[float] = None
    greeks: Optional[Dict] = None
    last_update: Optional[float] = None

class GreeksEngine:
    """
    Greeks计算引擎
    特点：
    1. 使用Numba JIT加速
    2. 支持美式期权（二叉树）
    3. 缓存机制减少重复计算
    4. 并行计算多个合约
    """
    
    def __init__(self, cache_ttl: float = 0.1):
        """
        Parameters:
        -----------
        cache_ttl: 缓存有效期（秒）
        """
        self.cache_ttl = cache_ttl
        self.cache = {}
        self.executor = ThreadPoolExecutor(max_workers=8)
        
    @staticmethod
    @jit(nopython=True, cache=True)
    def _black_scholes_price(S: float, K: float, T: float, r: float, 
                            sigma: float, q: float, is_call: bool) -> float:
        """
        Black-Scholes期权定价（Numba加速）
        """
        if T <= 0:
            return max(S - K, 0) if is_call else max(K - S, 0)
        
        d1 = (np.log(S / K) + (r - q + 0.5 * sigma**2) * T) / (sigma * np.sqrt(T))
        d2 = d1 - sigma * np.sqrt(T)
        
        # 使用近似正态分布CDF（更快）
        def norm_cdf(x):
            return 0.5 * (1 + np.tanh(0.07056 * x**3 + 1.5976 * x))
        
        if is_call:
            price = S * np.exp(-q * T) * norm_cdf(d1) - K * np.exp(-r * T) * norm_cdf(d2)
        else:
            price = K * np.exp(-r * T) * norm_cdf(-d2) - S * np.exp(-q * T) * norm_cdf(-d1)
        
        return price
    
    @staticmethod
    @jit(nopython=True, cache=True)
    def _binomial_american_price(S: float, K: float, T: float, r: float,
                                sigma: float, q: float, is_call: bool, 
                                N: int = 100) -> float:
        """
        二叉树美式期权定价（Numba加速）
        """
        if T <= 0:
            return max(S - K, 0) if is_call else max(K - S, 0)
        
        dt = T / N
        u = np.exp(sigma * np.sqrt(dt))
        d = 1 / u
        p = (np.exp((r - q) * dt) - d) / (u - d)
        disc = np.exp(-r * dt)
        
        # 构建价格树
        prices = np.zeros(N + 1)
        values = np.zeros(N + 1)
        
        # 终端节点
        for i in range(N + 1):
            prices[i] = S * (u ** (N - i)) * (d ** i)
            if is_call:
                values[i] = max(prices[i] - K, 0)
            else:
                values[i] = max(K - prices[i], 0)
        
        # 反向递归
        for j in range(N - 1, -1, -1):
            for i in range(j + 1):
                prices[i] = S * (u ** (j - i)) * (d ** i)
                
                # 欧式价值
                euro_value = disc * (p * values[i] + (1 - p) * values[i + 1])
                
                # 美式价值（提前行权）
                if is_call:
                    exercise_value = prices[i] - K
                else:
                    exercise_value = K - prices[i]
                
                values[i] = max(euro_value, exercise_value)
        
        return values[0]
    
    def calculate_greeks(self, contract: OptionContract, 
                        method: str = 'auto') -> Dict[str, float]:
        """
        计算所有Greeks
        
        Parameters:
        -----------
        contract: 期权合约
        method: 'finite_difference', 'analytical', 'auto'
        """
        
        # 检查缓存
        cache_key = self._get_cache_key(contract)
        if cache_key in self.cache:
            cached_result, timestamp = self.cache[cache_key]
            if time.time() - timestamp < self.cache_ttl:
                return cached_result
        
        # 选择计算方法
        if method == 'auto':
            if contract.style == OptionStyle.EUROPEAN:
                greeks = self._analytical_greeks(contract)
            else:
                greeks = self._finite_difference_greeks(contract)
        elif method == 'analytical':
            greeks = self._analytical_greeks(contract)
        else:
            greeks = self._finite_difference_greeks(contract)
        
        # 计算高阶Greeks
        greeks.update(self._calculate_second_order_greeks(contract))
        
        # 更新缓存
        self.cache[cache_key] = (greeks, time.time())
        contract.greeks = greeks
        contract.last_update = time.time()
        
        return greeks
    
    def _analytical_greeks(self, contract: OptionContract) -> Dict[str, float]:
        """
        解析法计算Greeks（仅欧式期权）
        """
        S = contract.spot
        K = contract.strike
        T = contract.maturity
        r = contract.rate
        sigma = contract.implied_vol
        q = contract.div_yield
        is_call = contract.option_type == 'call'
        
        # 避免除零
        if T <= 0:
            return {
                'delta': 1.0 if is_call else -1.0 if S > K else 0.0,
                'gamma': 0.0,
                'vega': 0.0,
                'theta': 0.0,
                'rho': 0.0
            }
        
        # Black-Scholes Greeks
        sqrt_T = np.sqrt(T)
        d1 = (np.log(S / K) + (r - q + 0.5 * sigma**2) * T) / (sigma * sqrt_T)
        d2 = d1 - sigma * sqrt_T
        
        # 标准正态分布
        from scipy.stats import norm
        
        if is_call:
            delta = np.exp(-q * T) * norm.cdf(d1)
            theta = (-S * np.exp(-q * T) * norm.pdf(d1) * sigma / (2 * sqrt_T) -
                    r * K * np.exp(-r * T) * norm.cdf(d2) +
                    q * S * np.exp(-q * T) * norm.cdf(d1))
            rho = K * T * np.exp(-r * T) * norm.cdf(d2)
        else:
            delta = -np.exp(-q * T) * norm.cdf(-d1)
            theta = (-S * np.exp(-q * T) * norm.pdf(d1) * sigma / (2 * sqrt_T) +
                    r * K * np.exp(-r * T) * norm.cdf(-d2) -
                    q * S * np.exp(-q * T) * norm.cdf(-d1))
            rho = -K * T * np.exp(-r * T) * norm.cdf(-d2)
        
        gamma = np.exp(-q * T) * norm.pdf(d1) / (S * sigma * sqrt_T)
        vega = S * np.exp(-q * T) * norm.pdf(d1) * sqrt_T / 100  # 除以100转换为1%波动率变化
        theta = theta / 365  # 转换为每日theta
        rho = rho / 100  # 转换为1%利率变化
        
        return {
            'delta': delta,
            'gamma': gamma,
            'vega': vega,
            'theta': theta,
            'rho': rho
        }
    
    def _finite_difference_greeks(self, contract: OptionContract) -> Dict[str, float]:
        """
        有限差分法计算Greeks（支持美式期权）
        """
        
        # 基准价格
        if contract.style == OptionStyle.AMERICAN:
            price_func = self._binomial_american_price
        else:
            price_func = self._black_scholes_price
        
        S = contract.spot
        K = contract.strike
        T = contract.maturity
        r = contract.rate
        sigma = contract.implied_vol
        q = contract.div_yield
        is_call = contract.option_type == 'call'
        
        base_price = price_func(S, K, T, r, sigma, q, is_call)
        
        # Delta: ∂V/∂S
        h_S = S * 0.001
        price_up = price_func(S + h_S, K, T, r, sigma, q, is_call)
        price_down = price_func(S - h_S, K, T, r, sigma, q, is_call)
        delta = (price_up - price_down) / (2 * h_S)
        
        # Gamma: ∂²V/∂S²
        gamma = (price_up - 2 * base_price + price_down) / (h_S ** 2)
        
        # Vega: ∂V/∂σ
        h_sigma = 0.001
        price_sigma_up = price_func(S, K, T, r, sigma + h_sigma, q, is_call)
        vega = (price_sigma_up - base_price) / h_sigma / 100
        
        # Theta: ∂V/∂T
        h_T = 1 / 365  # 1天
        if T > h_T:
            price_T_down = price_func(S, K, T - h_T, r, sigma, q, is_call)
            theta = (price_T_down - base_price) / h_T / 365
        else:
            theta = 0
        
        # Rho: ∂V/∂r
        h_r = 0.0001
        price_r_up = price_func(S, K, T, r + h_r, sigma, q, is_call)
        rho = (price_r_up - base_price) / h_r / 100
        
        return {
            'delta': delta,
            'gamma': gamma,
            'vega': vega,
            'theta': theta,
            'rho': rho,
            'price': base_price
        }
    
    def _calculate_second_order_greeks(self, contract: OptionContract) -> Dict[str, float]:
        """
        计算二阶Greeks
        """
        
        # 获取基础Greeks
        if contract.greeks:
            base_greeks = contract.greeks
        else:
            base_greeks = self._finite_difference_greeks(contract)
        
        S = contract.spot
        K = contract.strike
        T = contract.maturity
        r = contract.rate
        sigma = contract.implied_vol
        q = contract.div_yield
        
        # Vanna: ∂²V/∂S∂σ (Delta对波动率的敏感度)
        h_sigma = 0.001
        contract_up = OptionContract(**contract.__dict__)
        contract_up.implied_vol = sigma + h_sigma
        greeks_up = self._finite_difference_greeks(contract_up)
        
        vanna = (greeks_up['delta'] - base_greeks['delta']) / h_sigma / 100
        
        # Volga (Vomma): ∂²V/∂σ² (Vega对波动率的敏感度)
        contract_down = OptionContract(**contract.__dict__)
        contract_down.implied_vol = sigma - h_sigma
        greeks_down = self._finite_difference_greeks(contract_down)
        
        volga = (greeks_up['vega'] - greeks_down['vega']) / (2 * h_sigma) / 100
        
        # Charm: ∂²V/∂S∂T (Delta对时间的敏感度)
        if T > 1/365:
            h_T = 1/365
            contract_T = OptionContract(**contract.__dict__)
            contract_T.maturity = T - h_T
            greeks_T = self._finite_difference_greeks(contract_T)
            
            charm = (greeks_T['delta'] - base_greeks['delta']) / h_T / 365
        else:
            charm = 0
        
        # Speed: ∂³V/∂S³ (Gamma对股价的敏感度)
        h_S = S * 0.001
        contract_S_up = OptionContract(**contract.__dict__)
        contract_S_up.spot = S + h_S
        greeks_S_up = self._finite_difference_greeks(contract_S_up)
        
        contract_S_down = OptionContract(**contract.__dict__)
        contract_S_down.spot = S - h_S
        greeks_S_down = self._finite_difference_greeks(contract_S_down)
        
        speed = (greeks_S_up['gamma'] - greeks_S_down['gamma']) / (2 * h_S)
        
        # Zomma: ∂³V/∂S²∂σ (Gamma对波动率的敏感度)
        zomma = (greeks_up['gamma'] - base_greeks['gamma']) / h_sigma / 100
        
        # Color: ∂³V/∂S²∂T (Gamma对时间的敏感度)
        if T > 1/365:
            color = (greeks_T['gamma'] - base_greeks['gamma']) / h_T / 365
        else:
            color = 0
        
        return {
            'vanna': vanna,
            'volga': volga,
            'charm': charm,
            'speed': speed,
            'zomma': zomma,
            'color': color
        }
    
    def calculate_portfolio_greeks(self, contracts: List[OptionContract],
                                  aggregation: str = 'sum') -> pd.DataFrame:
        """
        计算组合Greeks
        
        Parameters:
        -----------
        contracts: 期权合约列表
        aggregation: 聚合方式 ('sum', 'by_underlying', 'by_expiry')
        """
        
        # 并行计算各合约Greeks
        futures = []
        for contract in contracts:
            future = self.executor.submit(self.calculate_greeks, contract)
            futures.append((contract, future))
        
        # 收集结果
        results = []
        for contract, future in futures:
            greeks = future.result()
            
            result = {
                'symbol': contract.symbol,
                'underlying': contract.underlying,
                'strike': contract.strike,
                'maturity': contract.maturity,
                'type': contract.option_type,
                'position': contract.position,
                'spot': contract.spot
            }
            
            # 按持仓量调整Greeks
            for greek_name, greek_value in greeks.items():
                result[greek_name] = greek_value * contract.position
            
            results.append(result)
        
        df = pd.DataFrame(results)
        
        # 根据聚合方式处理
        if aggregation == 'sum':
            # 总体Greeks
            total_greeks = df[['delta', 'gamma', 'vega', 'theta', 'rho']].sum()
            return total_greeks
        
        elif aggregation == 'by_underlying':
            # 按标的聚合
            grouped = df.groupby('underlying')[
                ['delta', 'gamma', 'vega', 'theta', 'rho']
            ].sum()
            return grouped
        
        elif aggregation == 'by_expiry':
            # 按到期日聚合
            df['expiry_bucket'] = pd.cut(
                df['maturity'] * 365,
                bins=[0, 7, 30, 90, 180, 365, np.inf],
                labels=['<1W', '1W-1M', '1M-3M', '3M-6M', '6M-1Y', '>1Y']
            )
            grouped = df.groupby('expiry_bucket')[
                ['delta', 'gamma', 'vega', 'theta', 'rho']
            ].sum()
            return grouped
        
        else:
            # 返回详细数据
            return df
    
    def _get_cache_key(self, contract: OptionContract) -> str:
        """生成缓存键"""
        return f"{contract.symbol}_{contract.spot:.2f}_{contract.implied_vol:.4f}_{contract.rate:.4f}"
    
    def calculate_pin_risk(self, contracts: List[OptionContract]) -> pd.DataFrame:
        """
        计算Pin Risk（到期日风险）
        """
        
        pin_risks = []
        
        for contract in contracts:
            # 只关注临近到期的期权
            if contract.maturity > 7/365:  # 超过7天
                continue
            
            S = contract.spot
            K = contract.strike
            
            # 计算距离行权价的距离
            moneyness = S / K
            distance_pct = abs(1 - moneyness)
            
            # Pin risk在ATM附近最高
            if distance_pct < 0.02:  # 2%以内
                pin_risk_score = 100
            elif distance_pct < 0.05:  # 5%以内
                pin_risk_score = 50
            else:
                pin_risk_score = 10
            
            # 考虑Gamma
            greeks = self.calculate_greeks(contract)
            gamma_risk = abs(greeks['gamma'] * contract.position * S * 0.01)  # 1%股价变动的影响
            
            pin_risks.append({
                'symbol': contract.symbol,
                'days_to_expiry': contract.maturity * 365,
                'strike': K,
                'spot': S,
                'moneyness': moneyness,
                'position': contract.position,
                'gamma': greeks['gamma'],
                'pin_risk_score': pin_risk_score,
                'gamma_risk_1pct': gamma_risk,
                'action_required': pin_risk_score > 50
            })
        
        return pd.DataFrame(pin_risks)

# 实时监控系统
class RealTimeGreeksMonitor:
    """
    实时Greeks监控系统
    """
    
    def __init__(self, engine: GreeksEngine):
        self.engine = engine
        self.limits = {}
        self.alerts = []
        self.last_check = {}
        
    def set_limits(self, limits: Dict[str, Dict[str, float]]):
        """
        设置Greeks限额
        
        Example:
        limits = {
            'portfolio': {'delta': 1000, 'gamma': 500, 'vega': 10000},
            'MSTR': {'delta': 500, 'gamma': 200}
        }
        """
        self.limits = limits
    
    def check_limits(self, contracts: List[OptionContract]) -> List[Dict]:
        """
        检查限额违规
        """
        
        violations = []
        
        # 计算组合Greeks
        portfolio_greeks = self.engine.calculate_portfolio_greeks(
            contracts, aggregation='sum'
        )
        
        # 检查组合限额
        if 'portfolio' in self.limits:
            for greek, limit in self.limits['portfolio'].items():
                if greek in portfolio_greeks:
                    value = abs(portfolio_greeks[greek])
                    if value > limit:
                        violations.append({
                            'type': 'portfolio',
                            'greek': greek,
                            'value': value,
                            'limit': limit,
                            'breach_pct': (value / limit - 1) * 100,
                            'severity': 'high' if value > limit * 1.2 else 'medium'
                        })
        
        # 按标的检查
        by_underlying = self.engine.calculate_portfolio_greeks(
            contracts, aggregation='by_underlying'
        )
        
        for underlying in by_underlying.index:
            if underlying in self.limits:
                for greek, limit in self.limits[underlying].items():
                    if greek in by_underlying.columns:
                        value = abs(by_underlying.loc[underlying, greek])
                        if value > limit:
                            violations.append({
                                'type': 'underlying',
                                'underlying': underlying,
                                'greek': greek,
                                'value': value,
                                'limit': limit,
                                'breach_pct': (value / limit - 1) * 100,
                                'severity': 'high' if value > limit * 1.2 else 'medium'
                            })
        
        return violations
    
    def generate_hedge_suggestions(self, contracts: List[OptionContract],
                                  target_greeks: Dict[str, float]) -> List[Dict]:
        """
        生成对冲建议
        """
        
        suggestions = []
        
        # 当前Greeks
        current_greeks = self.engine.calculate_portfolio_greeks(
            contracts, aggregation='sum'
        )
        
        # 计算需要对冲的量
        for greek, target in target_greeks.items():
            if greek in current_greeks:
                current = current_greeks[greek]
                hedge_needed = target - current
                
                if abs(hedge_needed) > 0.01:  # 忽略很小的差异
                    # 根据不同Greek提供对冲建议
                    if greek == 'delta':
                        suggestions.append({
                            'greek': 'delta',
                            'current': current,
                            'target': target,
                            'action': 'buy' if hedge_needed > 0 else 'sell',
                            'instrument': 'underlying stock',
                            'quantity': abs(hedge_needed),
                            'alternative': f"Or use {'call' if hedge_needed > 0 else 'put'} options with appropriate delta"
                        })
                    
                    elif greek == 'gamma':
                        suggestions.append({
                            'greek': 'gamma',
                            'current': current,
                            'target': target,
                            'action': 'reduce' if abs(current) > abs(target) else 'increase',
                            'instrument': 'ATM options',
                            'strategy': 'Gamma scalping or option spreads',
                            'note': 'ATM options have highest gamma'
                        })
                    
                    elif greek == 'vega':
                        suggestions.append({
                            'greek': 'vega',
                            'current': current,
                            'target': target,
                            'action': 'buy' if hedge_needed > 0 else 'sell',
                            'instrument': 'options (preferably longer-dated)',
                            'strategy': 'Calendar spreads for vega-neutral adjustments',
                            'note': 'Longer-dated options have higher vega'
                        })
                    
                    elif greek == 'theta':
                        suggestions.append({
                            'greek': 'theta',
                            'current': current,
                            'target': target,
                            'action': 'adjust time decay exposure',
                            'instrument': 'option spreads',
                            'strategy': 'Use calendar spreads or diagonal spreads',
                            'note': 'Short-dated options have higher theta decay'
                        })
        
        return suggestions

# 使用示例
if __name__ == "__main__":
    # 创建Greeks引擎
    engine = GreeksEngine(cache_ttl=0.1)
    
    # 创建MSTR期权组合
    contracts = [
        OptionContract(
            symbol="MSTR_CALL_500_30D",
            underlying="MSTR",
            strike=500,
            maturity=30/365,
            option_type="call",
            style=OptionStyle.AMERICAN,
            position=100,
            spot=480,
            implied_vol=0.85,
            rate=0.05,
            div_yield=0
        ),
        OptionContract(
            symbol="MSTR_PUT_450_30D",
            underlying="MSTR",
            strike=450,
            maturity=30/365,
            option_type="put",
            style=OptionStyle.AMERICAN,
            position=-50,
            spot=480,
            implied_vol=0.90,
            rate=0.05,
            div_yield=0
        ),
        OptionContract(
            symbol="MSTR_CALL_520_7D",
            underlying="MSTR",
            strike=520,
            maturity=7/365,
            option_type="call",
            style=OptionStyle.AMERICAN,
            position=200,
            spot=480,
            implied_vol=0.95,
            rate=0.05,
            div_yield=0
        )
    ]
    
    # 计算组合Greeks
    portfolio_greeks = engine.calculate_portfolio_greeks(contracts)
    print("Portfolio Greeks:")
    print("-" * 40)
    print(portfolio_greeks)
    
    # Pin Risk分析
    pin_risk_df = engine.calculate_pin_risk(contracts)
    if not pin_risk_df.empty:
        print("\nPin Risk Analysis:")
        print("-" * 40)
        print(pin_risk_df[pin_risk_df['action_required']])
    
    # 设置监控系统
    monitor = RealTimeGreeksMonitor(engine)
    monitor.set_limits({
        'portfolio': {
            'delta': 500,
            'gamma': 100,
            'vega': 5000
        },
        'MSTR': {
            'delta': 300,
            'gamma': 50
        }
    })
    
    # 检查限额
    violations = monitor.check_limits(contracts)
    if violations:
        print("\n⚠️ Limit Violations:")
        print("-" * 40)
        for violation in violations:
            print(f"{violation['type']} - {violation['greek']}: "
                  f"{violation['value']:.2f} > {violation['limit']:.2f} "
                  f"({violation['breach_pct']:.1f}% breach)")
    
    # 生成对冲建议
    target_greeks = {'delta': 0, 'gamma': 0, 'vega': 1000}
    suggestions = monitor.generate_hedge_suggestions(contracts, target_greeks)
    
    if suggestions:
        print("\nHedge Suggestions:")
        print("-" * 40)
        for suggestion in suggestions:
            print(f"{suggestion['greek'].upper()}: {suggestion['action']} "
                  f"{suggestion.get('quantity', '')} {suggestion['instrument']}")
            if 'note' in suggestion:
                print(f"  Note: {suggestion['note']}")
3.2 动态对冲策略系统
python"""
动态对冲策略系统
实现自动化对冲信号生成和执行
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
import asyncio
from datetime import datetime, timedelta

class HedgeType(Enum):
    DELTA_NEUTRAL = "delta_neutral"
    GAMMA_NEUTRAL = "gamma_neutral"
    VEGA_NEUTRAL = "vega_neutral"
    DYNAMIC = "dynamic"
    TAIL_HEDGE = "tail_hedge"

@dataclass
class HedgeSignal:
    """对冲信号"""
    timestamp: datetime
    hedge_type: HedgeType
    instrument: str
    action: str  # 'buy' or 'sell'
    quantity: float
    urgency: str  # 'immediate', 'urgent', 'normal'
    reason: str
    expected_impact: Dict[str, float]
    cost_estimate: float

class DynamicHedgingStrategy:
    """
    动态对冲策略
    """
    
    def __init__(self, config: Dict):
        """
        Parameters:
        -----------
        config: 对冲策略配置
        """
        self.config = config
        self.hedge_history = []
        self.performance_metrics = {}
        
        # 对冲阈值
        self.thresholds = config.get('thresholds', {
            'delta': {'soft': 100, 'hard': 200},
            'gamma': {'soft': 50, 'hard': 100},
            'vega': {'soft': 1000, 'hard': 2000}
        })
        
        # 对冲频率限制
        self.hedge_frequency_limit = config.get('max_hedges_per_hour', 10)
        self.min_hedge_interval = config.get('min_hedge_interval_seconds', 60)
        
        # 成本参数
        self.transaction_cost = config.get('transaction_cost_bps', 10) / 10000
        self.impact_cost_model = config.get('impact_cost_model', 'linear')
    
    def generate_hedge_signals(self, 
                              current_greeks: Dict[str, float],
                              market_data: Dict,
                              portfolio_value: float) -> List[HedgeSignal]:
        """
        生成对冲信号
        """
        signals = []
        
        # 1. Delta对冲
        delta_signal = self._generate_delta_hedge(current_greeks, market_data)
        if delta_signal:
            signals.append(delta_signal)
        
        # 2. Gamma对冲
        gamma_signal = self._generate_gamma_hedge(current_greeks, market_data)
        if gamma_signal:
            signals.append(gamma_signal)
        
        # 3. Vega对冲
        vega_signal = self._generate_vega_hedge(current_greeks, market_data)
        if vega_signal:
            signals.append(vega_signal)
        
        # 4. 尾部风险对冲
        if self._should_hedge_tail_risk(market_data):
            tail_signal = self._generate_tail_hedge(portfolio_value, market_data)
            if tail_signal:
                signals.append(tail_signal)
        
        # 5. 优先级排序
        signals = self._prioritize_signals(signals)
        
        # 6. 成本效益分析
        signals = self._filter_by_cost_benefit(signals, portfolio_value)
        
        return signals
    
    def _generate_delta_hedge(self, greeks: Dict, market: Dict) -> Optional[HedgeSignal]:
        """生成Delta对冲信号"""
        
        current_delta = greeks.get('delta', 0)
        delta_limit = self.thresholds['delta']
        
        # 检查是否需要对冲
        if abs(current_delta) < delta_limit['soft']:
            return None
        
        # 确定紧急程度
        if abs(current_delta) > delta_limit['hard']:
            urgency = 'immediate'
        elif abs(current_delta) > delta_limit['soft'] * 1.5:
            urgency = 'urgent'
        else:
            urgency = 'normal'
        
        # 计算对冲数量
        hedge_ratio = self._calculate_optimal_hedge_ratio('delta', current_delta, market)
        hedge_quantity = -current_delta * hedge_ratio
        
        # 选择对冲工具
        if market.get('options_liquidity', 0) > market.get('stock_liquidity', 0) * 0.5:
            # 使用期权对冲
            instrument = self._select_optimal_option_for_delta(hedge_quantity, market)
            action = 'buy' if hedge_quantity > 0 else 'sell'
        else:
            # 使用股票对冲
            instrument = market.get('underlying_symbol', 'MSTR')
            action = 'buy' if hedge_quantity > 0 else 'sell'
        
        # 估算成本
        cost_estimate = self._estimate_hedge_cost(
            instrument, abs(hedge_quantity), market
        )
        
        return HedgeSignal(
            timestamp=datetime.now(),
            hedge_type=HedgeType.DELTA_NEUTRAL,
            instrument=instrument,
            action=action,
            quantity=abs(hedge_quantity),
            urgency=urgency,
            reason=f"Delta exposure {current_delta:.1f} exceeds {urgency} threshold",
            expected_impact={'delta': -hedge_quantity, 'cost': cost_estimate},
            cost_estimate=cost_estimate
        )
    
    def _generate_gamma_hedge(self, greeks: Dict, market: Dict) -> Optional[HedgeSignal]:
        """生成Gamma对冲信号"""
        
        current_gamma = greeks.get('gamma', 0)
        gamma_limit = self.thresholds['gamma']
        
        if abs(current_gamma) < gamma_limit['soft']:
            return None
        
        # Gamma对冲通常使用ATM期权
        spot = market.get('spot', 500)
        
        # 找到最接近ATM的期权
        available_strikes = market.get('option_chain', {}).get('strikes', [])
        if not available_strikes:
            return None
        
        atm_strike = min(available_strikes, key=lambda x: abs(x - spot))
        
        # 计算需要的期权数量
        option_gamma = self._estimate_option_gamma(atm_strike, spot, market)
        if option_gamma == 0:
            return None
        
        hedge_quantity = -current_gamma / option_gamma
        
        # 生成信号
        instrument = f"OPTION_CALL_{atm_strike}_30D"
        action = 'buy' if current_gamma < 0 else 'sell'
        
        urgency = 'urgent' if abs(current_gamma) > gamma_limit['hard'] else 'normal'
        
        cost_estimate = self._estimate_hedge_cost(
            instrument, abs(hedge_quantity), market
        )
        
        return HedgeSignal(
            timestamp=datetime.now(),
            hedge_type=HedgeType.GAMMA_NEUTRAL,
            instrument=instrument,
            action=action,
            quantity=abs(hedge_quantity),
            urgency=urgency,
            reason=f"Gamma exposure {current_gamma:.2f} exceeds threshold",
            expected_impact={
                'gamma': -current_gamma,
                'delta': option_gamma * hedge_quantity * 0.5,  # 估算Delta影响
                'cost': cost_estimate
            },
            cost_estimate=cost_estimate
        )
    
    def _generate_vega_hedge(self, greeks: Dict, market: Dict) -> Optional[HedgeSignal]:
        """生成Vega对冲信号"""
        
        current_vega = greeks.get('vega', 0)
        vega_limit = self.thresholds['vega']
        
        if abs(current_vega) < vega_limit['soft']:
            return None
        
        # Vega对冲策略：使用期限结构
        # 长期期权vega更高，可以用更少的合约对冲
        
        target_maturity = 90 if abs(current_vega) > 5000 else 30  # 天
        
        # 选择合适的期权
        spot = market.get('spot', 500)
        strike = spot  # ATM
        
        option_vega = self._estimate_option_vega(strike, spot, target_maturity/365, market)
        hedge_quantity = -current_vega / option_vega
        
        instrument = f"OPTION_STRADDLE_{strike}_{target_maturity}D"
        action = 'buy' if current_vega < 0 else 'sell'
        
        urgency = 'urgent' if abs(current_vega) > vega_limit['hard'] else 'normal'
        
        cost_estimate = self._estimate_hedge_cost(
            instrument, abs(hedge_quantity), market
        )
        
        return HedgeSignal(
            timestamp=datetime.now(),
            hedge_type=HedgeType.VEGA_NEUTRAL,
            instrument=instrument,
            action=action,
            quantity=abs(hedge_quantity),
            urgency=urgency,
            reason=f"Vega exposure {current_vega:.0f} exceeds threshold",
            expected_impact={'vega': -current_vega, 'cost': cost_estimate},
            cost_estimate=cost_estimate
        )
    
    def _should_hedge_tail_risk(self, market: Dict) -> bool:
        """判断是否需要尾部风险对冲"""
        
        # 基于市场指标
        vix = market.get('vix', 20)
        skew = market.get('option_skew', 0)
        btc_vol = market.get('btc_30d_vol', 50)
        
        # 触发条件
        triggers = [
            vix > 30,  # 高VIX
            abs(skew) > 0.2,  # 高偏斜
            btc_vol > 100,  # BTC高波动
            market.get('drawdown_5d', 0) < -0.1  # 5日回撤超10%
        ]
        
        return sum(triggers) >= 2
    
    def _generate_tail_hedge(self, portfolio_value: float, 
                            market: Dict) -> Optional[HedgeSignal]:
        """生成尾部风险对冲信号"""
        
        # 尾部对冲策略：买入OTM puts
        spot = market.get('spot', 500)
        protection_level = 0.8  # 保护80%以下的损失
        strike = spot * protection_level
        
        # 计算需要的保护
        protection_needed = portfolio_value * 0.5  # 保护50%的组合价值
        
        # 估算期权价格
        put_price = self._estimate_option_price(
            strike, spot, 30/365, 'put', market
        )
        
        if put_price <= 0:
            return None
        
        hedge_quantity = protection_needed / (strike * 100)  # 每份期权100股
        
        cost_estimate = hedge_quantity * put_price * 100
        
        return HedgeSignal(
            timestamp=datetime.now(),
            hedge_type=HedgeType.TAIL_HEDGE,
            instrument=f"OPTION_PUT_{int(strike)}_30D",
            action='buy',
            quantity=hedge_quantity,
            urgency='urgent',
            reason="Market conditions trigger tail risk protection",
            expected_impact={
                'downside_protection': protection_needed,
                'cost': cost_estimate,
                'max_profit': protection_needed - cost_estimate
            },
            cost_estimate=cost_estimate
        )
    
    def _calculate_optimal_hedge_ratio(self, greek: str, 
                                      exposure: float, 
                                      market: Dict) -> float:
        """
        计算最优对冲比率
        考虑对冲成本和残余风险的权衡
        """
        
        # 基础对冲比率
        base_ratio = 1.0
        
        # 根据市场流动性调整
        if greek == 'delta':
            liquidity = market.get('stock_liquidity', 1.0)
            if liquidity < 0.5:
                base_ratio *= 0.8  # 流动性差时减少对冲
        
        # 根据波动率调整
        current_vol = market.get('implied_vol', 0.5)
        if current_vol > 1.0:  # 高波动环境
            base_ratio *= 1.2  # 增加对冲
        elif current_vol < 0.3:  # 低波动环境
            base_ratio *= 0.9  # 减少对冲
        
        # 根据成本调整
        if self.transaction_cost > 0.002:  # 高交易成本
            base_ratio *= 0.95
        
        return min(base_ratio, 1.0)  # 不超过100%对冲
    
    def _select_optimal_option_for_delta(self, delta_needed: float, 
                                        market: Dict) -> str:
        """选择最优的期权进行Delta对冲"""
        
        spot = market.get('spot', 500)
        option_chain = market.get('option_chain', {})
        
        best_option = None
        best_cost = float('inf')
        
        for strike in option_chain.get('strikes', []):
            for expiry in option_chain.get('expiries', []):
                # 计算期权Delta
                option_delta = self._estimate_option_delta(
                    strike, spot, expiry, 'call' if delta_needed > 0 else 'put', market
                )
                
                if option_delta == 0:
                    continue
                
                # 计算需要的合约数
                contracts_needed = abs(delta_needed / option_delta)
                
                # 估算成本
                option_price = self._estimate_option_price(
                    strike, spot, expiry, 'call' if delta_needed > 0 else 'put', market
                )
                
                total_cost = contracts_needed * option_price * 100
                
                # 考虑流动性
                liquidity_factor = option_chain.get('liquidity', {}).get(
                    f"{strike}_{expiry}", 1.0
                )
                adjusted_cost = total_cost / liquidity_factor
                
                if adjusted_cost < best_cost:
                    best_cost = adjusted_cost
                    best_option = f"OPTION_{'CALL' if delta_needed > 0 else 'PUT'}_{strike}_{int(expiry*365)}D"
        
        return best_option or "MSTR"
    
    def _estimate_option_delta(self, strike: float, spot: float, 
                              expiry: float, option_type: str, 
                              market: Dict) -> float:
        """估算期权Delta"""
        
        from scipy.stats import norm
        
        vol = market.get('implied_vol', 0.8)
        rate = market.get('rate', 0.05)
        
        if expiry <= 0:
            return 0
        
        d1 = (np.log(spot / strike) + (rate + 0.5 * vol**2) * expiry) / \
             (vol * np.sqrt(expiry))
        
        if option_type == 'call':
            return norm.cdf(d1)
        else:
            return -norm.cdf(-d1)
    
    def _estimate_option_gamma(self, strike: float, spot: float, 
                              market: Dict) -> float:
        """估算期权Gamma"""
        
        from scipy.stats import norm
        
        vol = market.get('implied_vol', 0.8)
        rate = market.get('rate', 0.05)
        expiry = 30/365  # 默认30天
        
        d1 = (np.log(spot / strike) + (rate + 0.5 * vol**2) * expiry) / \
             (vol * np.sqrt(expiry))
        
        return norm.pdf(d1) / (spot * vol * np.sqrt(expiry))
    
    def _estimate_option_vega(self, strike: float, spot: float, 
                            expiry: float, market: Dict) -> float:
        """估算期权Vega"""
        
        from scipy.stats import norm
        
        vol = market.get('implied_vol', 0.8)
        rate = market.get('rate', 0.05)
        
        d1 = (np.log(spot / strike) + (rate + 0.5 * vol**2) * expiry) / \
             (vol * np.sqrt(expiry))
        
        return spot * norm.pdf(d1) * np.sqrt(expiry) / 100
    
    def _estimate_option_price(self, strike: float, spot: float, 
                              expiry: float, option_type: str, 
                              market: Dict) -> float:
        """估算期权价格"""
        
        from scipy.stats import norm
        
        vol = market.get('implied_vol', 0.8)
        rate = market.get('rate', 0.05)
        
        if expiry <= 0:
            if option_type == 'call':
                return max(spot - strike, 0)
            else:
                return max(strike - spot, 0)
        
        d1 = (np.log(spot / strike) + (rate + 0.5 * vol**2) * expiry) / \
             (vol * np.sqrt(expiry))
        d2 = d1 - vol * np.sqrt(expiry)
        
        if option_type == 'call':
            price = spot * norm.cdf(d1) - strike * np.exp(-rate * expiry) * norm.cdf(d2)
        else:
            price = strike * np.exp(-rate * expiry) * norm.cdf(-d2) - spot * norm.cdf(-d1)
        
        return price
    
    def _estimate_hedge_cost(self, instrument: str, quantity: float, 
                           market: Dict) -> float:
        """估算对冲成本"""
        
        # 交易成本
        if 'OPTION' in instrument:
            price = market.get('option_prices', {}).get(instrument, 10)
            notional = quantity * price * 100
        else:
            price = market.get('spot', 500)
            notional = quantity * price
        
        transaction_cost = notional * self.transaction_cost
        
        # 市场冲击成本
        if self.impact_cost_model == 'linear':
            daily_volume = market.get('daily_volume', 1000000)
            impact_pct = min(notional / daily_volume * 0.1, 0.01)  # 最多1%
            impact_cost = notional * impact_pct
        else:
            # 平方根模型
            impact_cost = notional * np.sqrt(notional / market.get('daily_volume', 1000000)) * 0.01
        
        # 买卖价差成本
        spread = market.get('bid_ask_spread', 0.002)
        spread_cost = notional * spread / 2
        
        return transaction_cost + impact_cost + spread_cost
    
    def _prioritize_signals(self, signals: List[HedgeSignal]) -> List[HedgeSignal]:
        """按优先级排序对冲信号"""
        
        # 优先级评分
        priority_scores = []
        
        for signal in signals:
            score = 0
            
            # 紧急程度
            if signal.urgency == 'immediate':
                score += 100
            elif signal.urgency == 'urgent':
                score += 50
            else:
                score += 10
            
            # 对冲类型
            if signal.hedge_type == HedgeType.TAIL_HEDGE:
                score += 30  # 尾部风险优先
            elif signal.hedge_type == HedgeType.DELTA_NEUTRAL:
                score += 20
            elif signal.hedge_type == HedgeType.GAMMA_NEUTRAL:
                score += 15
            else:
                score += 10
            
            # 成本效益
            impact_value = sum(abs(v) for k, v in signal.expected_impact.items() 
                             if k != 'cost')
            if impact_value > 0:
                efficiency = impact_value / (signal.cost_estimate + 1)
                score += min(efficiency * 10, 50)
            
            priority_scores.append((score, signal))
        
        # 排序
        priority_scores.sort(key=lambda x: x[0], reverse=True)
        
        return [signal for _, signal in priority_scores]
    
    def _filter_by_cost_benefit(self, signals: List[HedgeSignal], 
                               portfolio_value: float) -> List[HedgeSignal]:
        """基于成本效益分析过滤信号"""
        
        filtered = []
        
        for signal in signals:
            # 成本占比
            cost_pct = signal.cost_estimate / portfolio_value
            
            # 如果成本过高，跳过
            if cost_pct > 0.002 and signal.urgency != 'immediate':  # 0.2%
                continue
            
            # 计算风险降低价值
            risk_reduction_value = 0
            for greek, impact in signal.expected_impact.items():
                if greek != 'cost':
                    # 简化：假设每单位Greek值特定金额的风险
                    greek_values = {
                        'delta': 1,  # 每Delta $1
                        'gamma': 10,  # 每Gamma $10
                        'vega': 0.1,  # 每Vega $0.1
                    }
                    risk_reduction_value += abs(impact) * greek_values.get(greek, 0)
            
            # 成本效益比
            if risk_reduction_value > 0:
                benefit_ratio = risk_reduction_value / signal.cost_estimate
                
                # 只保留效益比大于2的信号（除非紧急）
                if benefit_ratio > 2 or signal.urgency in ['immediate', 'urgent']:
                    filtered.append(signal)
        
        return filtered

# 执行管理器
class HedgeExecutionManager:
    """
    对冲执行管理器
    """
    
    def __init__(self, strategy: DynamicHedgingStrategy):
        self.strategy = strategy
        self.execution_queue = asyncio.Queue()
        self.execution_history = []
        self.active_orders = {}
        
    async def execute_hedges(self, signals: List[HedgeSignal]):
        """异步执行对冲"""
        
        for signal in signals:
            await self.execution_queue.put(signal)
        
        # 并发执行
        tasks = []
        for _ in range(min(len(signals), 5)):  # 最多5个并发
            task = asyncio.create_task(self._execute_worker())
            tasks.append(task)
        
        await asyncio.gather(*tasks)
    
    async def _execute_worker(self):
        """执行工作器"""
        
        while True:
            try:
                signal = await asyncio.wait_for(
                    self.execution_queue.get(), 
                    timeout=1.0
                )
            except asyncio.TimeoutError:
                break
            
            try:
                result = await self._execute_single_hedge(signal)
                self.execution_history.append({
                    'signal': signal,
                    'result': result,
                    'timestamp': datetime.now()
                })
            except Exception as e:
                print(f"Execution error: {e}")
    
    async def _execute_single_hedge(self, signal: HedgeSignal) -> Dict:
        """执行单个对冲交易"""
        
        # 模拟交易执行
        await asyncio.sleep(0.1)  # 模拟网络延迟
        
        # 生成订单ID
        order_id = f"HEDGE_{datetime.now().strftime('%Y%m%d%H%M%S')}_{np.random.randint(1000)}"
        
        # 记录活动订单
        self.active_orders[order_id] = {
            'signal': signal,
            'status': 'pending',
            'timestamp': datetime.now()
        }
        
        # 模拟执行结果
        success_rate = 0.95 if signal.urgency == 'immediate' else 0.9
        
        if np.random.random() < success_rate:
            # 成功执行
            execution_price = np.random.uniform(0.99, 1.01)  # ±1%滑点
            
            result = {
                'order_id': order_id,
                'status': 'executed',
                'execution_price': execution_price,
                'actual_quantity': signal.quantity * np.random.uniform(0.98, 1.0),
                'execution_time': datetime.now(),
                'slippage': abs(1 - execution_price) * signal.cost_estimate
            }
            
            self.active_orders[order_id]['status'] = 'executed'
        else:
            # 执行失败
            result = {
                'order_id': order_id,
                'status': 'failed',
                'reason': 'Insufficient liquidity' if np.random.random() > 0.5 else 'Price moved',
                'retry_count': 0
            }
            
            self.active_orders[order_id]['status'] = 'failed'
        
        return result

# 使用示例
async def main():
    # 配置
    config = {
        'thresholds': {
            'delta': {'soft': 200, 'hard': 500},
            'gamma': {'soft': 50, 'hard': 150},
            'vega': {'soft': 2000, 'hard': 5000}
        },
        'max_hedges_per_hour': 20,
        'min_hedge_interval_seconds': 30,
        'transaction_cost_bps': 10
    }
    
    # 创建策略
    strategy = DynamicHedgingStrategy(config)
    
    # 当前Greeks（示例）
    current_greeks = {
        'delta': 450,  # 超过软限制
        'gamma': 75,   # 超过软限制
        'vega': 3000,  # 超过软限制
        'theta': -500
    }
    
    # 市场数据
    market_data = {
        'spot': 480,
        'implied_vol': 0.85,
        'rate': 0.05,
        'vix': 25,
        'option_skew': -0.15,
        'btc_30d_vol': 80,
        'stock_liquidity': 0.8,
        'options_liquidity': 0.6,
        'daily_volume': 5000000,
        'bid_ask_spread': 0.003,
        'option_chain': {
            'strikes': [450, 460, 470, 480, 490, 500, 510, 520],
            'expiries': [7/365, 30/365, 60/365, 90/365]
        }
    }
    
    # 生成对冲信号
    signals = strategy.generate_hedge_signals(
        current_greeks, 
        market_data, 
        portfolio_value=10000000  # $10M portfolio
    )
    
    print("Generated Hedge Signals:")
    print("-" * 60)
    for i, signal in enumerate(signals, 1):
        print(f"\n{i}. {signal.hedge_type.value.upper()}")
        print(f"   Instrument: {signal.instrument}")
        print(f"   Action: {signal.action} {signal.quantity:.2f}")
        print(f"   Urgency: {signal.urgency}")
        print(f"   Reason: {signal.reason}")
        print(f"   Cost Estimate: ${signal.cost_estimate:,.2f}")
        print(f"   Expected Impact: {signal.expected_impact}")
    
    # 执行对冲
    if signals:
        executor = HedgeExecutionManager(strategy)
        await executor.execute_hedges(signals[:3])  # 执行前3个信号
        
        print("\n\nExecution Results:")
        print("-" * 60)
        for record in executor.execution_history:
            result = record['result']
            signal = record['signal']
            print(f"\n{signal.hedge_type.value}: {result['status']}")
            if result['status'] == 'executed':
                print(f"   Order ID: {result['order_id']}")
                print(f"   Executed Qty: {result['actual_quantity']:.2f}")
                print(f"   Slippage: ${result['slippage']:.2f}")

if __name__ == "__main__":
    asyncio.run(main())
第四部分：数据与基础设施工程师详细实施方案
4.1 高性能数据管道
python"""
高性能实时数据管道
处理市场数据、清洗、存储和分发
"""

import asyncio
import aioredis
import asyncpg
from kafka import KafkaProducer, KafkaConsumer
from kafka.errors import KafkaError
import numpy as np
import pandas as pd
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
import json
import time
from datetime import datetime, timedelta
import logging
from collections import deque
import pickle

# 配置日志
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class MarketDataPoint:
    """市场数据点"""
    timestamp: float
    symbol: str
    price: float
    volume: float
    bid: Optional[float] = None
    ask: Optional[float] = None
    implied_vol: Optional[float] = None
    open_interest: Optional[int] = None
    
    def to_dict(self) -> Dict:
        return asdict(self)
    
    def validate(self) -> bool:
        """数据验证"""
        if self.price <= 0:
            return False
        if self.bid and self.ask and self.bid > self.ask:
            return False
        if self.implied_vol and (self.implied_vol < 0 or self.implied_vol > 10):
            return False
        return True

class DataPipeline:
    """
    高性能数据管道
    """
    
    def __init__(self, config: Dict):
        self.config = config
        self.kafka_producer = None
        self.redis_client = None
        self.postgres_pool = None
        self.data_buffer = deque(maxlen=10000)
        self.metrics = {
            'messages_processed': 0,
            'errors': 0,
            'latency_ms': deque(maxlen=1000)
        }
        
    async def initialize(self):
        """初始化连接"""
        
        # Kafka生产者
        self.kafka_producer = KafkaProducer(
            bootstrap_servers=self.config['kafka']['brokers'],
            value_serializer=lambda v: json.dumps(v).encode('utf-8'),
            compression_type='snappy',
            batch_size=16384,
            linger_ms=10
        )
        
        # Redis连接
        self.redis_client = await aioredis.create_redis_pool(
            self.config['redis']['url'],
            minsize=5,
            maxsize=10
        )
        
        # PostgreSQL连接池
        self.postgres_pool = await asyncpg.create_pool(
            **self.config['postgres'],
            min_size=10,
            max_size=20,
            command_timeout=60
        )
        
        # 创建表结构
        await self._create_tables()
        
        logger.info("Data pipeline initialized")
    
    async def _create_tables(self):
        """创建TimescaleDB表"""
        
        async with self.postgres_pool.acquire() as conn:
            # 市场数据表
            await conn.execute('''
                CREATE TABLE IF NOT EXISTS market_data (
                    time TIMESTAMPTZ NOT NULL,
                    symbol TEXT NOT NULL,
                    price DECIMAL(20, 8),
                    volume DECIMAL(20, 8),
                    bid DECIMAL(20, 8),
                    ask DECIMAL(20, 8),
                    implied_vol DECIMAL(10, 6),
                    open_interest INTEGER
                );
            ''')
            
            # 转换为超表（TimescaleDB）
            await conn.execute('''
                SELECT create_hypertable(
                    'market_data', 
                    'time',
                    if_not_exists => TRUE
                );
            ''')
            
            # 创建索引
            await conn.execute('''
                CREATE INDEX IF NOT EXISTS idx_market_data_symbol_time 
                ON market_data (symbol, time DESC);
            ''')
            
            # Greeks历史表
            await conn.execute('''
                CREATE TABLE IF NOT EXISTS greeks_history (
                    time TIMESTAMPTZ NOT NULL,
                    portfolio_id TEXT NOT NULL,
                    delta DECIMAL(20, 8),
                    gamma DECIMAL(20, 8),
                    vega DECIMAL(20, 8),
                    theta DECIMAL(20, 8),
                    rho DECIMAL(20, 8)
                );
            ''')
            
            await conn.execute('''
                SELECT create_hypertable(
                    'greeks_history', 
                    'time',
                    if_not_exists => TRUE
                );
            ''')
    
    async def process_market_data(self, raw_data: Dict) -> Optional[MarketDataPoint]:
        """
        处理原始市场数据
        """
        
        start_time = time.time()
        
        try:
            # 解析数据
            data_point = self._parse_raw_data(raw_data)
            
            # 数据清洗
            data_point = await self._clean_data(data_point)
            
            # 数据验证
            if not data_point.validate():
                logger.warning(f"Invalid data point: {data_point}")
                self.metrics['errors'] += 1
                return None
            
            # 异常检测
            if await self._detect_anomaly(data_point):
                logger.warning(f"Anomaly detected: {data_point}")
                await self._handle_anomaly(data_point)
            
            # 发送到Kafka
            await self._send_to_kafka(data_point)
            
            # 缓存到Redis
            await self._cache_to_redis(data_point)
            
            # 批量写入PostgreSQL
            self.data_buffer.append(data_point)
            if len(self.data_buffer) >= 100:
                await self._batch_write_to_postgres()
            
            # 记录延迟
            latency = (time.time() - start_time) * 1000
            self.metrics['latency_ms'].append(latency)
            self.metrics['messages_processed'] += 1
            
            return data_point
            
        except Exception as e:
            logger.error(f"Error processing data: {e}")
            self.metrics['errors'] += 1
            return None
    
    def _parse_raw_data(self, raw_data: Dict) -> MarketDataPoint:
        """解析原始数据"""
        
        # 处理不同数据源的格式差异
        if 'ticker' in raw_data:  # 格式1
            symbol = raw_data['ticker']
        elif 'symbol' in raw_data:  # 格式2
            symbol = raw_data['symbol']
        else:
            symbol = raw_data.get('s', 'UNKNOWN')
        
        # 处理时间戳
        if 'timestamp' in raw_data:
            timestamp = raw_data['timestamp']
        elif 'time' in raw_data:
            timestamp = raw_data['time']
        else:
            timestamp = time.time()
        
        # 转换为统一格式
        return MarketDataPoint(
            timestamp=timestamp,
            symbol=symbol,
            price=float(raw_data.get('price', 0)),
            volume=float(raw_data.get('volume', 0)),
            bid=float(raw_data.get('bid', 0)) if 'bid' in raw_data else None,
            ask=float(raw_data.get('ask', 0)) if 'ask' in raw_data else None,
            implied_vol=float(raw_data.get('iv', 0)) if 'iv' in raw_data else None,
            open_interest=int(raw_data.get('oi', 0)) if 'oi' in raw_data else None
        )
    
    async def _clean_data(self, data_point: MarketDataPoint) -> MarketDataPoint:
        """数据清洗"""
        
        # 处理异常价格
        if data_point.price <= 0:
            # 使用前值
            cached = await self._get_cached_price(data_point.symbol)
            if cached:
                data_point.price = cached
            else:
                data_point.price = (data_point.bid + data_point.ask) / 2 if data_point.bid and data_point.ask else 0
        
        # 处理买卖价差
        if data_point.bid and data_point.ask:
            if data_point.bid > data_point.ask:
                # 交换
                data_point.bid, data_point.ask = data_point.ask, data_point.bid
            
            # 检查价差是否合理
            spread_pct = (data_point.ask - data_point.bid) / data_point.price if data_point.price > 0 else 0
            if spread_pct > 0.1:  # 10%以上的价差
                logger.warning(f"Large spread detected: {spread_pct:.2%} for {data_point.symbol}")
        
        # 处理隐含波动率
        if data_point.implied_vol:
            # 限制在合理范围
            data_point.implied_vol = max(0.01, min(data_point.implied_vol, 5.0))
        
        return data_point
    
    async def _detect_anomaly(self, data_point: MarketDataPoint) -> bool:
        """异常检测"""
        
        # 获取历史数据
        history = await self._get_recent_history(data_point.symbol, 100)
        
        if not history:
            return False
        
        prices = [h['price'] for h in history]
        
        # 计算统计指标
        mean_price = np.mean(prices)
        std_price = np.std(prices)
        
        # Z-score检测
        if std_price > 0:
            z_score = abs((data_point.price - mean_price) / std_price)
            if z_score > 3:  # 3个标准差外
                return True
        
        # 价格跳变检测
        if len(prices) > 0:
            last_price = prices[-1]
            price_change = abs(data_point.price - last_price) / last_price
            if price_change > 0.2:  # 20%跳变
                return True
        
        return False
    
    async def _handle_anomaly(self, data_point: MarketDataPoint):
        """处理异常数据"""
        
        # 记录到专门的异常表
        async with self.postgres_pool.acquire() as conn:
            await conn.execute('''
                INSERT INTO data_anomalies (time, symbol, price, anomaly_type, raw_data)
                VALUES ($1, $2, $3, $4, $5)
            ''', 
            datetime.fromtimestamp(data_point.timestamp),
            data_point.symbol,
            data_point.price,
            'price_spike',
            json.dumps(data_point.to_dict())
            )
        
        # 发送告警
        await self._send_alert(f"Data anomaly detected for {data_point.symbol}: price={data_point.price}")
    
    async def _send_to_kafka(self, data_point: MarketDataPoint):
        """发送到Kafka"""
        
        topic = f"market_data_{data_point.symbol}"
        
        try:
            future = self.kafka_producer.send(
                topic,
                value=data_point.to_dict(),
                timestamp_ms=int(data_point.timestamp * 1000)
            )
            
            # 异步等待发送确认
            # record_metadata = await future
            
        except KafkaError as e:
            logger.error(f"Kafka error: {e}")
            raise
    
    async def _cache_to_redis(self, data_point: MarketDataPoint):
        """缓存到Redis"""
        
        # 最新价格
        key = f"price:{data_point.symbol}"
        await self.redis_client.setex(
            key, 
            60,  # 60秒过期
            data_point.price
        )
        
        # 时间序列（使用有序集合）
        ts_key = f"timeseries:{data_point.symbol}"
        await self.redis_client.zadd(
            ts_key,
            data_point.timestamp,
            pickle.dumps(data_point.to_dict())
        )
        
        # 保留最近1000个点
        await self.redis_client.zremrangebyrank(ts_key, 0, -1001)
        
        # 更新统计信息
        stats_key = f"stats:{data_point.symbol}"
        await self.redis_client.hincrby(stats_key, 'count')
        await self.redis_client.hset(stats_key, 'last_update', data_point.timestamp)
    
    async def _batch_write_to_postgres(self):
        """批量写入PostgreSQL"""
        
        if not self.data_buffer:
            return
        
        # 准备批量数据
        batch_data = []
        while self.data_buffer:
            data_point = self.data_buffer.popleft()
            batch_data.append((
                datetime.fromtimestamp(data_point.timestamp),
                data_point.symbol,
                data_point.price,
                data_point.volume,
                data_point.bid,
                data_point.ask,
                data_point.implied_vol,
                data_point.open_interest
            ))
        
        # 批量插入
        async with self.postgres_pool.acquire() as conn:
            await conn.executemany('''
                INSERT INTO market_data 
                (time, symbol, price, volume, bid, ask, implied_vol, open_interest)
                VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
                ON CONFLICT (time, symbol) DO UPDATE
                SET price = EXCLUDED.price,
                    volume = EXCLUDED.volume,
                    bid = EXCLUDED.bid,
                    ask = EXCLUDED.ask
            ''', batch_data)
        
        logger.info(f"Batch wrote {len(batch_data)} records to PostgreSQL")
    
    async def _get_cached_price(self, symbol: str) -> Optional[float]:
        """获取缓存价格"""
        
        key = f"price:{symbol}"
        price = await self.redis_client.get(key)
        return float(price) if price else None
    
    async def _get_recent_history(self, symbol: str, limit: int) -> List[Dict]:
        """获取最近历史"""
        
        # 先尝试Redis
        ts_key = f"timeseries:{symbol}"
        data = await self.redis_client.zrevrange(ts_key, 0, limit - 1)
        
        if data:
            return [pickle.loads(d) for d in data]
        
        # 否则查询PostgreSQL
        async with self.postgres_pool.acquire() as conn:
            rows = await conn.fetch('''
                SELECT time, price, volume
                FROM market_data
                WHERE symbol = $1
                ORDER BY time DESC
                LIMIT $2
            ''', symbol, limit)
            
            return [{'price': row['price'], 'time': row['time']} for row in rows]
    
    async def _send_alert(self, message: str):
        """发送告警"""
        
        # 这里可以集成告警系统（如PagerDuty、Slack等）
        logger.warning(f"ALERT: {message}")
        
        # 写入告警表
        async with self.postgres_pool.acquire() as conn:
            await conn.execute('''
                INSERT INTO alerts (time, message, severity)
                VALUES ($1, $2, $3)
            ''', datetime.now(), message, 'warning')
    
    def get_metrics(self) -> Dict:
        """获取性能指标"""
        
        latencies = list(self.metrics['latency_ms'])
        
        return {
            'messages_processed': self.metrics['messages_processed'],
            'errors': self.metrics['errors'],
            'error_rate': self.metrics['errors'] / max(self.metrics['messages_processed'], 1),
            'latency_p50': np.percentile(latencies, 50) if latencies else 0,
            'latency_p95': np.percentile(latencies, 95) if latencies else 0,
            'latency_p99': np.percentile(latencies, 99) if latencies else 0,
            'buffer_size': len(self.data_buffer)
        }

# 数据质量监控
class DataQualityMonitor:
    """
    数据质量监控系统
    """
    
    def __init__(self, pipeline: DataPipeline):
        self.pipeline = pipeline
        self.quality_metrics = {
            'completeness': deque(maxlen=1000),
            'accuracy': deque(maxlen=1000),
            'timeliness': deque(maxlen=1000),
            'consistency': deque(maxlen=1000)
        }
        
    async def check_data_quality(self, symbol: str, period: int = 3600):
        """
        检查数据质量
        
        Parameters:
        -----------
        symbol: 标的符号
        period: 检查周期（秒）
        """
        
        end_time = datetime.now()
        start_time = end_time - timedelta(seconds=period)
        
        # 获取数据
        async with self.pipeline.postgres_pool.acquire() as conn:
            rows = await conn.fetch('''
                SELECT *
                FROM market_data
                WHERE symbol = $1 AND time BETWEEN $2 AND $3
                ORDER BY time
            ''', symbol, start_time, end_time)
        
        if not rows:
            return {
                'status': 'no_data',
                'symbol': symbol,
                'period': period
            }
        
        df = pd.DataFrame(rows)
        
        # 完整性检查
        expected_points = period  # 假设每秒一个数据点
        actual_points = len(df)
        completeness = min(actual_points / expected_points, 1.0)
        self.quality_metrics['completeness'].append(completeness)
        
        # 准确性检查（通过异常值比例）
        price_z_scores = np.abs((df['price'] - df['price'].mean()) / df['price'].std())
        outlier_ratio = (price_z_scores > 3).mean()
        accuracy = 1 - outlier_ratio
        self.quality_metrics['accuracy'].append(accuracy)
        
        # 时效性检查
        df['time_diff'] = df['time'].diff().dt.total_seconds()
        avg_delay = df['time_diff'].mean()
        timeliness = 1 / (1 + avg_delay) if avg_delay else 1
        self.quality_metrics['timeliness'].append(timeliness)
        
        # 一致性检查（买卖价逻辑）
        if 'bid' in df.columns and 'ask' in df.columns:
            consistency_checks = (df['bid'] <= df['ask']).mean()
        else:
            consistency_checks = 1.0
        self.quality_metrics['consistency'].append(consistency_checks)
        
        # 计算综合质量分数
        quality_score = np.mean([
            completeness,
            accuracy,
            timeliness,
            consistency_checks
        ])
        
        return {
            'symbol': symbol,
            'period': period,
            'data_points': actual_points,
            'completeness': completeness,
            'accuracy': accuracy,
            'timeliness': timeliness,
            'consistency': consistency_checks,
            'quality_score': quality_score,
            'issues': self._identify_issues(df)
        }
    
    def _identify_issues(self, df: pd.DataFrame) -> List[str]:
        """识别数据问题"""
        
        issues = []
        
        # 检查缺失值
        missing_ratio = df.isnull().mean()
        for col, ratio in missing_ratio.items():
            if ratio > 0.1:  # 超过10%缺失
                issues.append(f"High missing rate for {col}: {ratio:.1%}")
        
        # 检查价格连续性
        price_jumps = df['price'].pct_change().abs()
        if (price_jumps > 0.1).any():  # 10%以上跳变
            issues.append(f"Price jumps detected: max={price_jumps.max():.1%}")
        
        # 检查时间间隔
        time_gaps = df['time'].diff().dt.total_seconds()
        max_gap = time_gaps.max()
        if max_gap > 60:  # 超过1分钟的间隔
            issues.append(f"Time gaps detected: max={max_gap:.0f} seconds")
        
        # 检查价格范围
        price_range = df['price'].max() / df['price'].min() if df['price'].min() > 0 else float('inf')
        if price_range > 2:  # 价格范围超过2倍
            issues.append(f"Large price range: {price_range:.1f}x")
        
        return issues
    
    def get_quality_report(self) -> Dict:
        """生成质量报告"""
        
        def safe_mean(data):
            return np.mean(list(data)) if data else 0
        
        return {
            'overall_quality': {
                'completeness': safe_mean(self.quality_metrics['completeness']),
                'accuracy': safe_mean(self.quality_metrics['accuracy']),
                'timeliness': safe_mean(self.quality_metrics['timeliness']),
                'consistency': safe_mean(self.quality_metrics['consistency'])
            },
            'recent_trend': {
                'completeness': list(self.quality_metrics['completeness'])[-10:],
                'accuracy': list(self.quality_metrics['accuracy'])[-10:],
            },
            'recommendations': self._generate_recommendations()
        }
    
    def _generate_recommendations(self) -> List[str]:
        """生成改进建议"""
        
        recommendations = []
        
        # 基于质量指标
        if self.quality_metrics['completeness']:
            avg_completeness = np.mean(list(self.quality_metrics['completeness']))
            if avg_completeness < 0.95:
                recommendations.append("Increase data collection frequency or add backup data sources")
        
        if self.quality_metrics['accuracy']:
            avg_accuracy = np.mean(list(self.quality_metrics['accuracy']))
            if avg_accuracy < 0.98:
                recommendations.append("Review and enhance anomaly detection algorithms")
        
        if self.quality_metrics['timeliness']:
            avg_timeliness = np.mean(list(self.quality_metrics['timeliness']))
            if avg_timeliness < 0.9:
                recommendations.append("Optimize data pipeline for lower latency")
        
        return recommendations

# 使用示例
async def main():
    # 配置
    config = {
        'kafka': {
            'brokers': ['localhost:9092']
        },
        'redis': {
            'url': 'redis://localhost'
        },
        'postgres': {
            'host': 'localhost',
            'port': 5432,
            'database': 'risk_db',
            'user': 'risk_user',
            'password': 'password'
        }
    }
    
    # 初始化管道
    pipeline = DataPipeline(config)
    await pipeline.initialize()
    
    # 模拟数据处理
    for i in range(100):
        raw_data = {
            'timestamp': time.time(),
            'symbol': 'MSTR',
            'price': 500 + np.random.randn() * 10,
            'volume': 100000 + np.random.randint(-10000, 10000),
            'bid': 499 + np.random.randn() * 10,
            'ask': 501 + np.random.randn() * 10,
            'iv': 0.8 + np.random.randn() * 0.1
        }
        
        await pipeline.process_market_data(raw_data)
        
        if i % 10 == 0:
            metrics = pipeline.get_metrics()
            print(f"Processed: {metrics['messages_processed']}, "
                  f"Errors: {metrics['errors']}, "
                  f"Latency P95: {metrics['latency_p95']:.2f}ms")
    
    # 数据质量检查
    monitor = DataQualityMonitor(pipeline)
    quality_report = await monitor.check_data_quality('MSTR', 3600)
    
    print("\nData Quality Report:")
    print("-" * 60)
    print(f"Quality Score: {quality_report['quality_score']:.2%}")
    print(f"Completeness: {quality_report['completeness']:.2%}")
    print(f"Accuracy: {quality_report['accuracy']:.2%}")
    print(f"Timeliness: {quality_report['timeliness']:.2%}")
    
    if quality_report['issues']:
        print("\nIssues Detected:")
        for issue in quality_report['issues']:
            print(f"  - {issue}")

if __name__ == "__main__":
    asyncio.run(main())
第五部分：模型验证与治理专家详细实施方案
5.1 回测框架与模型验证
python"""
专业级回测框架和模型验证系统
包含Walk-forward分析、模型衰减监测、性能归因
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Callable
from dataclasses import dataclass
from datetime import datetime, timedelta
from scipy import stats
from sklearn.metrics import mean_squared_error, mean_absolute_error
import warnings
warnings.filterwarnings('ignore')

@dataclass
class BacktestConfig:
    """回测配置"""
    start_date: datetime
    end_date: datetime
    initial_capital: float
    lookback_window: int  # 训练窗口（天）
    rebalance_frequency: int  # 再平衡频率（天）
    walk_forward_window: int  # Walk-forward窗口（天）
    transaction_cost: float  # 交易成本（基点）
    slippage_model: str  # 滑点模型类型
    
class ModelBacktester:
    """
    专业级模型回测系统
    """
    
    def __init__(self, config: BacktestConfig):
        self.config = config
        self.results = {}
        self.model_performance = {}
        self.validation_metrics = {}
        
    def run_backtest(self, model: Any, data: pd.DataFrame, 
                    strategy: Callable) -> Dict:
        """
        运行完整回测
        
        Parameters:
        -----------
        model: 风险模型
        data: 历史数据
        strategy: 交易策略函数
        """
        
        # 1. Walk-forward分析
        wf_results = self._walk_forward_analysis(model, data, strategy)
        
        # 2. Out-of-sample测试
        oos_results = self._out_of_sample_test(model, data, strategy)
        
        # 3. 模型稳定性测试
        stability_results = self._test_model_stability(model, data)
        
        # 4. 性能归因
        attribution = self._performance_attribution(wf_results)
        
        # 5. 统计检验
        statistical_tests = self._run_statistical_tests(wf_results, oos_results)
        
        return {
            'walk_forward': wf_results,
            'out_of_sample': oos_results,
            'stability': stability_results,
            'attribution': attribution,
            'statistical_tests': statistical_tests,
            'summary': self._generate_summary(wf_results, oos_results)
        }
    
    def _walk_forward_analysis(self, model: Any, data: pd.DataFrame, 
                              strategy: Callable) -> Dict:
        """
        Walk-forward分析
        """
        
        results = []
        window_size = self.config.lookback_window
        step_size = self.config.walk_forward_window
        
        # 滚动窗口
        for i in range(0, len(data) - window_size - step_size, step_size):
            # 训练窗口
            train_start = i
            train_end = i + window_size
            train_data = data.iloc[train_start:train_end]
            
            # 测试窗口
            test_start = train_end
            test_end = min(train_end + step_size, len(data))
            test_data = data.iloc[test_start:test_end]
            
            # 训练模型
            model.fit(train_data)
            
            # 在测试集上运行策略
            window_result = self._run_strategy_on_window(
                model, test_data, strategy
            )
            
            window_result['train_period'] = (
                train_data.index[0], train_data.index[-1]
            )
            window_result['test_period'] = (
                test_data.index[0], test_data.index[-1]
            )
            
            results.append(window_result)
        
        # 聚合结果
        return self._aggregate_window_results(results)
    
    def _run_strategy_on_window(self, model: Any, data: pd.DataFrame,
                               strategy: Callable) -> Dict:
        """
        在单个窗口上运行策略
        """
        
        portfolio_value = [self.config.initial_capital]
        positions = []
        trades = []
        risk_metrics = []
        
        for i in range(len(data)):
            current_data = data.iloc[:i+1]
            
            # 获取模型预测
            predictions = model.predict(current_data)
            
            # 计算风险指标
            risk = self._calculate_risk_metrics(model, current_data)
            risk_metrics.append(risk)
            
            # 生成交易信号
            signal = strategy(predictions, risk, current_data)
            
            # 执行交易
            if signal['action'] != 'hold':
                trade = self._execute_trade(
                    signal, 
                    portfolio_value[-1],
                    current_data.iloc[-1]
                )
                trades.append(trade)
                
                # 更新持仓
                positions = self._update_positions(positions, trade)
            
            # 计算组合价值
            new_value = self._calculate_portfolio_value(
                positions, current_data.iloc[-1], portfolio_value[-1]
            )
            portfolio_value.append(new_value)
        
        # 计算性能指标
        returns = pd.Series(portfolio_value).pct_change().dropna()
        
        return {
            'portfolio_value': portfolio_value,
            'returns': returns,
            'trades': trades,
            'risk_metrics': risk_metrics,
            'sharpe_ratio': self._calculate_sharpe_ratio(returns),
            'max_drawdown': self._calculate_max_drawdown(portfolio_value),
            'win_rate': self._calculate_win_rate(trades)
        }
    
    def _calculate_risk_metrics(self, model: Any, data: pd.DataFrame) -> Dict:
        """计算风险指标"""
        
        # 使用模型计算VaR和ES
        var_95 = model.calculate_var(data, confidence=0.95)
        var_99 = model.calculate_var(data, confidence=0.99)
        es_95 = model.calculate_expected_shortfall(data, confidence=0.95)
        
        # 计算Greeks（如果适用）
        greeks = {}
        if hasattr(model, 'calculate_greeks'):
            greeks = model.calculate_greeks(data)
        
        return {
            'var_95': var_95,
            'var_99': var_99,
            'es_95': es_95,
            'greeks': greeks,
            'timestamp': data.index[-1]
        }
    
    def _execute_trade(self, signal: Dict, capital: float, 
                      market_data: pd.Series) -> Dict:
        """执行交易（含成本模型）"""
        
        # 基础执行价格
        execution_price = market_data['price']
        
        # 滑点模型
        slippage = self._calculate_slippage(
            signal['quantity'], 
            market_data
        )
        
        # 交易成本
        notional = abs(signal['quantity']) * execution_price
        transaction_cost = notional * self.config.transaction_cost / 10000
        
        # 实际执行价格
        if signal['action'] == 'buy':
            actual_price = execution_price * (1 + slippage)
        else:
            actual_price = execution_price * (1 - slippage)
        
        return {
            'timestamp': market_data.name,
            'action': signal['action'],
            'quantity': signal['quantity'],
            'execution_price': execution_price,
            'actual_price': actual_price,
            'slippage': slippage,
            'transaction_cost': transaction_cost,
            'total_cost': notional + transaction_cost
        }
    
    def _calculate_slippage(self, quantity: float, market_data: pd.Series) -> float:
        """计算滑点"""
        
        if self.config.slippage_model == 'linear':
            # 线性滑点模型
            market_impact = abs(quantity) / market_data.get('volume', 100000) * 0.001
        elif self.config.slippage_model == 'sqrt':
            # 平方根滑点模型
            market_impact = np.sqrt(abs(quantity) / market_data.get('volume', 100000)) * 0.001
        else:
            # 固定滑点
            market_impact = 0.0001
        
        # 加入随机成分
        random_component = np.random.normal(0, 0.0001)
        
        return market_impact + random_component
    
    def _out_of_sample_test(self, model: Any, data: pd.DataFrame,
                           strategy: Callable) -> Dict:
        """
        样本外测试
        """
        
        # 分割数据
        split_point = int(len(data) * 0.7)
        train_data = data.iloc[:split_point]
        test_data = data.iloc[split_point:]
        
        # 在训练集上训练模型
        model.fit(train_data)
        
        # 在测试集上评估
        test_predictions = model.predict(test_data)
        
        # 运行策略
        test_results = self._run_strategy_on_window(model, test_data, strategy)
        
        # 计算预测准确度
        if 'actual_returns' in test_data.columns:
            prediction_metrics = {
                'mse': mean_squared_error(
                    test_data['actual_returns'], 
                    test_predictions.get('returns', [])
                ),
                'mae': mean_absolute_error(
                    test_data['actual_returns'],
                    test_predictions.get('returns', [])
                ),
                'correlation': np.corrcoef(
                    test_data['actual_returns'],
                    test_predictions.get('returns', [])
                )[0, 1]
            }
        else:
            prediction_metrics = {}
        
        return {
            'test_period': (test_data.index[0], test_data.index[-1]),
            'performance': test_results,
            'prediction_metrics': prediction_metrics
        }
    
    def _test_model_stability(self, model: Any, data: pd.DataFrame) -> Dict:
        """
        测试模型稳定性
        """
        
        stability_metrics = {}
        
        # 1. 参数稳定性测试
        parameter_stability = self._test_parameter_stability(model, data)
        stability_metrics['parameter_stability'] = parameter_stability
        
        # 2. 预测稳定性测试
        prediction_stability = self._test_prediction_stability(model, data)
        stability_metrics['prediction_stability'] = prediction_stability
        
        # 3. 模型衰减测试
        decay_metrics = self._test_model_decay(model, data)
        stability_metrics['model_decay'] = decay_metrics
        
        return stability_metrics
    
    def _test_parameter_stability(self, model: Any, data: pd.DataFrame) -> Dict:
        """测试参数稳定性"""
        
        window_size = 100
        parameters_history = []
        
        for i in range(window_size, len(data), 20):
            window_data = data.iloc[i-window_size:i]
            model.fit(window_data)
            
            if hasattr(model, 'get_parameters'):
                params = model.get_parameters()
                parameters_history.append(params)
        
        # 分析参数变化
        params_df = pd.DataFrame(parameters_history)
        
        stability_scores = {}
        for col in params_df.columns:
            # 计算变异系数
            cv = params_df[col].std() / params_df[col].mean() if params_df[col].mean() != 0 else 0
            stability_scores[col] = 1 / (1 + cv)  # 转换为稳定性分数
        
        return {
            'parameter_evolution': params_df,
            'stability_scores': stability_scores,
            'overall_stability': np.mean(list(stability_scores.values()))
        }
    
    def _test_prediction_stability(self, model: Any, data: pd.DataFrame) -> Dict:
        """测试预测稳定性"""
        
        # 使用bootstrap方法
        n_bootstrap = 100
        predictions = []
        
        for _ in range(n_bootstrap):
            # 重采样
            sample_indices = np.random.choice(len(data), len(data), replace=True)
            sample_data = data.iloc[sample_indices]
            
            # 训练和预测
            model.fit(sample_data[:80])
            pred = model.predict(sample_data[80:])
            predictions.append(pred)
        
        # 分析预测的一致性
        predictions_array = np.array(predictions)
        prediction_std = np.std(predictions_array, axis=0)
        prediction_mean = np.mean(predictions_array, axis=0)
        
        # 计算预测区间
        lower_bound = np.percentile(predictions_array, 5, axis=0)
        upper_bound = np.percentile(predictions_array, 95, axis=0)
        
        return {
            'prediction_std': np.mean(prediction_std),
            'prediction_cv': np.mean(prediction_std / (prediction_mean + 1e-10)),
            'confidence_interval_width': np.mean(upper_bound - lower_bound),
            'stability_score': 1 / (1 + np.mean(prediction_std))
        }
    
    def _test_model_decay(self, model: Any, data: pd.DataFrame) -> Dict:
        """测试模型衰减"""
        
        # 训练模型
        train_size = int(len(data) * 0.5)
        model.fit(data[:train_size])
        
        # 测试不同时间范围的性能
        decay_periods = [1, 5, 10, 20, 40, 60]  # 天
        decay_metrics = []
        
        for period in decay_periods:
            if train_size + period > len(data):
                break
            
            test_data = data[train_size:train_size + period]
            predictions = model.predict(test_data)
            
            # 计算误差
            if 'actual' in test_data.columns:
                error = mean_squared_error(test_data['actual'], predictions)
            else:
                # 使用代理指标
                error = np.random.random() * period * 0.01  # 模拟衰减
            
            decay_metrics.append({
                'period': period,
                'error': error,
                'relative_error': error / (decay_metrics[0]['error'] if decay_metrics else 1)
            })
        
        # 拟合衰减曲线
        if len(decay_metrics) > 2:
            periods = [m['period'] for m in decay_metrics]
            errors = [m['error'] for m in decay_metrics]
            
            # 指数衰减拟合
            from scipy.optimize import curve_fit
            
            def exp_decay(x, a, b):
                return a * np.exp(b * x)
            
            try:
                params, _ = curve_fit(exp_decay, periods, errors, p0=[errors[0], 0.01])
                half_life = np.log(2) / abs(params[1]) if params[1] != 0 else np.inf
            except:
                half_life = np.inf
        else:
            half_life = np.inf
        
        return {
            'decay_curve': decay_metrics,
            'half_life_days': half_life,
            'recommended_retraining': min(half_life / 2, 30)  # 建议重训练周期
        }
    
    def _performance_attribution(self, results: Dict) -> Dict:
        """
        性能归因分析
        """
        
        attribution = {}
        
        # 1. 因子贡献分析
        if 'factor_exposures' in results:
            factor_contrib = self._calculate_factor_contribution(results)
            attribution['factor_contribution'] = factor_contrib
        
        # 2. 时间段分析
        period_analysis = self._analyze_by_period(results)
        attribution['period_analysis'] = period_analysis
        
        # 3. 风险调整归因
        risk_adjusted = self._risk_adjusted_attribution(results)
        attribution['risk_adjusted'] = risk_adjusted
        
        return attribution
    
    def _calculate_factor_contribution(self, results: Dict) -> Dict:
        """计算因子贡献"""
        
        # 这里需要根据具体的因子模型实现
        # 示例：分解收益来源
        
        total_return = results.get('total_return', 0)
        
        contributions = {
            'market': total_return * 0.4,  # 市场贡献
            'selection': total_return * 0.3,  # 选股贡献
            'timing': total_return * 0.2,  # 择时贡献
            'residual': total_return * 0.1  # 残差
        }
        
        return contributions
    
    def _analyze_by_period(self, results: Dict) -> Dict:
        """按时间段分析"""
        
        if 'returns' not in results:
            return {}
        
        returns = pd.Series(results['returns'])
        
        # 按市场状态分析
        analysis = {}
        
        # 牛市/熊市
        bull_returns = returns[returns > 0]
        bear_returns = returns[returns <= 0]
        
        analysis['bull_market'] = {
            'avg_return': bull_returns.mean(),
            'hit_rate': len(bull_returns) / len(returns),
            'total_contribution': bull_returns.sum()
        }
        
        analysis['bear_market'] = {
            'avg_return': bear_returns.mean(),
            'hit_rate': len(bear_returns) / len(returns),
            'total_contribution': bear_returns.sum()
        }
        
        # 高/低波动期
        rolling_vol = returns.rolling(20).std()
        median_vol = rolling_vol.median()
        
        high_vol_returns = returns[rolling_vol > median_vol]
        low_vol_returns = returns[rolling_vol <= median_vol]
        
        analysis['high_volatility'] = {
            'avg_return': high_vol_returns.mean() if len(high_vol_returns) > 0 else 0,
            'sharpe': high_vol_returns.mean() / high_vol_returns.std() if len(high_vol_returns) > 0 else 0
        }
        
        analysis['low_volatility'] = {
            'avg_return': low_vol_returns.mean() if len(low_vol_returns) > 0 else 0,
            'sharpe': low_vol_returns.mean() / low_vol_returns.std() if len(low_vol_returns) > 0 else 0
        }
        
        return analysis
    
    def _risk_adjusted_attribution(self, results: Dict) -> Dict:
        """风险调整归因"""
        
        if 'returns' not in results or 'risk_metrics' not in results:
            return {}
        
        returns = pd.Series(results['returns'])
        risk_metrics = results['risk_metrics']
        
        # 计算各种风险调整指标
        attribution = {}
        
        # Sharpe分解
        risk_free_rate = 0.02 / 252  # 日化无风险利率
        excess_returns = returns - risk_free_rate
        
        attribution['sharpe_decomposition'] = {
            'excess_return': excess_returns.mean(),
            'volatility': returns.std(),
            'sharpe_ratio': excess_returns.mean() / returns.std() if returns.std() > 0 else 0
        }
        
        # VaR调整收益
        if isinstance(risk_metrics, list) and len(risk_metrics) > 0:
            avg_var = np.mean([m.get('var_95', 0) for m in risk_metrics])
            if avg_var > 0:
                attribution['var_adjusted_return'] = returns.mean() / avg_var
        
        return attribution
    
    def _run_statistical_tests(self, wf_results: Dict, oos_results: Dict) -> Dict:
        """
        运行统计检验
        """
        
        tests = {}
        
        # 1. 正态性检验
        if 'returns' in wf_results:
            returns = wf_results['returns']
            
            # Jarque-Bera检验
            jb_stat, jb_pvalue = stats.jarque_bera(returns)
            tests['normality'] = {
                'jarque_bera_statistic': jb_stat,
                'p_value': jb_pvalue,
                'is_normal': jb_pvalue > 0.05
            }
        
        # 2. 自相关检验
        if 'returns' in wf_results:
            from statsmodels.stats.diagnostic import acorr_ljungbox
            
            lb_result = acorr_ljungbox(returns, lags=10, return_df=True)
            tests['autocorrelation'] = {
                'ljung_box_stats': lb_result['lb_stat'].tolist(),
                'p_values': lb_result['lb_pvalue'].tolist(),
                'has_autocorrelation': any(lb_result['lb_pvalue'] < 0.05)
            }
        
        # 3. 异方差检验
        if 'returns' in wf_results:
            from statsmodels.stats.diagnostic import het_white
            
            # 需要回归残差，这里简化处理
            tests['heteroskedasticity'] = {
                'test': 'White Test',
                'note': 'Requires regression residuals'
            }
        
        # 4. 结构突变检验
        if 'returns' in wf_results:
            tests['structural_break'] = self._test_structural_break(returns)
        
        return tests
    
    def _test_structural_break(self, returns: pd.Series) -> Dict:
        """检验结构突变"""
        
        # Chow Test简化版本
        n = len(returns)
        if n < 60:
            return {'test_performed': False, 'reason': 'Insufficient data'}
        
        # 分割点
        break_point = n // 2
        
        # 前后两段的统计特征
        first_half = returns[:break_point]
        second_half = returns[break_point:]
        
        # t检验：均值是否相同
        t_stat, p_value = stats.ttest_ind(first_half, second_half)
        
        # F检验：方差是否相同
        f_stat = first_half.var() / second_half.var() if second_half.var() > 0 else np.inf
        f_p_value = stats.f.cdf(f_stat, len(first_half)-1, len(second_half)-1)
        
        return {
            'break_point': break_point,
            'mean_test': {
                't_statistic': t_stat,
                'p_value': p_value,
                'means_different': p_value < 0.05
            },
            'variance_test': {
                'f_statistic': f_stat,
                'p_value': f_p_value,
                'variances_different': f_p_value < 0.05
            },
            'has_structural_break': p_value < 0.05 or f_p_value < 0.05
        }
    
    def _calculate_sharpe_ratio(self, returns: pd.Series, 
                               risk_free_rate: float = 0.02) -> float:
        """计算夏普比率"""
        
        if len(returns) == 0:
            return 0
        
        # 年化处理
        daily_rf = risk_free_rate / 252
        excess_returns = returns - daily_rf
        
        if excess_returns.std() == 0:
            return 0
        
        sharpe = excess_returns.mean() / excess_returns.std() * np.sqrt(252)
        return sharpe
    
    def _calculate_max_drawdown(self, portfolio_values: List[float]) -> float:
        """计算最大回撤"""
        
        if len(portfolio_values) < 2:
            return 0
        
        values = pd.Series(portfolio_values)
        cummax = values.cummax()
        drawdown = (values - cummax) / cummax
        
        return abs(drawdown.min())
    
    def _calculate_win_rate(self, trades: List[Dict]) -> float:
        """计算胜率"""
        
        if not trades:
            return 0
        
        winning_trades = sum(1 for t in trades if t.get('pnl', 0) > 0)
        return winning_trades / len(trades)
    
    def _aggregate_window_results(self, results: List[Dict]) -> Dict:
        """聚合窗口结果"""
        
        if not results:
            return {}
        
        # 合并所有返回
        all_returns = pd.concat([r['returns'] for r in results])
        
        # 合并所有交易
        all_trades = []
        for r in results:
            all_trades.extend(r['trades'])
        
        # 计算聚合指标
        return {
            'returns': all_returns,
            'trades': all_trades,
            'total_return': (1 + all_returns).prod() - 1,
            'annual_return': all_returns.mean() * 252,
            'annual_volatility': all_returns.std() * np.sqrt(252),
            'sharpe_ratio': self._calculate_sharpe_ratio(all_returns),
            'max_drawdown': max([r['max_drawdown'] for r in results]),
            'win_rate': self._calculate_win_rate(all_trades),
            'num_trades': len(all_trades),
            'avg_trade_return': np.mean([t.get('return', 0) for t in all_trades]) if all_trades else 0
        }
    
    def _generate_summary(self, wf_results: Dict, oos_results: Dict) -> Dict:
        """生成回测摘要"""
        
        summary = {
            'performance_metrics': {
                'walk_forward': {
                    'total_return': wf_results.get('total_return', 0),
                    'sharpe_ratio': wf_results.get('sharpe_ratio', 0),
                    'max_drawdown': wf_results.get('max_drawdown', 0),
                    'win_rate': wf_results.get('win_rate', 0)
                },
                'out_of_sample': {
                    'total_return': oos_results.get('performance', {}).get('total_return', 0),
                    'sharpe_ratio': oos_results.get('performance', {}).get('sharpe_ratio', 0)
                }
            },
            'robustness_score': self._calculate_robustness_score(wf_results, oos_results),
            'recommendation': self._generate_recommendation(wf_results, oos_results)
        }
        
        return summary
    
    def _calculate_robustness_score(self, wf_results: Dict, oos_results: Dict) -> float:
        """计算稳健性评分"""
        
        score = 0
        
        # 样本内外一致性
        if wf_results.get('sharpe_ratio', 0) > 0 and oos_results.get('performance', {}).get('sharpe_ratio', 0) > 0:
            consistency = min(
                oos_results.get('performance', {}).get('sharpe_ratio', 0) / 
                wf_results.get('sharpe_ratio', 1), 
                1
            )
            score += consistency * 40
        
        # 回撤控制
        if wf_results.get('max_drawdown', 1) < 0.2:  # 最大回撤小于20%
            score += 30
        elif wf_results.get('max_drawdown', 1) < 0.3:
            score += 20
        
        # 交易频率合理性
        num_trades = wf_results.get('num_trades', 0)
        if 10 < num_trades < 1000:  # 合理的交易次数
            score += 20
        
        # 胜率
        if wf_results.get('win_rate', 0) > 0.5:
            score += 10
        
        return min(score, 100)
    
    def _generate_recommendation(self, wf_results: Dict, oos_results: Dict) -> str:
        """生成建议"""
        
        robustness = self._calculate_robustness_score(wf_results, oos_results)
        
        if robustness > 80:
            return "Model shows strong performance. Ready for production deployment."
        elif robustness > 60:
            return "Model shows good performance. Consider minor optimizations before deployment."
        elif robustness > 40:
            return "Model needs improvement. Review feature engineering and parameter tuning."
        else:
            return "Model performance is weak. Significant redesign recommended."

# P&L归因分析系统
class PnLAttributionSystem:
    """
    P&L归因分析系统
    """
    
    def __init__(self):
        self.attribution_history = []
        self.unexplained_threshold = 0.02  # 2%的未解释P&L阈值
        
    def attribute_pnl(self, portfolio_data: Dict, market_data: Dict,
                     model_params: Dict) -> Dict:
        """
        执行P&L归因
        """
        
        # 计算实际P&L
        actual_pnl = self._calculate_actual_pnl(portfolio_data)
        
        # 分解P&L来源
        attribution = {}
        
        # 1. 市场风险归因
        market_attribution = self._attribute_market_risk(
            portfolio_data, market_data
        )
        attribution['market'] = market_attribution
        
        # 2. Greeks归因
        greeks_attribution = self._attribute_greeks(
            portfolio_data, market_data
        )
        attribution['greeks'] = greeks_attribution
        
        # 3. 基差风险归因
        basis_attribution = self._attribute_basis_risk(
            portfolio_data, market_data
        )
        attribution['basis'] = basis_attribution
        
        # 4. 波动率归因
        vol_attribution = self._attribute_volatility(
            portfolio_data, market_data
        )
        attribution['volatility'] = vol_attribution
        
        # 5. 交易成本归因
        cost_attribution = self._attribute_costs(portfolio_data)
        attribution['costs'] = cost_attribution
        
        # 计算未解释P&L
        explained_pnl = sum([
            attribution[k]['pnl'] for k in attribution 
            if 'pnl' in attribution[k]
        ])
        
        unexplained_pnl = actual_pnl - explained_pnl
        unexplained_pct = abs(unexplained_pnl / actual_pnl) if actual_pnl != 0 else 0
        
        # 如果未解释部分过大，进行深度分析
        if unexplained_pct > self.unexplained_threshold:
            deep_analysis = self._deep_dive_unexplained(
                unexplained_pnl, portfolio_data, market_data
            )
            attribution['deep_analysis'] = deep_analysis
        
        return {
            'actual_pnl': actual_pnl,
            'attribution': attribution,
            'unexplained_pnl': unexplained_pnl,
            'unexplained_pct': unexplained_pct,
            'quality_score': 1 - unexplained_pct,
            'timestamp': datetime.now()
        }
    
    def _calculate_actual_pnl(self, portfolio_data: Dict) -> float:
        """计算实际P&L"""
        
        return portfolio_data.get('current_value', 0) - \
               portfolio_data.get('previous_value', 0)
    
    def _attribute_market_risk(self, portfolio_data: Dict, 
                              market_data: Dict) -> Dict:
        """市场风险归因"""
        
        pnl = 0
        details = []
        
        # QQQ部分
        if 'QQQ_position' in portfolio_data:
            qqq_delta = portfolio_data['QQQ_position']
            qqq_return = market_data.get('QQQ_return', 0)
            qqq_pnl = qqq_delta * qqq_return * portfolio_data.get('QQQ_price', 500)
            
            pnl += qqq_pnl
            details.append({
                'factor': 'QQQ',
                'exposure': qqq_delta,
                'factor_return': qqq_return,
                'contribution': qqq_pnl
            })
        
        # MSTR股价部分
        if 'MSTR_delta' in portfolio_data:
            mstr_delta = portfolio_data['MSTR_delta']
            mstr_return = market_data.get('MSTR_return', 0)
            mstr_pnl = mstr_delta * mstr_return * portfolio_data.get('MSTR_price', 500)
            
            pnl += mstr_pnl
            details.append({
                'factor': 'MSTR',
                'exposure': mstr_delta,
                'factor_return': mstr_return,
                'contribution': mstr_pnl
            })
        
        # BTC关联部分
        if 'BTC_exposure' in portfolio_data:
            btc_exposure = portfolio_data['BTC_exposure']
            btc_return = market_data.get('BTC_return', 0)
            btc_pnl = btc_exposure * btc_return
            
            pnl += btc_pnl
            details.append({
                'factor': 'BTC',
                'exposure': btc_exposure,
                'factor_return': btc_return,
                'contribution': btc_pnl
            })
        
        return {
            'pnl': pnl,
            'details': details,
            'summary': f"Market risk contributed ${pnl:,.2f}"
        }
    
    def _attribute_greeks(self, portfolio_data: Dict, 
                         market_data: Dict) -> Dict:
        """Greeks归因"""
        
        pnl = 0
        details = {}
        
        # Delta归因
        if 'delta' in portfolio_data:
            spot_change = market_data.get('spot_change', 0)
            delta_pnl = portfolio_data['delta'] * spot_change
            pnl += delta_pnl
            details['delta'] = {
                'exposure': portfolio_data['delta'],
                'market_move': spot_change,
                'pnl': delta_pnl
            }
        
        # Gamma归因
        if 'gamma' in portfolio_data:
            gamma_pnl = 0.5 * portfolio_data['gamma'] * spot_change ** 2
            pnl += gamma_pnl
            details['gamma'] = {
                'exposure': portfolio_data['gamma'],
                'market_move_squared': spot_change ** 2,
                'pnl': gamma_pnl
            }
        
        # Vega归因
        if 'vega' in portfolio_data:
            vol_change = market_data.get('vol_change', 0)
            vega_pnl = portfolio_data['vega'] * vol_change * 100  # vol in %
            pnl += vega_pnl
            details['vega'] = {
                'exposure': portfolio_data['vega'],
                'vol_change': vol_change,
                'pnl': vega_pnl
            }
        
        # Theta归因
        if 'theta' in portfolio_data:
            theta_pnl = portfolio_data['theta']  # 每日theta
            pnl += theta_pnl
            details['theta'] = {
                'exposure': portfolio_data['theta'],
                'days': 1,
                'pnl': theta_pnl
            }
        
        return {
            'pnl': pnl,
            'details': details,
            'summary': f"Greeks contributed ${pnl:,.2f}"
        }
    
    def _attribute_basis_risk(self, portfolio_data: Dict,
                             market_data: Dict) -> Dict:
        """基差风险归因"""
        
        pnl = 0
        
        if 'mstr_premium' in portfolio_data:
            premium_change = market_data.get('premium_change', 0)
            basis_exposure = portfolio_data.get('mstr_position_value', 0)
            
            pnl = basis_exposure * premium_change
        
        return {
            'pnl': pnl,
            'premium_change': market_data.get('premium_change', 0),
            'summary': f"Basis risk contributed ${pnl:,.2f}"
        }
    
    def _attribute_volatility(self, portfolio_data: Dict,
                             market_data: Dict) -> Dict:
        """波动率归因"""
        
        pnl = 0
        details = {}
        
        # 隐含波动率变化
        if 'iv_exposure' in portfolio_data:
            iv_change = market_data.get('iv_change', 0)
            iv_pnl = portfolio_data['iv_exposure'] * iv_change
            pnl += iv_pnl
            details['implied_vol'] = {
                'change': iv_change,
                'pnl': iv_pnl
            }
        
        # 实现波动率vs隐含波动率
        if 'vol_arb_position' in portfolio_data:
            rv_iv_spread = market_data.get('realized_vol', 0) - market_data.get('implied_vol', 0)
            vol_arb_pnl = portfolio_data['vol_arb_position'] * rv_iv_spread * 100
            pnl += vol_arb_pnl
            details['vol_arbitrage'] = {
                'rv_iv_spread': rv_iv_spread,
                'pnl': vol_arb_pnl
            }
        
        return {
            'pnl': pnl,
            'details': details,
            'summary': f"Volatility contributed ${pnl:,.2f}"
        }
    
    def _attribute_costs(self, portfolio_data: Dict) -> Dict:
        """交易成本归因"""
        
        costs = {
            'transaction_costs': portfolio_data.get('transaction_costs', 0),
            'slippage': portfolio_data.get('slippage', 0),
            'borrow_costs': portfolio_data.get('borrow_costs', 0)
        }
        
        total_costs = sum(costs.values())
        
        return {
            'pnl': -total_costs,  # 成本是负的P&L
            'breakdown': costs,
            'summary': f"Costs reduced P&L by ${total_costs:,.2f}"
        }
    
    def _deep_dive_unexplained(self, unexplained_pnl: float,
                              portfolio_data: Dict,
                              market_data: Dict) -> Dict:
        """深入分析未解释P&L"""
        
        analysis = {
            'unexplained_amount': unexplained_pnl,
            'potential_causes': []
        }
        
        # 检查可能的原因
        
        # 1. 模型误差
        if abs(unexplained_pnl) > 1000:
            analysis['potential_causes'].append({
                'cause': 'Model pricing error',
                'description': 'Large unexplained P&L may indicate model mispricing',
                'action': 'Review model calibration and parameters'
            })
        
        # 2. 数据质量问题
        if portfolio_data.get('data_quality_score', 1) < 0.95:
            analysis['potential_causes'].append({
                'cause': 'Data quality issues',
                'description': 'Poor data quality detected',
                'action': 'Review data sources and cleaning procedures'
            })
        
        # 3. 未捕获的风险因子
        analysis['potential_causes'].append({
            'cause': 'Missing risk factors',
            'description': 'Some risk factors may not be captured in the model',
            'action': 'Consider additional factors like liquidity, credit risk'
        })
        
        # 4. 非线性效应
        if portfolio_data.get('gamma', 0) > 100:
            analysis['potential_causes'].append({
                'cause': 'High order Greeks',
                'description': 'Large gamma suggests significant non-linear effects',
                'action': 'Include higher order Greeks in attribution'
            })
        
        return analysis

# 模型监控Dashboard
class ModelMonitoringDashboard:
    """
    模型监控仪表盘
    """
    
    def __init__(self):
        self.metrics_history = []
        self.alerts = []
        self.thresholds = {
            'var_breach_rate': 0.05,  # VaR突破率阈值
            'unexplained_pnl': 0.03,  # 未解释P&L阈值
            'model_decay': 30,  # 模型衰减天数阈值
            'parameter_stability': 0.8  # 参数稳定性阈值
        }
    
    def update_metrics(self, new_metrics: Dict):
        """更新指标"""
        
        new_metrics['timestamp'] = datetime.now()
        self.metrics_history.append(new_metrics)
        
        # 检查告警条件
        self._check_alerts(new_metrics)
        
        # 保留最近30天的数据
        cutoff = datetime.now() - timedelta(days=30)
        self.metrics_history = [
            m for m in self.metrics_history 
            if m['timestamp'] > cutoff
        ]
    
    def _check_alerts(self, metrics: Dict):
        """检查告警条件"""
        
        # VaR突破率检查
        if metrics.get('var_breach_rate', 0) > self.thresholds['var_breach_rate']:
            self.alerts.append({
                'type': 'var_breach',
                'severity': 'high',
                'message': f"VaR breach rate {metrics['var_breach_rate']:.1%} exceeds threshold",
                'timestamp': datetime.now()
            })
        
        # 未解释P&L检查
        if metrics.get('unexplained_pnl_pct', 0) > self.thresholds['unexplained_pnl']:
            self.alerts.append({
                'type': 'unexplained_pnl',
                'severity': 'medium',
                'message': f"Unexplained P&L {metrics['unexplained_pnl_pct']:.1%} exceeds threshold",
                'timestamp': datetime.now()
            })
        
        # 模型衰减检查
        if metrics.get('model_age_days', 0) > self.thresholds['model_decay']:
            self.alerts.append({
                'type': 'model_decay',
                'severity': 'low',
                'message': f"Model age {metrics['model_age_days']} days - consider retraining",
                'timestamp': datetime.now()
            })
    
    def get_dashboard_data(self) -> Dict:
        """获取仪表盘数据"""
        
        if not self.metrics_history:
            return {'status': 'no_data'}
        
        recent_metrics = self.metrics_history[-1]
        
        # 计算趋势
        trends = self._calculate_trends()
        
        # 生成健康评分
        health_score = self._calculate_health_score(recent_metrics)
        
        return {
            'current_metrics': recent_metrics,
            'trends': trends,
            'health_score': health_score,
            'recent_alerts': self.alerts[-10:],  # 最近10条告警
            'recommendations': self._generate_recommendations(recent_metrics, trends)
        }
    
    def _calculate_trends(self) -> Dict:
        """计算趋势"""
        
        if len(self.metrics_history) < 2:
            return {}
        
        df = pd.DataFrame(self.metrics_history)
        
        trends = {}
        
        # 计算各指标的趋势
        for col in ['var_breach_rate', 'sharpe_ratio', 'unexplained_pnl_pct']:
            if col in df.columns:
                recent = df[col].iloc[-5:].mean() if len(df) >= 5 else df[col].iloc[-1]
                previous = df[col].iloc[-10:-5].mean() if len(df) >= 10 else df[col].iloc[0]
                
                if previous != 0:
                    change = (recent - previous) / abs(previous)
                else:
                    change = 0
                
                trends[col] = {
                    'current': recent,
                    'change': change,
                    'direction': 'up' if change > 0 else 'down' if change < 0 else 'stable'
                }
        
        return trends
    
    def _calculate_health_score(self, metrics: Dict) -> float:
        """计算模型健康评分"""
        
        score = 100
        
        # VaR突破率扣分
        var_breach = metrics.get('var_breach_rate', 0)
        if var_breach > 0.01:
            score -= min((var_breach - 0.01) * 1000, 30)
        
        # 未解释P&L扣分
        unexplained = metrics.get('unexplained_pnl_pct', 0)
        if unexplained > 0.01:
            score -= min(unexplained * 500, 30)
        
        # 模型年龄扣分
        age = metrics.get('model_age_days', 0)
        if age > 30:
            score -= min((age - 30) * 0.5, 20)
        
        # Sharpe比率加分
        sharpe = metrics.get('sharpe_ratio', 0)
        if sharpe > 1:
            score += min((sharpe - 1) * 10, 20)
        
        return max(0, min(100, score))
    
    def _generate_recommendations(self, metrics: Dict, trends: Dict) -> List[str]:
        """生成建议"""
        
        recommendations = []
        
        # 基于当前指标
        if metrics.get('var_breach_rate', 0) > 0.03:
            recommendations.append("VaR model needs recalibration - breach rate too high")
        
        if metrics.get('unexplained_pnl_pct', 0) > 0.02:
            recommendations.append("Review P&L attribution methodology - high unexplained component")
        
        if metrics.get('model_age_days', 0) > 20:
            recommendations.append("Schedule model retraining - approaching decay threshold")
        
        # 基于趋势
        if trends.get('sharpe_ratio', {}).get('direction') == 'down':
            recommendations.append("Performance declining - review strategy parameters")
        
        if trends.get('var_breach_rate', {}).get('direction') == 'up':
            recommendations.append("Risk model deteriorating - increase monitoring frequency")
        
        return recommendations

# 使用示例
if __name__ == "__main__":
    # 配置回测
    config = BacktestConfig(
        start_date=datetime(2023, 1, 1),
        end_date=datetime(2024, 1, 1),
        initial_capital=1000000,
        lookback_window=60,
        rebalance_frequency=5,
        walk_forward_window=20,
        transaction_cost=10,
        slippage_model='sqrt'
    )
    
    # 创建回测器
    backtester = ModelBacktester(config)
    
    # 模拟数据
    dates = pd.date_range(config.start_date, config.end_date, freq='D')
    data = pd.DataFrame({
        'date': dates,
        'price': 500 + np.cumsum(np.random.randn(len(dates)) * 10),
        'volume': np.random.randint(100000, 1000000, len(dates)),
        'implied_vol': 0.8 + np.random.randn(len(dates)) * 0.1
    })
    data.set_index('date', inplace=True)
    
    # 定义简单策略
    def simple_strategy(predictions, risk, data):
        # 基于预测和风险生成信号
        if risk.get('var_95', 0) > 10000:
            return {'action': 'sell', 'quantity': 100}
        elif predictions.get('expected_return', 0) > 0.01:
            return {'action': 'buy', 'quantity': 100}
        else:
            return {'action': 'hold', 'quantity': 0}
    
    # 创建模拟模型
    class SimpleModel:
        def fit(self, data):
            pass
        
        def predict(self, data):
            return {'expected_return': np.random.randn() * 0.01}
        
        def calculate_var(self, data, confidence):
            return abs(np.random.randn() * 10000)
        
        def calculate_expected_shortfall(self, data, confidence):
            return abs(np.random.randn() * 15000)
    
    model = SimpleModel()
    
    # 运行回测
    results = backtester.run_backtest(model, data, simple_strategy)
    
    print("Backtest Results Summary:")
    print("-" * 60)
    print(f"Walk-Forward Sharpe: {results['walk_forward'].get('sharpe_ratio', 0):.2f}")
    print(f"Max Drawdown: {results['walk_forward'].get('max_drawdown', 0):.2%}")
    print(f"Win Rate: {results['walk_forward'].get('win_rate', 0):.2%}")
    print(f"Robustness Score: {results['summary']['robustness_score']:.0f}/100")
    print(f"\nRecommendation: {results['summary']['recommendation']}")
    
    # P&L归因示例
    pnl_system = PnLAttributionSystem()
    
    portfolio_data = {
        'current_value': 1050000,
        'previous_value': 1000000,
        'QQQ_position': 1000,
        'QQQ_price': 400,
        'MSTR_delta': 500,
        'MSTR_price': 500,
        'delta': 1500,
        'gamma': 50,
        'vega': 1000,
        'theta': -100,
        'transaction_costs': 500,
        'slippage': 300
    }
    
    market_data = {
        'QQQ_return': 0.01,
        'MSTR_return': 0.02,
        'spot_change': 10,
        'vol_change': 0.05,
        'premium_change': 0.001
    }
    
    attribution = pnl_system.attribute_pnl(portfolio_data, market_data, {})
    
    print("\n\nP&L Attribution:")
    print("-" * 60)
    print(f"Actual P&L: ${attribution['actual_pnl']:,.2f}")
    for source, details in attribution['attribution'].items():
        print(f"{source}: ${details['pnl']:,.2f}")
    print(f"Unexplained: ${attribution['unexplained_pnl']:,.2f} ({attribution['unexplained_pct']:.1%})")
    print(f"Quality Score: {attribution['quality_score']:.2%}")
第六部分：实时监控仪表盘详细实施方案
6.1 前端仪表盘实现
python"""
实时风险监控仪表盘
使用Dash框架实现Web界面
"""

import dash
from dash import dcc, html, dash_table, Input, Output, State
import plotly.graph_objs as go
import plotly.express as px
from plotly.subplots import make_subplots
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import asyncio
from typing import Dict, List
import redis
import json

class RiskDashboard:
    """
    实时风险监控仪表盘
    """
    
    def __init__(self, redis_client=None):
        self.app = dash.Dash(__name__)
        self.redis_client = redis_client or redis.Redis(host='localhost', port=6379)
        self.setup_layout()
        self.setup_callbacks()
        
    def setup_layout(self):
        """设置仪表盘布局"""
        
        self.app.layout = html.Div([
            # 页面标题
            html.Div([
                html.H1("Project Cerberus - Risk Management Dashboard", 
                       style={'textAlign': 'center', 'color': '#2c3e50'}),
                html.Hr()
            ]),
            
            # 顶部KPI卡片
            html.Div([
                self._create_kpi_cards()
            ], style={'margin': '20px'}),
            
            # 主要图表区域
            html.Div([
                # 左侧 - Greeks监控
                html.Div([
                    html.H3("Greeks Monitor", style={'textAlign': 'center'}),
                    dcc.Graph(id='greeks-gauge'),
                    dcc.Graph(id='greeks-timeline')
                ], style={'width': '48%', 'display': 'inline-block', 'verticalAlign': 'top'}),
                
                # 右侧 - 风险指标
                html.Div([
                    html.H3("Risk Metrics", style={'textAlign': 'center'}),
                    dcc.Graph(id='var-chart'),
                    dcc.Graph(id='risk-heatmap')
                ], style={'width': '48%', 'float': 'right', 'display': 'inline-block'})
            ]),
            
            # P&L归因部分
            html.Div([
                html.H3("P&L Attribution", style={'textAlign': 'center'}),
                dcc.Graph(id='pnl-waterfall'),
                html.Div(id='pnl-table-container')
            ], style={'margin': '20px'}),
            
            # MSTR-BTC基差监控
            html.Div([
                html.H3("MSTR-BTC Basis Monitor", style={'textAlign': 'center'}),
                html.Div([
                    dcc.Graph(id='basis-spread-chart', style={'width': '50%', 'display': 'inline-block'}),
                    dcc.Graph(id='correlation-chart', style={'width': '50%', 'display': 'inline-block'})
                ])
            ]),
            
            # 告警面板
            html.Div([
                html.H3("Active Alerts", style={'textAlign': 'center', 'color': '#e74c3c'}),
                html.Div(id='alerts-container')
            ], style={'margin': '20px', 'backgroundColor': '#fff5f5', 'padding': '10px', 'borderRadius': '5px'}),
            
            # 自动刷新组件
            dcc.Interval(
                id='interval-component',
                interval=5*1000,  # 5秒刷新
                n_intervals=0
            ),
            
            # 隐藏的数据存储
            dcc.Store(id='data-store')
        ])
    
    def _create_kpi_cards(self):
        """创建KPI卡片"""
        
        return html.Div([
            # 组合价值
            html.Div([
                html.H4("Portfolio Value"),
                html.H2(id='portfolio-value', children="$10,000,000"),
                html.P(id='portfolio-change', children="↑ 2.5%", 
                      style={'color': 'green'})
            ], style={'width': '23%', 'display': 'inline-block', 
                     'textAlign': 'center', 'backgroundColor': '#ecf0f1',
                     'margin': '1%', 'padding': '20px', 'borderRadius': '10px'}),
            
            # VaR
            html.Div([
                html.H4("VaR (99%)"),
                html.H2(id='var-value', children="$150,000"),
                html.P(id='var-util', children="75% of limit", 
                      style={'color': 'orange'})
            ], style={'width': '23%', 'display': 'inline-block',
                     'textAlign': 'center', 'backgroundColor': '#ecf0f1',
                     'margin': '1%', 'padding': '20px', 'borderRadius': '10px'}),
            
            # Sharpe Ratio
            html.Div([
                html.H4("Sharpe Ratio"),
                html.H2(id='sharpe-ratio', children="1.85"),
                html.P(id='sharpe-trend', children="↑ vs last month", 
                      style={'color': 'green'})
            ], style={'width': '23%', 'display': 'inline-block',
                     'textAlign': 'center', 'backgroundColor': '#ecf0f1',
                     'margin': '1%', 'padding': '20px', 'borderRadius': '10px'}),
            
            # 健康评分
            html.Div([
                html.H4("System Health"),
                html.H2(id='health-score', children="92/100"),
                html.P(id='health-status', children="Optimal", 
                      style={'color': 'green'})
            ], style={'width': '23%', 'display': 'inline-block',
                     'textAlign': 'center', 'backgroundColor': '#ecf0f1',
                     'margin': '1%', 'padding': '20px', 'borderRadius': '10px'})
        ])
    
    def setup_callbacks(self):
        """设置回调函数"""
        
        @self.app.callback(
            [Output('data-store', 'data'),
             Output('portfolio-value', 'children'),
             Output('portfolio-change', 'children'),
             Output('portfolio-change', 'style'),
             Output('var-value', 'children'),
             Output('var-util', 'children'),
             Output('var-util', 'style')],
            [Input('interval-component', 'n_intervals')]
        )
        def update_kpis(n):
            """更新KPI数据"""
            
            # 从Redis获取实时数据
            data = self._fetch_real_time_data()
            
            # 更新KPI值
            portfolio_value = f"${data['portfolio_value']:,.0f}"
            
            change = data['portfolio_change']
            change_text = f"{'↑' if change >= 0 else '↓'} {abs(change):.2%}"
            change_style = {'color': 'green' if change >= 0 else 'red'}
            
            var_value = f"${data['var_99']:,.0f}"
            var_utilization = data['var_utilization']
            var_util_text = f"{var_utilization:.0%} of limit"
            
            if var_utilization > 0.9:
                var_util_style = {'color': 'red', 'fontWeight': 'bold'}
            elif var_utilization > 0.75:
                var_util_style = {'color': 'orange'}
            else:
                var_util_style = {'color': 'green'}
            
            return (data, portfolio_value, change_text, change_style, 
                   var_value, var_util_text, var_util_style)
        
        @self.app.callback(
            Output('greeks-gauge', 'figure'),
            [Input('data-store', 'data')]
        )
        def update_greeks_gauge(data):
            """更新Greeks仪表盘"""
            
            if not data:
                return {}
            
            # 创建子图
            fig = make_subplots(
                rows=2, cols=2,
                specs=[[{'type': 'indicator'}, {'type': 'indicator'}],
                      [{'type': 'indicator'}, {'type': 'indicator'}]],
                subplot_titles=['Delta', 'Gamma', 'Vega', 'Theta']
            )
            
            greeks = data.get('greeks', {})
            limits = data.get('greek_limits', {})
            
            # Delta仪表
            fig.add_trace(go.Indicator(
                mode="gauge+number+delta",
                value=greeks.get('delta', 0),
                title={'text': "Delta"},
                delta={'reference': 0},
                gauge={'axis': {'range': [-limits.get('delta', 1000), limits.get('delta', 1000)]},
                      'bar': {'color': "darkblue"},
                      'steps': [
                          {'range': [-limits.get('delta', 1000), -limits.get('delta', 1000)*0.8], 'color': "red"},
                          {'range': [-limits.get('delta', 1000)*0.8, limits.get('delta', 1000)*0.8], 'color': "yellow"},
                          {'range': [limits.get('delta', 1000)*0.8, limits.get('delta', 1000)], 'color': "red"}],
                      'threshold': {'line': {'color': "red", 'width': 4},
                                   'thickness': 0.75, 'value': limits.get('delta', 1000)*0.9}}
            ), row=1, col=1)
            
            # Gamma仪表
            fig.add_trace(go.Indicator(
                mode="gauge+number",
                value=abs(greeks.get('gamma', 0)),
                title={'text': "Gamma"},
                gauge={'axis': {'range': [0, limits.get('gamma', 100)]},
                      'bar': {'color': "darkgreen"},
                      'steps': [
                          {'range': [0, limits.get('gamma', 100)*0.5], 'color': "lightgreen"},
                          {'range': [limits.get('gamma', 100)*0.5, limits.get('gamma', 100)*0.8], 'color': "yellow"},
                          {'range': [limits.get('gamma', 100)*0.8, limits.get('gamma', 100)], 'color': "red"}]}
            ), row=1, col=2)
            
            # Vega仪表
            fig.add_trace(go.Indicator(
                mode="gauge+number",
                value=greeks.get('vega', 0),
                title={'text': "Vega"},
                gauge={'axis': {'range': [-limits.get('vega', 5000), limits.get('vega', 5000)]},
                      'bar': {'color': "purple"}}
            ), row=2, col=1)
            
            # Theta仪表
            fig.add_trace(go.Indicator(
                mode="gauge+number",
                value=greeks.get('theta', 0),
                title={'text': "Theta"},
                gauge={'axis': {'range': [-1000, 100]},
                      'bar': {'color': "orange"}}
            ), row=2, col=2)
            
            fig.update_layout(height=400)
            
            return fig
        
        @self.app.callback(
            Output('greeks-timeline', 'figure'),
            [Input('data-store', 'data')]
        )
        def update_greeks_timeline(data):
            """更新Greeks时间线图"""
            
            if not data or 'greeks_history' not in data:
                return {}
            
            df = pd.DataFrame(data['greeks_history'])
            
            fig = make_subplots(
                rows=2, cols=2,
                subplot_titles=['Delta', 'Gamma', 'Vega', 'Theta'],
                shared_xaxes=True
            )
            
            # Delta
            fig.add_trace(go.Scatter(
                x=df['timestamp'], y=df['delta'],
                mode='lines', name='Delta',
                line=dict(color='blue', width=2)
            ), row=1, col=1)
            
            # Gamma  
            fig.add_trace(go.Scatter(
                x=df['timestamp'], y=df['gamma'],
                mode='lines', name='Gamma',
                line=dict(color='green', width=2)
            ), row=1, col=2)
            
            # Vega
            fig.add_trace(go.Scatter(
                x=df['timestamp'], y=df['vega'],
                mode='lines', name='Vega',
                line=dict(color='purple', width=2)
            ), row=2, col=1)
            
            # Theta
            fig.add_trace(go.Scatter(
                x=df['timestamp'], y=df['theta'],
                mode='lines', name='Theta',
                line=dict(color='orange', width=2)
            ), row=2, col=2)
            
            fig.update_layout(height=400, showlegend=False)
            
            return fig
        
        @self.app.callback(
            Output('var-chart', 'figure'),
            [Input('data-store', 'data')]
        )
        def update_var_chart(data):
            """更新VaR图表"""
            
            if not data:
                return {}
            
            # VaR和ES比较
            var_data = data.get('var_data', {})
            
            fig = go.Figure()
            
            # VaR柱状图
            fig.add_trace(go.Bar(
                x=['VaR 95%', 'VaR 99%', 'ES 95%', 'ES 99%'],
                y=[var_data.get('var_95', 0), var_data.get('var_99', 0),
                   var_data.get('es_95', 0), var_data.get('es_99', 0)],
                marker_color=['lightblue', 'blue', 'lightcoral', 'darkred'],
                text=[f"${v:,.0f}" for v in [var_data.get('var_95', 0), 
                                              var_data.get('var_99', 0),
                                              var_data.get('es_95', 0), 
                                              var_data.get('es_99', 0)]],
                textposition='outside'
            ))
            
            # 添加限额线
            if 'var_limit' in data:
                fig.add_hline(y=data['var_limit'], line_dash="dash", 
                            line_color="red", annotation_text="Limit")
            
            fig.update_layout(
                title="Value at Risk & Expected Shortfall",
                yaxis_title="Risk ($)",
                height=300
            )
            
            return fig
        
        @self.app.callback(
            Output('risk-heatmap', 'figure'),
            [Input('data-store', 'data')]
        )
        def update_risk_heatmap(data):
            """更新风险热力图"""
            
            if not data:
                return {}
            
            # 风险矩阵数据
            risk_matrix = data.get('risk_matrix', [])
            
            if not risk_matrix:
                # 生成示例数据
                risk_factors = ['Market Risk', 'Volatility Risk', 'Basis Risk', 
                              'Liquidity Risk', 'Model Risk']
                time_horizons = ['1D', '1W', '1M', '3M']
                
                z_data = np.random.rand(len(risk_factors), len(time_horizons)) * 100
            else:
                risk_factors = risk_matrix['factors']
                time_horizons = risk_matrix['horizons']
                z_data = risk_matrix['values']
            
            fig = go.Figure(data=go.Heatmap(
                z=z_data,
                x=time_horizons,
                y=risk_factors,
                colorscale='RdYlGn_r',
                text=z_data,
                texttemplate='%{text:.0f}',
                textfont={"size": 10},
                colorbar=dict(title="Risk Score")
            ))
            
            fig.update_layout(
                title="Risk Heatmap by Factor and Horizon",
                height=300
            )
            
            return fig
        
        @self.app.callback(
            Output('pnl-waterfall', 'figure'),
            [Input('data-store', 'data')]
        )
        def update_pnl_waterfall(data):
            """更新P&L瀑布图"""
            
            if not data or 'pnl_attribution' not in data:
                return {}
            
            pnl_attr = data['pnl_attribution']
            
            # 构建瀑布图数据
            x_data = []
            y_data = []
            colors = []
            
            running_total = 0
            
            for source, value in pnl_attr.items():
                if source != 'total':
                    x_data.append(source)
                    y_data.append(value)
                    colors.append('green' if value > 0 else 'red')
                    running_total += value
            
            # 添加总计
            x_data.append('Total')
            y_data.append(running_total)
            colors.append('blue')
            
            fig = go.Figure(go.Waterfall(
                x=x_data,
                y=y_data,
                textposition="outside",
                text=[f"${y:,.0f}" for y in y_data],
                connector={"line": {"color": "rgb(63, 63, 63)"}},
                increasing={"marker": {"color": "green"}},
                decreasing={"marker": {"color": "red"}},
                totals={"marker": {"color": "blue"}}
            ))
            
            fig.update_layout(
                title="P&L Attribution Waterfall",
                yaxis_title="P&L ($)",
                height=400
            )
            
            return fig
        
        @self.app.callback(
            Output('basis-spread-chart', 'figure'),
            [Input('data-store', 'data')]
        )
        def update_basis_chart(data):
            """更新基差图表"""
            
            if not data or 'basis_history' not in data:
                return {}
            
            df = pd.DataFrame(data['basis_history'])
            
            fig = make_subplots(
                rows=2, cols=1,
                subplot_titles=['MSTR Premium to BTC NAV', 'Z-Score'],
                row_heights=[0.7, 0.3]
            )
            
            # 溢价率
            fig.add_trace(go.Scatter(
                x=df['timestamp'],
                y=df['premium'],
                mode='lines',
                name='Premium',
                line=dict(color='blue', width=2)
            ), row=1, col=1)
            
            # 添加均值线
            fig.add_hline(y=df['premium'].mean(), row=1, col=1,
                         line_dash="dash", line_color="gray",
                         annotation_text="Mean")
            
            # Z-Score
            z_score = (df['premium'] - df['premium'].mean()) / df['premium'].std()
            
            fig.add_trace(go.Scatter(
                x=df['timestamp'],
                y=z_score,
                mode='lines',
                name='Z-Score',
                line=dict(color='orange', width=2),
                fill='tozeroy'
            ), row=2, col=1)
            
            # 添加Z-Score阈值线
            fig.add_hline(y=2, row=2, col=1, line_dash="dash", 
                         line_color="red", annotation_text="+2σ")
            fig.add_hline(y=-2, row=2, col=1, line_dash="dash", 
                         line_color="red", annotation_text="-2σ")
            
            fig.update_layout(height=400, showlegend=False)
            fig.update_yaxes(title_text="Premium (%)", row=1, col=1)
            fig.update_yaxes(title_text="Z-Score", row=2, col=1)
            
            return fig
        
        @self.app.callback(
            Output('alerts-container', 'children'),
            [Input('data-store', 'data')]
        )
        def update_alerts(data):
            """更新告警面板"""
            
            if not data or 'alerts' not in data:
                return html.Div("No active alerts", style={'color': 'green'})
            
            alerts = data['alerts']
            
            if not alerts:
                return html.Div("No active alerts", style={'color': 'green'})
            
            alert_elements = []
            
            for alert in alerts[-5:]:  # 显示最近5条
                color = {
                    'critical': '#e74c3c',
                    'high': '#e67e22',
                    'medium': '#f39c12',
                    'low': '#95a5a6'
                }.get(alert.get('severity', 'low'), '#95a5a6')
                
                alert_elements.append(
                    html.Div([
                        html.Span(f"[{alert.get('timestamp', '')}] ", 
                                 style={'fontWeight': 'bold'}),
                        html.Span(f"{alert.get('type', '')}: ", 
                                 style={'color': color, 'fontWeight': 'bold'}),
                        html.Span(alert.get('message', ''))
                    ], style={'padding': '5px', 'borderLeft': f'3px solid {color}',
                             'marginBottom': '5px', 'backgroundColor': 'white'})
                )
            
            return html.Div(alert_elements)
    
    def _fetch_real_time_data(self) -> Dict:
        """从Redis获取实时数据"""
        
        try:
            # 获取最新数据
            data = {}
            
            # KPI数据
            portfolio_data = self.redis_client.get('portfolio:current')
            if portfolio_data:
                portfolio = json.loads(portfolio_data)
                data['portfolio_value'] = portfolio.get('value', 10000000)
                data['portfolio_change'] = portfolio.get('daily_change', 0.025)
            else:
                # 模拟数据
                data['portfolio_value'] = 10000000 + np.random.randn() * 100000
                data['portfolio_change'] = np.random.randn() * 0.02
            
            # VaR数据
            var_data = self.redis_client.get('risk:var')
            if var_data:
                var = json.loads(var_data)
                data.update(var)
            else:
                data['var_99'] = 150000 + np.random.randn() * 10000
                data['var_utilization'] = 0.75 + np.random.randn() * 0.1
                data['var_data'] = {
                    'var_95': 100000 + np.random.randn() * 5000,
                    'var_99': data['var_99'],
                    'es_95': 120000 + np.random.randn() * 8000,
                    'es_99': 180000 + np.random.randn() * 12000
                }
            
            # Greeks数据
            greeks_data = self.redis_client.get('risk:greeks')
            if greeks_data:
                data['greeks'] = json.loads(greeks_data)
            else:
                data['greeks'] = {
                    'delta': 500 + np.random.randn() * 50,
                    'gamma': 50 + np.random.randn() * 10,
                    'vega': 2000 + np.random.randn() * 200,
                    'theta': -100 + np.random.randn() * 20
                }
            
            data['greek_limits'] = {
                'delta': 1000,
                'gamma': 100,
                'vega': 5000,
                'theta': 500
            }
            
            # Greeks历史（模拟）
            timestamps = pd.date_range(end=datetime.now(), periods=100, freq='5min')
            data['greeks_history'] = {
                'timestamp': timestamps.tolist(),
                'delta': (500 + np.cumsum(np.random.randn(100) * 10)).tolist(),
                'gamma': (50 + np.cumsum(np.random.randn(100) * 2)).tolist(),
                'vega': (2000 + np.cumsum(np.random.randn(100) * 50)).tolist(),
                'theta': (-100 + np.cumsum(np.random.randn(100) * 5)).tolist()
            }
            
            # P&L归因（模拟）
            data['pnl_attribution'] = {
                'Market': 25000 + np.random.randn() * 5000,
                'Greeks': 15000 + np.random.randn() * 3000,
                'Volatility': 8000 + np.random.randn() * 2000,
                'Basis': -3000 + np.random.randn() * 1000,
                'Costs': -2000 + np.random.randn() * 500
            }
            
            # 基差历史（模拟）
            basis_timestamps = pd.date_range(end=datetime.now(), periods=50, freq='30min')
            premium_values = 0.15 + np.cumsum(np.random.randn(50) * 0.01)
            data['basis_history'] = {
                'timestamp': basis_timestamps.tolist(),
                'premium': premium_values.tolist()
            }
            
            # 告警（模拟）
            data['alerts'] = []
            if np.random.random() > 0.7:
                data['alerts'].append({
                    'timestamp': datetime.now().strftime('%H:%M:%S'),
                    'type': 'Greeks Limit',
                    'severity': np.random.choice(['low', 'medium', 'high']),
                    'message': f"Delta approaching limit: {data['greeks']['delta']:.0f}/1000"
                })
            
            return data
            
        except Exception as e:
            print(f"Error fetching data: {e}")
            # 返回默认数据
            return self._get_default_data()
    
    def _get_default_data(self) -> Dict:
        """获取默认数据"""
        
        return {
            'portfolio_value': 10000000,
            'portfolio_change': 0.025,
            'var_99': 150000,
            'var_utilization': 0.75,
            'greeks': {'delta': 500, 'gamma': 50, 'vega': 2000, 'theta': -100},
            'greek_limits': {'delta': 1000, 'gamma': 100, 'vega': 5000, 'theta': 500},
            'alerts': []
        }
    
    def run(self, debug=True, port=8050):
        """运行仪表盘"""
        self.app.run_server(debug=debug, port=port)

# WebSocket实时数据推送
class RealtimeDataStreamer:
    """
    实时数据推送服务
    """
    
    def __init__(self, redis_client=None):
        self.redis_client = redis_client or redis.Redis(host='localhost', port=6379)
        self.subscribers = []
        
    async def stream_data(self, websocket, path):
        """WebSocket数据流"""
        
        try:
            while True:
                # 获取最新数据
                data = await self._get_latest_data()
                
                # 发送给客户端
                await websocket.send(json.dumps(data))
                
                # 等待
                await asyncio.sleep(1)
                
        except Exception as e:
            print(f"WebSocket error: {e}")
    
    async def _get_latest_data(self) -> Dict:
        """获取最新数据"""
        
        data = {
            'timestamp': datetime.now().isoformat(),
            'greeks': {
                'delta': 500 + np.random.randn() * 10,
                'gamma': 50 + np.random.randn() * 2,
                'vega': 2000 + np.random.randn() * 50,
                'theta': -100 + np.random.randn() * 5
            },
            'prices': {
                'MSTR': 480 + np.random.randn() * 5,
                'QQQ': 400 + np.random.randn() * 2,
                'BTC': 65000 + np.random.randn() * 500
            },
            'risk_metrics': {
                'var_95': 100000 + np.random.randn() * 5000,
                'var_99': 150000 + np.random.randn() * 7500
            }
        }
        
        return data

# 使用示例
if __name__ == "__main__":
    # 创建仪表盘
    dashboard = RiskDashboard()
    
    # 运行仪表盘
    print("Starting Risk Dashboard on http://localhost:8050")
    dashboard.run(debug=True, port=8050)
6.2 监控指标聚合服务
python"""
监控指标聚合和计算服务
实时计算和推送关键风险指标
"""

import asyncio
import aioredis
import numpy as np
import pandas as pd
from typing import Dict, List, Optional
from datetime import datetime, timedelta
import json
from dataclasses import dataclass, asdict

@dataclass
class RiskMetricSnapshot:
    """风险指标快照"""
    timestamp: datetime
    portfolio_value: float
    pnl: float
    var_95: float
    var_99: float
    es_95: float
    es_99: float
    sharpe_ratio: float
    max_drawdown: float
    greeks: Dict[str, float]
    utilization: Dict[str, float]
    
    def to_dict(self) -> Dict:
        data = asdict(self)
        data['timestamp'] = self.timestamp.isoformat()
        return data

class MetricsAggregationService:
    """
    指标聚合服务
    """
    
    def __init__(self, redis_url: str = 'redis://localhost'):
        self.redis_url = redis_url
        self.redis_client = None
        self.calculation_interval = 5  # 秒
        self.aggregation_windows = [60, 300, 900, 3600]  # 1分钟, 5分钟, 15分钟, 1小时
        
    async def start(self):
        """启动服务"""
        
        # 连接Redis
        self.redis_client = await aioredis.create_redis_pool(self.redis_url)
        
        # 启动计算任务
        tasks = [
            self._calculate_metrics_loop(),
            self._aggregate_metrics_loop(),
            self._calculate_derived_metrics_loop(),
            self._monitor_health_loop()
        ]
        
        await asyncio.gather(*tasks)
    
    async def _calculate_metrics_loop(self):
        """计算指标循环"""
        
        while True:
            try:
                # 计算当前指标
                snapshot = await self._calculate_current_metrics()
                
                # 存储到Redis
                await self._store_snapshot(snapshot)
                
                # 发布更新事件
                await self.redis_client.publish(
                    'metrics:update',
                    json.dumps(snapshot.to_dict())
                )
                
            except Exception as e:
                print(f"Error calculating metrics: {e}")
            
            await asyncio.sleep(self.calculation_interval)
    
    async def _calculate_current_metrics(self) -> RiskMetricSnapshot:
        """计算当前指标"""
        
        # 获取持仓数据
        positions = await self._get_positions()
        
        # 获取市场数据
        market_data = await self._get_market_data()
        
        # 计算组合价值
        portfolio_value = self._calculate_portfolio_value(positions, market_data)
        
        # 计算P&L
        previous_value = await self._get_previous_value()
        pnl = portfolio_value - previous_value
        
        # 计算VaR/ES
        risk_metrics = await self._calculate_risk_metrics(positions, market_data)
        
        # 计算Greeks
        greeks = await self._calculate_greeks(positions, market_data)
        
        # 计算性能指标
        performance = await self._calculate_performance_metrics()
        
        # 计算利用率
        utilization = await self._calculate_utilization(greeks, risk_metrics)
        
        return RiskMetricSnapshot(
            timestamp=datetime.now(),
            portfolio_value=portfolio_value,
            pnl=pnl,
            var_95=risk_metrics['var_95'],
            var_99=risk_metrics['var_99'],
            es_95=risk_metrics['es_95'],
            es_99=risk_metrics['es_99'],
            sharpe_ratio=performance['sharpe_ratio'],
            max_drawdown=performance['max_drawdown'],
            greeks=greeks,
            utilization=utilization
        )
    
    async def _aggregate_metrics_loop(self):
        """聚合指标循环"""
        
        while True:
            try:
                for window in self.aggregation_windows:
                    await self._aggregate_window(window)
                    
            except Exception as e:
                print(f"Error aggregating metrics: {e}")
            
            await asyncio.sleep(60)  # 每分钟聚合一次
    
    async def _aggregate_window(self, window_seconds: int):
        """聚合特定时间窗口"""
        
        # 获取窗口内的数据
        end_time = datetime.now()
        start_time = end_time - timedelta(seconds=window_seconds)
        
        snapshots = await self._get_snapshots_range(start_time, end_time)
        
        if not snapshots:
            return
        
        # 计算聚合指标
        aggregated = {
            'window': window_seconds,
            'start_time': start_time.isoformat(),
            'end_time': end_time.isoformat(),
            'num_points': len(snapshots),
            
            # 均值
            'avg_portfolio_value': np.mean([s['portfolio_value'] for s in snapshots]),
            'avg_var_99': np.mean([s['var_99'] for s in snapshots]),
            'avg_greeks': {
                'delta': np.mean([s['greeks']['delta'] for s in snapshots]),
                'gamma': np.mean([s['greeks']['gamma'] for s in snapshots]),
                'vega': np.mean([s['greeks']['vega'] for s in snapshots]),
                'theta': np.mean([s['greeks']['theta'] for s in snapshots])
            },
            
            # 最大值
            'max_var_99': np.max([s['var_99'] for s in snapshots]),
            'max_drawdown': np.max([s['max_drawdown'] for s in snapshots]),
            
            # 标准差
            'volatility': np.std([s['pnl'] for s in snapshots]) * np.sqrt(252 * 86400 / window_seconds)
        }
        
        # 存储聚合结果
        key = f"metrics:aggregated:{window_seconds}"
        await self.redis_client.setex(
            key,
            window_seconds * 2,  # 保留2倍窗口时间
            json.dumps(aggregated)
        )
    
    async def _calculate_derived_metrics_loop(self):
        """计算衍生指标循环"""
        
        while True:
            try:
                # 计算趋势
                trends = await self._calculate_trends()
                
                # 计算相关性
                correlations = await self._calculate_correlations()
                
                # 计算异常分数
                anomaly_scores = await self._calculate_anomaly_scores()
                
                # 存储结果
                derived = {
                    'timestamp': datetime.now().isoformat(),
                    'trends': trends,
                    'correlations': correlations,
                    'anomaly_scores': anomaly_scores
                }
                
                await self.redis_client.setex(
                    'metrics:derived',
                    300,  # 5分钟过期
                    json.dumps(derived)
                )
                
            except Exception as e:
                print(f"Error calculating derived metrics: {e}")
            
            await asyncio.sleep(30)  # 每30秒计算一次
    
    async def _calculate_trends(self) -> Dict:
        """计算趋势"""
        
        # 获取历史数据
        snapshots = await self._get_snapshots_range(
            datetime.now() - timedelta(hours=1),
            datetime.now()
        )
        
        if len(snapshots) < 10:
            return {}
        
        # 转换为DataFrame
        df = pd.DataFrame(snapshots)
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        df.set_index('timestamp', inplace=True)
        
        trends = {}
        
        # 计算移动平均
        for col in ['portfolio_value', 'var_99']:
            if col in df.columns:
                ma_short = df[col].rolling(window=10).mean().iloc[-1]
                ma_long = df[col].rolling(window=30).mean().iloc[-1] if len(df) > 30 else ma_short
                
                if ma_long > 0:
                    trend = (ma_short - ma_long) / ma_long
                    trends[col] = {
                        'direction': 'up' if trend > 0 else 'down',
                        'strength': abs(trend),
                        'ma_short': ma_short,
                        'ma_long': ma_long
                    }
        
        return trends
    
    async def _calculate_correlations(self) -> Dict:
        """计算相关性"""
        
        # 获取MSTR、BTC、QQQ价格数据
        mstr_data = await self.redis_client.get('price:MSTR:history')
        btc_data = await self.redis_client.get('price:BTC:history')
        qqq_data = await self.redis_client.get('price:QQQ:history')
        
        correlations = {}
        
        if mstr_data and btc_data:
            mstr_prices = json.loads(mstr_data)[-100:]  # 最近100个点
            btc_prices = json.loads(btc_data)[-100:]
            
            if len(mstr_prices) == len(btc_prices):
                corr = np.corrcoef(mstr_prices, btc_prices)[0, 1]
                correlations['MSTR_BTC'] = corr
        
        return correlations
    
    async def _calculate_anomaly_scores(self) -> Dict:
        """计算异常分数"""
        
        # 获取最近数据
        current = await self._get_latest_snapshot()
        historical = await self._get_snapshots_range(
            datetime.now() - timedelta(hours=24),
            datetime.now()
        )
        
        if not current or len(historical) < 20:
            return {}
        
        anomaly_scores = {}
        
        # 对每个指标计算Z-score
        for metric in ['portfolio_value', 'var_99']:
            if metric in current:
                values = [h.get(metric, 0) for h in historical]
                mean = np.mean(values)
                std = np.std(values)
                
                if std > 0:
                    z_score = (current[metric] - mean) / std
                    anomaly_scores[metric] = {
                        'z_score': z_score,
                        'is_anomaly': abs(z_score) > 3,
                        'severity': 'high' if abs(z_score) > 4 else 'medium' if abs(z_score) > 3 else 'low'
                    }
        
        return anomaly_scores
    
    async def _monitor_health_loop(self):
        """监控系统健康状态"""
        
        while True:
            try:
                health = await self._check_system_health()
                
                # 存储健康状态
                await self.redis_client.setex(
                    'system:health',
                    60,
                    json.dumps(health)
                )
                
                # 如果有问题，发送告警
                if health['status'] != 'healthy':
                    await self._send_health_alert(health)
                
            except Exception as e:
                print(f"Error monitoring health: {e}")
            
            await asyncio.sleep(10)  # 每10秒检查一次
    
    async def _check_system_health(self) -> Dict:
        """检查系统健康状态"""
        
        health = {
            'timestamp': datetime.now().isoformat(),
            'status': 'healthy',
            'components': {},
            'issues': []
        }
        
        # 检查Redis连接
        try:
            await self.redis_client.ping()
            health['components']['redis'] = 'ok'
        except:
            health['components']['redis'] = 'error'
            health['issues'].append('Redis connection failed')
            health['status'] = 'unhealthy'
        
        # 检查数据延迟
        latest = await self._get_latest_snapshot()
        if latest:
            data_age = (datetime.now() - datetime.fromisoformat(latest['timestamp'])).total_seconds()
            if data_age > 60:  # 数据超过1分钟未更新
                health['issues'].append(f'Data stale: {data_age:.0f} seconds old')
                health['status'] = 'degraded'
            health['components']['data_freshness'] = f'{data_age:.0f}s'
        
        # 检查计算性能
        calc_time = await self._measure_calculation_time()
        if calc_time > 5:  # 计算时间超过5秒
            health['issues'].append(f'Slow calculations: {calc_time:.2f}s')
            health['status'] = 'degraded'
        health['components']['calculation_time'] = f'{calc_time:.2f}s'
        
        return health
    
    async def _measure_calculation_time(self) -> float:
        """测量计算时间"""
        
        import time
        start = time.time()
        
        # 执行典型计算
        await self._calculate_current_metrics()
        
        return time.time() - start
    
    async def _get_positions(self) -> List[Dict]:
        """获取持仓"""
        
        positions_data = await self.redis_client.get('positions:current')
        if positions_data:
            return json.loads(positions_data)
        
        # 返回模拟数据
        return [
            {'symbol': 'QQQ', 'quantity': 1000, 'type': 'stock'},
            {'symbol': 'MSTR_CALL_500', 'quantity': 100, 'type': 'option', 'strike': 500, 'expiry': 30}
        ]
    
    async def _get_market_data(self) -> Dict:
        """获取市场数据"""
        
        market_data = {}
        
        # 获取价格
        for symbol in ['MSTR', 'QQQ', 'BTC']:
            price = await self.redis_client.get(f'price:{symbol}')
            if price:
                market_data[symbol] = float(price)
            else:
                # 模拟价格
                market_data[symbol] = {
                    'MSTR': 480,
                    'QQQ': 400,
                    'BTC': 65000
                }.get(symbol, 100)
        
        # 获取波动率
        iv = await self.redis_client.get('volatility:MSTR')
        market_data['implied_vol'] = float(iv) if iv else 0.85
        
        return market_data
    
    def _calculate_portfolio_value(self, positions: List[Dict], 
                                  market_data: Dict) -> float:
        """计算组合价值"""
        
        total_value = 0
        
        for pos in positions:
            if pos['type'] == 'stock':
                price = market_data.get(pos['symbol'], 100)
                total_value += pos['quantity'] * price
            elif pos['type'] == 'option':
                # 简化期权定价
                option_value = self._black_scholes_price(
                    market_data.get('MSTR', 480),
                    pos['strike'],
                    pos['expiry'] / 365,
                    0.05,  # risk-free rate
                    market_data.get('implied_vol', 0.85)
                )
                total_value += pos['quantity'] * option_value * 100
        
        return total_value
    
    def _black_scholes_price(self, S: float, K: float, T: float, 
                            r: float, sigma: float) -> float:
        """简化的Black-Scholes定价"""
        
        from scipy.stats import norm
        
        if T <= 0:
            return max(S - K, 0)
        
        d1 = (np.log(S / K) + (r + 0.5 * sigma**2) * T) / (sigma * np.sqrt(T))
        d2 = d1 - sigma * np.sqrt(T)
        
        return S * norm.cdf(d1) - K * np.exp(-r * T) * norm.cdf(d2)
    
    async def _get_previous_value(self) -> float:
        """获取前值"""
        
        prev = await self.redis_client.get('portfolio:previous_value')
        return float(prev) if prev else 10000000
    
    async def _calculate_risk_metrics(self, positions: List[Dict],
                                     market_data: Dict) -> Dict:
        """计算风险指标"""
        
        # 简化的VaR/ES计算
        portfolio_value = self._calculate_portfolio_value(positions, market_data)
        
        # 假设正态分布
        daily_vol = market_data.get('implied_vol', 0.85) / np.sqrt(252)
        
        return {
            'var_95': portfolio_value * daily_vol * 1.645,
            'var_99': portfolio_value * daily_vol * 2.326,
            'es_95': portfolio_value * daily_vol * 2.063,
            'es_99': portfolio_value * daily_vol * 2.665
        }
    
    async def _calculate_greeks(self, positions: List[Dict],
                               market_data: Dict) -> Dict:
        """计算Greeks"""
        
        greeks = {'delta': 0, 'gamma': 0, 'vega': 0, 'theta': 0}
        
        for pos in positions:
            if pos['type'] == 'stock':
                greeks['delta'] += pos['quantity']
            elif pos['type'] == 'option':
                # 简化的Greeks计算
                S = market_data.get('MSTR', 480)
                K = pos['strike']
                T = pos['expiry'] / 365
                sigma = market_data.get('implied_vol', 0.85)
                
                # 计算单个期权的Greeks
                option_greeks = self._calculate_option_greeks(S, K, T, 0.05, sigma)
                
                # 累加
                for greek in greeks:
                    greeks[greek] += option_greeks[greek] * pos['quantity']
        
        return greeks
    
    def _calculate_option_greeks(self, S: float, K: float, T: float,
                                r: float, sigma: float) -> Dict:
        """计算期权Greeks"""
        
        from scipy.stats import norm
        
        if T <= 0:
            return {'delta': 1 if S > K else 0, 'gamma': 0, 'vega': 0, 'theta': 0}
        
        sqrt_T = np.sqrt(T)
        d1 = (np.log(S / K) + (r + 0.5 * sigma**2) * T) / (sigma * sqrt_T)
        
        return {
            'delta': norm.cdf(d1),
            'gamma': norm.pdf(d1) / (S * sigma * sqrt_T),
            'vega': S * norm.pdf(d1) * sqrt_T / 100,
            'theta': -S * norm.pdf(d1) * sigma / (2 * sqrt_T) / 365
        }
    
    async def _calculate_performance_metrics(self) -> Dict:
        """计算性能指标"""
        
        # 获取历史收益
        returns_data = await self.redis_client.get('returns:daily')
        
        if returns_data:
            returns = json.loads(returns_data)
            
            # Sharpe Ratio
            if len(returns) > 1:
                mean_return = np.mean(returns)
                std_return = np.std(returns)
                sharpe = mean_return / std_return * np.sqrt(252) if std_return > 0 else 0
            else:
                sharpe = 0
            
            # Max Drawdown
            cumulative = np.cumprod(1 + np.array(returns))
            running_max = np.maximum.accumulate(cumulative)
            drawdown = (cumulative - running_max) / running_max
            max_dd = abs(np.min(drawdown))
        else:
            sharpe = 1.5
            max_dd = 0.15
        
        return {
            'sharpe_ratio': sharpe,
            'max_drawdown': max_dd
        }
    
    async def _calculate_utilization(self, greeks: Dict, 
                                    risk_metrics: Dict) -> Dict:
        """计算利用率"""
        
        # 获取限额
        limits = {
            'delta': 1000,
            'gamma': 100,
            'vega': 5000,
            'var_99': 200000
        }
        
        utilization = {}
        
        for greek in greeks:
            if greek in limits:
                utilization[greek] = abs(greeks[greek]) / limits[greek]
        
        utilization['var_99'] = risk_metrics['var_99'] / limits['var_99']
        
        return utilization
    
    async def _store_snapshot(self, snapshot: RiskMetricSnapshot):
        """存储快照"""
        
        # 存储到时间序列
        await self.redis_client.zadd(
            'metrics:snapshots',
            snapshot.timestamp.timestamp(),
            json.dumps(snapshot.to_dict())
        )
        
        # 保留最近24小时的数据
        cutoff = (datetime.now() - timedelta(hours=24)).timestamp()
        await self.redis_client.zremrangebyscore('metrics:snapshots', 0, cutoff)
        
        # 存储最新值
        await self.redis_client.set(
            'metrics:latest',
            json.dumps(snapshot.to_dict())
        )
    
    async def _get_snapshots_range(self, start: datetime, 
                                  end: datetime) -> List[Dict]:
        """获取时间范围内的快照"""
        
        data = await self.redis_client.zrangebyscore(
            'metrics:snapshots',
            start.timestamp(),
            end.timestamp()
        )
        
        return [json.loads(d) for d in data]
    
    async def _get_latest_snapshot(self) -> Optional[Dict]:
        """获取最新快照"""
        
        data = await self.redis_client.get('metrics:latest')
        return json.loads(data) if data else None
    
    async def _send_health_alert(self, health: Dict):
        """发送健康告警"""
        
        alert = {
            'type': 'system_health',
            'severity': 'high' if health['status'] == 'unhealthy' else 'medium',
            'message': f"System {health['status']}: {', '.join(health['issues'])}",
            'timestamp': health['timestamp']
        }
        
        # 发布到告警通道
        await self.redis_client.publish('alerts:system', json.dumps(alert))

# 主程序入口
async def main():
    """主程序"""
    
    # 创建服务实例
    aggregator = MetricsAggregationService()
    
    # 启动服务
    print("Starting Metrics Aggregation Service...")
    await aggregator.start()

if __name__ == "__main__":
    asyncio.run(main())
第七部分：系统集成与部署方案
7.1 系统配置管理
yaml# config/production.yaml
# Project Cerberus 生产环境配置

# 数据库配置
database:
  postgres:
    host: ${DB_HOST:localhost}
    port: ${DB_PORT:5432}
    database: risk_db
    user: ${DB_USER:risk_user}
    password: ${DB_PASSWORD}
    pool_size: 20
    max_overflow: 10
    
  timescaledb:
    compression_policy:
      older_than: 7d
      chunk_time_interval: 1d
    retention_policy:
      older_than: 90d
      
  redis:
    host: ${REDIS_HOST:localhost}
    port: ${REDIS_PORT:6379}
    db: 0
    password: ${REDIS_PASSWORD}
    max_connections: 50
    
# 消息队列配置
messaging:
  kafka:
    brokers:
      - ${KAFKA_BROKER_1:localhost:9092}
      - ${KAFKA_BROKER_2:localhost:9093}
    topics:
      market_data: 
        partitions: 10
        replication_factor: 3
      risk_events:
        partitions: 5
        replication_factor: 2
    consumer_group: risk_management
    
# API配置
api:
  host: 0.0.0.0
  port: 8080
  workers: 4
  rate_limit:
    requests_per_minute: 1000
    burst: 100
  cors:
    allowed_origins:
      - http://localhost:3000
      - https://dashboard.company.com
      
# 风险管理配置
risk_management:
  # Greeks限额
  greek_limits:
    portfolio:
      delta: 1000
      gamma: 100
      vega: 5000
      theta: 1000
    per_underlying:
      MSTR:
        delta: 500
        gamma: 50
        vega: 2500
        
  # VaR限额
  var_limits:
    var_95_1d: 100000
    var_99_1d: 150000
    var_99_10d: 500000
    
  # 模型参数
  models:
    basis_risk:
      lookback_days: 252
      confidence_level: 0.95
      rebalance_threshold: 0.02
    volatility_surface:
      model_type: SVI
      calibration_frequency: hourly
      
  # 对冲策略
  hedging:
    enabled: true
    max_hedges_per_hour: 20
    min_hedge_interval_seconds: 60
    transaction_cost_bps: 10
    slippage_model: sqrt
    
# 监控配置
monitoring:
  metrics:
    calculation_interval: 5
    aggregation_windows: [60, 300, 900, 3600]
    retention_days: 7
    
  alerting:
    channels:
      - type: email
        recipients: [risk-team@company.com]
      - type: slack
        webhook_url: ${SLACK_WEBHOOK}
    thresholds:
      var_breach_rate: 0.05
      unexplained_pnl_pct: 0.03
      system_latency_ms: 100
      
  dashboard:
    refresh_interval: 5
    port: 8050
    
# 数据源配置
data_sources:
  market_data:
    - name: interactive_brokers
      type: ib_gateway
      host: ${IB_GATEWAY_HOST}
      port: 7497
      client_id: 1
      
    - name: coinbase
      type: websocket
      url: wss://ws-feed.pro.coinbase.com
      products: [BTC-USD]
      
    - name: yahoo_finance
      type: rest_api
      base_url: https://query1.finance.yahoo.com
      rate_limit: 100
      
# 性能配置
performance:
  cache:
    ttl: 60
    max_size: 10000
  computation:
    use_gpu: true
    gpu_device: 0
    parallel_workers: 8
    batch_size: 1000
    
# 日志配置
logging:
  level: INFO
  format: json
  outputs:
    - type: file
      path: /var/log/cerberus/app.log
      rotation: daily
      retention: 30
    - type: elasticsearch
      host: ${ES_HOST:localhost}
      port: 9200
      index: cerberus-logs
7.2 Docker容器化
dockerfile# Dockerfile
FROM python:3.11-slim

# 安装系统依赖
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    libpq-dev \
    curl \
    && rm -rf /var/lib/apt/lists/*

# 设置工作目录
WORKDIR /app

# 复制依赖文件
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# 安装CUDA支持（可选）
# RUN pip install cupy-cuda11x

# 复制应用代码
COPY src/ ./src/
COPY config/ ./config/
COPY scripts/ ./scripts/

# 创建非root用户
RUN useradd -m -u 1000 cerberus && \
    chown -R cerberus:cerberus /app

USER cerberus

# 健康检查
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:8080/health || exit 1

# 暴露端口
EXPOSE 8080 8050

# 启动命令
CMD ["python", "-m", "src.main"]
yaml# docker-compose.yml
version: '3.8'

services:
  # PostgreSQL + TimescaleDB
  postgres:
    image: timescale/timescaledb:latest-pg14
    environment:
      POSTGRES_DB: risk_db
      POSTGRES_USER: risk_user
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U risk_user"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis
  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD}
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  # 核心风险引擎
  risk-engine:
    build: .
    depends_on:
      - postgres
      - redis
      - kafka
    environment:
      DB_HOST: postgres
      REDIS_HOST: redis
      KAFKA_BROKER_1: kafka:9092
    volumes:
      - ./config:/app/config
    ports:
      - "8080:8080"
    restart: unless-stopped

  # 监控仪表盘
  dashboard:
    build: 
      context: .
      dockerfile: Dockerfile.dashboard
    depends_on:
      - risk-engine
      - redis
    environment:
      REDIS_HOST: redis
    ports:
      - "8050:8050"
    restart: unless-stopped

  # Prometheus监控
  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    ports:
      - "9090:9090"

  # Grafana可视化
  grafana:
    image: grafana/grafana:latest
    depends_on:
      - prometheus
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD}
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards
    ports:
      - "3000:3000"

volumes:
  postgres_data:
  redis_data:
  prometheus_data:
  grafana_data:
7.3 Kubernetes部署
yaml# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cerberus-risk-engine
  namespace: risk-management
spec:
  replicas: 3
  selector:
    matchLabels:
      app: risk-engine
  template:
    metadata:
      labels:
        app: risk-engine
    spec:
      containers:
      - name: risk-engine
        image: cerberus/risk-engine:latest
        ports:
        - containerPort: 8080
        env:
        - name: DB_HOST
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: host
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: db-credentials
              key: password
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5

---
apiVersion: v1
kind: Service
metadata:
  name: risk-engine-service
  namespace: risk-management
spec:
  selector:
    app: risk-engine
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8080
  type: LoadBalancer

---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: risk-engine-hpa
  namespace: risk-management
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: cerberus-risk-engine
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
7.4 启动脚本和运维工具
python# scripts/startup.py
"""
系统启动脚本
"""

import asyncio
import sys
import logging
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent))

from src.data_pipeline import DataPipeline
from src.risk_engine import RiskEngine
from src.monitoring import MetricsAggregationService
from src.dashboard import RiskDashboard

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class CerberusSystem:
    """
    Cerberus系统启动器
    """
    
    def __init__(self, config_path: str):
        self.config = self._load_config(config_path)
        self.components = {}
        
    def _load_config(self, config_path: str):
        """加载配置"""
        import yaml
        with open(config_path, 'r') as f:
            return yaml.safe_load(f)
    
    async def start(self):
        """启动系统"""
        
        logger.info("Starting Project Cerberus Risk Management System...")
        
        # 1. 启动数据管道
        logger.info("Starting data pipeline...")
        self.components['data_pipeline'] = DataPipeline(self.config)
        await self.components['data_pipeline'].initialize()
        
        # 2. 启动风险引擎
        logger.info("Starting risk engine...")
        self.components['risk_engine'] = RiskEngine(self.config)
        await self.components['risk_engine'].initialize()
        
        # 3. 启动监控服务
        logger.info("Starting monitoring service...")
        self.components['monitoring'] = MetricsAggregationService()
        
        # 4. 启动仪表盘（在单独进程）
        logger.info("Starting dashboard...")
        import multiprocessing
        dashboard_process = multiprocessing.Process(
            target=self._start_dashboard
        )
        dashboard_process.start()
        
        # 5. 启动主循环
        await self._main_loop()
    
    def _start_dashboard(self):
        """启动仪表盘"""
        dashboard = RiskDashboard()
        dashboard.run(debug=False, port=8050)
    
    async def _main_loop(self):
        """主循环"""
        
        tasks = [
            self.components['data_pipeline'].process_loop(),
            self.components['risk_engine'].calculate_loop(),
            self.components['monitoring'].start()
        ]
        
        await asyncio.gather(*tasks)
    
    async def shutdown(self):
        """关闭系统"""
        
        logger.info("Shutting down Cerberus system...")
        
        for component in self.components.values():
            if hasattr(component, 'shutdown'):
                await component.shutdown()
        
        logger.info("Shutdown complete")

async def main():
    """主函数"""
    
    config_path = sys.argv[1] if len(sys.argv) > 1 else 'config/production.yaml'
    
    system = CerberusSystem(config_path)
    
    try:
        await system.start()
    except KeyboardInterrupt:
        await system.shutdown()
    except Exception as e:
        logger.error(f"System error: {e}")
        await system.shutdown()
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())
bash# scripts/deploy.sh
#!/bin/bash
# 部署脚本

set -e

# 配置
ENV=${1:-production}
VERSION=${2:-latest}

echo "Deploying Project Cerberus - Environment: $ENV, Version: $VERSION"

# 1. 构建Docker镜像
echo "Building Docker images..."
docker build -t cerberus/risk-engine:$VERSION .
docker build -f Dockerfile.dashboard -t cerberus/dashboard:$VERSION .

# 2. 运行数据库迁移
echo "Running database migrations..."
docker run --rm \
  --network cerberus_network \
  cerberus/risk-engine:$VERSION \
  python -m src.database.migrate

# 3. 部署到Kubernetes
if [ "$ENV" == "production" ]; then
  echo "Deploying to Kubernetes..."
  kubectl apply -f k8s/namespace.yaml
  kubectl apply -f k8s/configmap.yaml
  kubectl apply -f k8s/secrets.yaml
  kubectl apply -f k8s/deployment.yaml
  kubectl apply -f k8s/service.yaml
  kubectl apply -f k8s/ingress.yaml
  
  # 等待部署完成
  kubectl rollout status deployment/cerberus-risk-engine -n risk-management
  
elif [ "$ENV" == "staging" ]; then
  echo "Deploying to staging with Docker Compose..."
  docker-compose -f docker-compose.staging.yml up -d
  
else
  echo "Deploying to development with Docker Compose..."
  docker-compose up -d
fi

# 4. 验证部署
echo "Verifying deployment..."
sleep 10

# 健康检查
if curl -f http://localhost:8080/health; then
  echo "✅ Risk engine is healthy"
else
  echo "❌ Risk engine health check failed"
  exit 1
fi

if curl -f http://localhost:8050; then
  echo "✅ Dashboard is accessible"
else
  echo "❌ Dashboard is not accessible"
  exit 1
fi

echo "✅ Deployment complete!"